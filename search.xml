<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>EM算法详解</title>
      <link href="/2020/12/08/methods/methods-em/"/>
      <url>/2020/12/08/methods/methods-em/</url>
      
        <content type="html"><![CDATA[<blockquote><p>这段时间研究了一下EM算法，发现之前对于EM算法的理解有些偏差，这一段时间的实践和学习让我对EM算法的理解又近了一步，所以这里写个文章记录一下。</p></blockquote><h1 id="背景">背景</h1><p>EM算法（Expectation Maximization）要解决的问题是：<strong>如何估计模型的参数。</strong></p><p>存在一批观察数据，我们希望通过一个参数模型来对其进行描述，通过这批数据得到该模型的参数的估计。针对该问题，最常见的方法就是<strong>极大似然法</strong>：</p><p><span class="math display">\[\hat{\theta}=\argmax_{\theta}{\sum_{i=1}^N{L_{\theta}(x_i)}}=\argmax_{\theta}{\sum_{i=1}^N{\log p_{\theta}(x_i)}}\tag{1}\]</span></p><p>我们可以通过微积分的方式求解<span class="math inline">\(1\)</span>：</p><p><span class="math display">\[\sum_{i=1}^N{\frac{\partial L_\theta(x_i)}{\partial\theta}}=0\]</span></p><p>很多情况下这种方式已经是足够用了。但是，另外的很多情况下，我们的参数模型是非常复杂的，上面这种直接的求解方法可能并不能用。比如，<strong>如果我们的参数模型是存在一个隐含变量<span class="math inline">\(z_i\)</span>的话</strong>，就无法直接使用上面的方法了。</p><blockquote><p>存在一个隐含变量的情况下，我们来计算一下对数似然函数的导数：</p><p><span class="math display">\[\begin{aligned}\sum_{i=1}^N{\frac{\partial L_\theta(x_i)}{\partial\theta}}&amp;=\sum_{i=1}^N{\frac{1}{p_{\theta}(x_i)}\frac{\partial p_{\theta}(x_i)}{\partial\theta}}\\&amp;\propto\sum_{i=1}^N{  \frac{1}{p_{\theta}(x_i)}\sum_{z}  \frac{\partial p_{\theta}(x_i|z_i)}{\partial\theta}\qquad\text{这里假设先验是均匀的}}\end{aligned}\]</span></p><p>因为有隐变量的存在，我们会额外出现一个求和号<span class="math inline">\(\sum_z\)</span>（或积分），这就会使得我们无法继续处理下去。比如若<span class="math inline">\(p_{\theta}\)</span>是正态分布，则一般来说在进行对数似然的计算时可以化简计算。但这里因为有求和号的存在，我们无法再像之前那样处理，即便这个<span class="math inline">\(z\)</span>是一个服从伯努利分布的二分类变量，更别提多分类或者连续分布变量了。</p></blockquote><p>EM算法便善于解决上面的这种存在隐变量的问题，其思路是使用启发式的迭代方法：固定参数来估计隐含变量<span class="math inline">\(z_i\)</span>（E step），固定隐含变量<span class="math inline">\(z_i\)</span>估计参数（M step）。这样不断迭代下去，直至算法收敛。</p><p>其实，k-means算法就可以算作EM算法的一个特例：计算每个样本属于哪个簇的过程就是E step；重新更新每个簇的质心的过程就是M step。</p><h1 id="推导">推导</h1><blockquote><p>推导有两种思路：即通过Jensen不等式和KL散度，我对KL散度比较熟，所以以这条思路为主。</p></blockquote><p>因为组成iid样本，我们先对单独一个样本进行分析：</p><p><span class="math display">\[\log p_{\theta}(x_i) =\log p_{\theta}(x_i,z_i)-\log p_{\theta}(z_i|x_i)\]</span></p><p>这里我们引入一个变分分布<span class="math inline">\(q_{\phi}(z_i)\)</span>，将上式进行变换得到：</p><p><span class="math display">\[\begin{aligned}    \log p_{\theta}(x_i)&amp;=\mathbb{E}_{q_{\phi}(z_i)}[\log p_{\theta}(x_i)] \\    &amp;=\mathbb{E}_{q_{\phi}(z_i)}[        \frac{\log p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] -        \mathbb{E}_{q_{\phi}(z_i)}[            \frac{\log p_{\theta}(z_i|x_i)}{q_{\phi}(z_i)}] \\    &amp;=\mathbb{E}_{q_{\phi}(z_i)}[        \frac{\log p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] +        KL(q_{\phi}(z_i)||p_{\theta}(z_i|x_i)) \\    &amp;\ge \mathbb{E}_{q_{\phi}(z_i)}[        \frac{\log p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] \\    &amp;= ELBO(x_i, z_i, \theta, \phi)\end{aligned}\]</span></p><p>这时，我们可以看到，当<span class="math inline">\(KL(q_{\phi}(z_i)||p_{\theta}(z_i|x_i))=0\)</span>，即<span class="math inline">\(q_{\phi}(z_i)=p_{\theta}(z_i|x_i)\)</span>时，ELBO等于对数似然。</p><blockquote><p>基于Jensen不等式的推导：</p><p><span class="math display">\[\begin{aligned}    \log p_{\theta}(x_i)&amp;=\sum_{z_i}\log p_{\theta}(x_i,z_i) \\    &amp;=\sum_{z_i}\log q_{\phi}(z_i)[        \frac{p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] \\    &amp;\ge \sum_{z_i}q_{\phi}(z_i)\log [        \frac{p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] \\    &amp;= \mathbb{E}_{q_{\phi}(z_i)}[\frac{\log p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] \\    &amp;= ELBO(x_i, z_i, \theta, \phi)\end{aligned}\]</span></p><p>这里使用的jensen不等式是：如果<span class="math inline">\(f\)</span>是一个凸函数，则有<span class="math inline">\(f(\mathbb{E}(X))\le\mathbb{E}(f(X))\)</span>，等号成立当且仅当随机变量<span class="math inline">\(X\)</span>是个常数随机变量。对数函数是一个上凸函数，所以结论反过来即可。</p><p>根据上面的例子，我们知道当且仅当下面的条件成立的时候，ELBO和对数似然相等，即：</p><p><span class="math display">\[ \frac{p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}=c \]</span></p><p>又因为<span class="math inline">\(\sum_z{q_{\phi}(z)}=1\)</span>，得到：</p><p><span class="math display">\[\begin{aligned}    q_{\phi}(z_i)&amp;=\frac{p_{\theta}(x_i,z_i)}{c} \\    &amp;=\frac{p_{\theta}(x_i,z_i)}{c\sum_z{q_{\phi}(z)}} \\    &amp;=\frac{p_{\theta}(x_i,z_i)}{c\sum_z{\frac{p_\theta(x_i,z_i)}{c}}} \\    &amp;=\frac{p_{\theta}(x_i,z_i)}{\sum_z{p_\theta(x_i,z_i)}} \\    &amp;=\frac{p_{\theta}(x_i,z_i)}{p_\theta(x_i)} \\    &amp;=p_{\theta}(z_i|x_i)\end{aligned}\]</span></p><p>我们可以看到，基于Jensen的过程和基于KL散度的过程是殊途同归的。</p></blockquote><p>根据上面的公式，我们可以给出一个启发式的想法：</p><ol type="1"><li><p>首先我们求出在当前<span class="math inline">\(\theta_1\)</span>下的后验分布<span class="math inline">\(p_{\theta_1}(z_i|x_i)\)</span>，将其作为变分分布<span class="math inline">\(q_{\phi}(z_i)\)</span>，则此时<span class="math inline">\(ELBO_1\)</span>就是当前<span class="math inline">\(\theta_1\)</span>下的对数似然。</p></li><li><p>我们固定变分分布，改变<span class="math inline">\(\theta\)</span>来最大化<span class="math inline">\(ELBO\)</span>，得到新的<span class="math inline">\(\theta_2\)</span>和<span class="math inline">\(ELBO_2\)</span>。</p><p>注意，当前<span class="math inline">\(\theta_2\)</span>下对应的对数似然一定是大于<span class="math inline">\(\theta_1\)</span>的对数似然的。因为<span class="math inline">\(\theta_2\)</span>的对数似然一定是大于等于<span class="math inline">\(ELBO_2\)</span>（不管变分分布是什么，ELOB都小于等于对数似然）；而<span class="math inline">\(ELBO_2\)</span>一定大于<span class="math inline">\(ELBO_1\)</span>（最大化操作保证）；<span class="math inline">\(ELBO_1\)</span>就是<span class="math inline">\(\theta_1\)</span>下的对数似然。所以上述操作保证了<span class="math inline">\(\theta\)</span>的变化一直在使其对应的对数似然提高的。</p></li></ol><p>由此，我们得到了EM算法。</p><blockquote><p>以上过程实际上证明了EM算法是一直在使对数似然函数值变大的。而很容易也知道，对数似然函数是有上界的（一定不会大于0），则可知<strong>EM算法一定收敛到一个稳定点</strong>。</p></blockquote><p>这里最大化ELBO的步骤还可以进一步简化一下：</p><p><span class="math display">\[\begin{aligned}    ELBO(x_i, z_i, \theta, \phi)    &amp;=\mathbb{E}_{q_{\phi}(z_i)}[        \frac{\log p_{\theta}(x_i,z_i)}{q_{\phi}(z_i)}] \\    &amp;=\mathbb{E}_{q_{\phi}(z_i)}[        \log p_{\theta}(x_i,z_i)]+H(q_{\phi}(z_i))\end{aligned}\]</span></p><p>注意到，后面变分分布的熵不和<span class="math inline">\(\theta\)</span>有关，所以我们寻找最大化<span class="math inline">\(\theta\)</span>的ELBO的时候其没有贡献，可以去掉。另外将所有样本都考虑到：</p><p><span class="math display">\[\hat{\theta}=\argmax_{\theta}\sum_i^N\mathbb{E}_{q_{\phi}(z_i)}[\log p_{\theta}(x_i,z_i)]\]</span></p><p>所以，我们求解的实际上是对数联合分布的期望，所以EM算法的第一个步骤是Expectation（期望）。求出来后，改变<span class="math inline">\(\theta\)</span>来最大化这个期望，即Maximization（最大化）。</p><blockquote><p>通过上面的推导，我们知道EM算法和VI（variational inference，变分推断）真的很像，其不同点在于：</p><p>VI将变分分布也参数化，也需要通过最大化ELBO来得到的，此时是固定<span class="math inline">\(\theta\)</span>改变<span class="math inline">\(\phi\)</span>来实现的，这时候使ELBO最大（达到对数似然）的变分分布正好就是后验分布。</p><p>EM则需要显式的知道后验分布怎么算，直接算出来。</p><p>另外，VI使用的ELBO，而EM使用更加简化的对数联合概率期望。</p></blockquote><h1 id="算法流程">算法流程</h1><ul><li>输入数据：<span class="math inline">\(x=(x_1, x_2, \cdots, x_N)\)</span></li><li>隐变量：<span class="math inline">\(z_i\)</span></li><li>最大迭代次数：<span class="math inline">\(J\)</span></li></ul><ol type="1"><li><p>初始化模型参数<span class="math inline">\(\theta_0\)</span>；</p></li><li><p>开始EM算法迭代：</p><ol type="a"><li>E step：计算后验分布作为变分分布，并由此计算对数联合分布的期望<span class="math inline">\(\sum_i^N\mathbb{E}_{p_{\theta_i}(z_i|x_i)}[\log p_{\theta_i}(x_i,z_i)]\)</span>。</li><li>M step：最大化上面的期望，得到新的参数估计<span class="math inline">\(\theta_{i+1}\)</span>。</li><li>如果<span class="math inline">\(\theta_{i+1}\)</span>对应的对数联合分布期望变化不大或达到设定的最大迭代次数<span class="math inline">\(J\)</span>，则输出此参数，否则回到a。</li></ol></li></ol><blockquote><p>在一些时候，我们也称得到后验分布的过程是E step，计算对数联合分布期望并最大化它的过程是M step。这时候更加注重强调隐变量<span class="math inline">\(z\)</span>的作用。</p></blockquote><h2 id="注意事项">注意事项</h2><p>EM算法对于初值是非常敏感的，这一点上和Kmeans算法特别相似。为了解决这个问题，有下面的一些研究：</p><ol type="1"><li>Blömer J, Bujna K. Simple methods for initializing the EM algorithm for Gaussian mixture models[J]. CoRR, 2013.</li><li>Chen F. An Improved EM algorithm[J]. arXiv preprint arXiv:1305.0626, 2013.</li><li>Kwedlo W. (2013) A New Method for Random Initialization of the EM Algorithm for Multivariate Gaussian Mixture Learning. In: Burduk R., Jackowski K., Kurzynski M., Wozniak M., Zolnierek A. (eds) Proceedings of the 8th International Conference on Computer Recognition Systems CORES 2013. Advances in Intelligent Systems and Computing, vol 226. Springer, Heidelberg.</li></ol><p>有兴趣的可以拜读一下。</p><blockquote><p>来自<a href="https://zhuanlan.zhihu.com/p/40991784" target="_blank" rel="noopener">Microstrong的知乎</a>。</p></blockquote><h1 id="高斯混合模型gmm">高斯混合模型（GMM）</h1><p>GMM是一个概率模型，其认为数据来自多个高斯分布的混合，其可以表示为：</p><p><span class="math display">\[p(x)=\sum_{i=1}^C{f(x|z=i)g(z)}\]</span></p><p>其中<span class="math inline">\(z\)</span>服从的是一个Categorical distribution的随机变量，分类数量为<span class="math inline">\(C\)</span>，表示有C个高斯分布。<span class="math inline">\(f(x|z=i)\)</span>是第<span class="math inline">\(i\)</span>个高斯分布的密度函数。我们的样本是<span class="math inline">\(x_i\)</span>是<span class="math inline">\(x\)</span>的采样。</p><p>这是一个典型的具有隐变量的问题，非常适合使用EM算法来解决。</p><h2 id="公式推导">公式推导</h2><p>首先，我们需要估计的参数就是每个高斯分布的参数和分类分布的参数<span class="math inline">\(\theta=\{\mu_j,\sigma_j,\gamma_j|j=1,\dots,C\}\)</span>：</p><p><span class="math display">\[g(z=j)=\gamma_j,\quad\sum_j\gamma_j=1\]</span> <span class="math display">\[f(x|z=j)=\frac{1}{\sqrt{2\pi}\sigma_j}\exp(-\frac{(x-\mu_j)^2}{2\sigma_j^2})\]</span></p><p>对于E step，关键在于知道<span class="math inline">\(p_{\theta}(z_i|x_i)\)</span>。这个可以通过贝叶斯公式得到：</p><p><span class="math display">\[\begin{aligned}w_{ij}=q_{\phi}(z_i=j|x_i)=p_{\theta}(z_i=j|x_i)&amp;=\frac{p_{\theta}(x_i|z_i=j)\gamma_j}{\sum_{j}p_{\theta}(x_i|z_i=j)\gamma_j}\end{aligned}\]</span></p><p>之后，我们计算对数联合概率期望：</p><p><span class="math display">\[\begin{aligned}&amp;\sum_i^N\mathbb{E}_{p_{\theta}(z_i|x_i)}[\log p_{\theta}(x_i,z_i)] \\=\quad&amp;\sum_i^N\mathbb{E}_{p_{\theta}(z_i|x_i)}[\log p_{\theta}(x_i|z_i)g(z_i)] \\=\quad&amp;\sum_i^N\sum_{j=1}^C[\log (p_{\theta}(x_i|z_i=j)\gamma_j)p_{\theta}(z_i=j|x_i)] \\=\quad&amp;\sum_i^N\sum_{j=1}^Cw_{ij}\times(\log\gamma_j +[-\log(\sqrt{2\pi}\sigma_j)-\frac{(x_i-\mu_j)^2}{2\sigma^2_j}])\end{aligned}\]</span></p><p>注意到，尽管<span class="math inline">\(p_{\theta}(z_i|x_i)\)</span>也有参数下标，但这里其实表示的是变分分布的位置，所以在下面的M step中是不动的，使用<span class="math inline">\(w_{ij}\)</span>来表示。</p><p>对于M step，我们可以通过微积分求极值的方式得到参数的估计。首先是分类分布的参数：</p><p><span class="math display">\[\gamma_j=\frac{\sum_{i=1}^Nw_{ij}}{\sum_{j=1}^C\sum_{i=1}^Nw_{ij}}\]</span></p><blockquote><p>注意到，这里有约束条件<span class="math inline">\(\sum_j\gamma_j=1\)</span>，利用<span class="math inline">\(\gamma_C=1-\sum_{j=1}^{C-1}\gamma_j\)</span>或拉格朗日乘子法可以得到上面的结论。</p><p>令<span class="math inline">\(W_j=\sum_{i=1}^Nw_{ij}\)</span>，则我们要最大化的其实是</p><p><span class="math display">\[\sum_{j=1}^CW_j\log\gamma_j\]</span> 这是一个交叉熵。</p><p>我们首先使用<span class="math inline">\(\gamma_C=1-\sum_{j=1}^{C-1}\gamma_j\)</span>，然后求导（这里不需加入<span class="math inline">\(\gt0\)</span>的约束了，<span class="math inline">\(\log\)</span>的定义域决定了不能<span class="math inline">\(\le0\)</span>）：</p><p><span class="math display">\[\begin{aligned}\frac{\partial \sum_{j=1}^{C-1}[W_j\log\gamma_j]+W_C\log(1-\sum_i^{C-1}\gamma_i)}{\partial\gamma_j}&amp;=\frac{W_j}{\gamma_j}-\frac{W_C}{1-\sum_{i=1}^{C-1}\gamma_j}\end{aligned}\]</span> 其中<span class="math inline">\(j=1,\cdots,C-1\)</span>。然后令其等于0，得到： <span class="math display">\[\frac{W_j}{W_C}=\frac{\gamma_j}{\gamma_C},\quad j=1,\cdots,C-1\]</span> 其中<span class="math inline">\(\gamma_C=1-\sum_{i=1}^{C-1}\gamma_j\)</span>。我们将以上<span class="math inline">\(C-1\)</span>个式子加总，再加<span class="math inline">\(1\)</span>，得到 <span class="math display">\[\frac{\sum_jW_j}{W_C}=\frac{1}{\gamma_C}\]</span> 得到<span class="math inline">\(\gamma_C=\frac{W_C}{\sum_jW_j}\)</span>，进而得到<span class="math inline">\(\gamma_j=\frac{W_j}{\sum_jW_j}\)</span>。</p><p>如果使用拉格朗日乘子法，则是最大化下面的式子</p><p><span class="math display">\[\sum_{j=1}^CW_j\log\gamma_j+\lambda(\sum_{j=1}^C\gamma_j-1)\]</span></p><p>求导得到：</p><p><span class="math display">\[\begin{aligned}\frac{W_j}{\gamma_j}+\lambda&amp;=0 \\\sum_{j=1}^C\gamma_j&amp;=1\end{aligned}\]</span></p><p>继续</p><p><span class="math display">\[\begin{aligned}    \gamma_j=-\frac{W_j}{\lambda} \\    -\frac{\sum_jW_j}{\lambda}=1 \\    \lambda=-\sum_jW_j \\    \gamma_j=\frac{W_j}{\sum_jW_j}\end{aligned}\]</span></p><p>得到了相同的结果。</p></blockquote><p>接下来是均值：</p><p><span class="math display">\[\hat{\mu_j}=\frac{\sum_i{w_{ij}x_i}}{\sum_i{w_{ij}}}\]</span></p><p>可以看到，这里的均值的估计就是以后验概率为权重的样本均值。</p><p>然后是方差的估计，这里的估计要分为两种情况：</p><ul><li><p>组间方差不等：</p><p><span class="math display">\[\hat{\sigma_j}=\frac{\sum_i{w_{ij}(x_j-\hat{\mu_j})^2}}  {\sum_i{w_{ij}}}\]</span></p></li><li><p>组间方差相等： <span class="math display">\[\hat{\sigma}=  \frac{\sum_j\sum_i{w_{ij}(x_j-\hat{\mu_j})^2}}  {\sum_j\sum_i{w_{ij}}}\]</span></p></li></ul><h2 id="代码实现">代码实现</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># E step</span><span class="token keyword">def</span> <span class="token function">_e_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> gammas_<span class="token punctuation">,</span> mus_<span class="token punctuation">,</span> sigmas_<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    The Expectation step.    Compute the posterior distribution and expectation of joint        distribution.    """</span>    logp <span class="token operator">=</span> ss<span class="token punctuation">.</span>norm<span class="token punctuation">.</span>logpdf<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span><span class="token punctuation">,</span> mus_<span class="token punctuation">,</span> sigmas_<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># p(x|z)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>gamma_type <span class="token operator">==</span> <span class="token string">"full"</span><span class="token punctuation">:</span>        logp <span class="token operator">=</span> logp <span class="token operator">+</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>gammas_<span class="token punctuation">)</span>    logpsum <span class="token operator">=</span> logsumexp<span class="token punctuation">(</span>logp<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    logp_norm <span class="token operator">=</span> logp <span class="token operator">-</span> logpsum<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span>               <span class="token comment" spellcheck="true"># p(z|x)</span>    <span class="token keyword">return</span> logp_norm<span class="token punctuation">,</span> <span class="token punctuation">(</span>logp <span class="token operator">*</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logp_norm<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># M step</span><span class="token keyword">def</span> <span class="token function">_m_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> logp<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    The Maximization step.    Maximize the expectation of joint distribution and compute the new        parameters.    """</span>    <span class="token comment" spellcheck="true"># 1. prepare</span>    p <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>logp<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># get rid of having NaN</span>    psum <span class="token operator">=</span> p<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">10</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>finfo<span class="token punctuation">(</span>p<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">.</span>eps    <span class="token comment" spellcheck="true"># 2. compute the parameters of categorical distribution</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>gamma_type <span class="token operator">==</span> <span class="token string">"full"</span><span class="token punctuation">:</span>        gammas_ <span class="token operator">=</span> psum <span class="token operator">/</span> psum<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        gammas_ <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_components<span class="token punctuation">)</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>n_components    <span class="token comment" spellcheck="true"># 3. compute the mean of gaussian components</span>    mus_ <span class="token operator">=</span> <span class="token punctuation">(</span>p <span class="token operator">*</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> psum    <span class="token comment" spellcheck="true"># 4. compute the stdandard deviations of gaussian components</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>sigma_type <span class="token operator">==</span> <span class="token string">"full"</span><span class="token punctuation">:</span>        sigmas2_ <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span> <span class="token operator">-</span> mus_<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">*</span> p<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> psum        sigmas_ <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sigmas2_<span class="token punctuation">)</span>    <span class="token keyword">elif</span> self<span class="token punctuation">.</span>sigma_type <span class="token operator">==</span> <span class="token string">"equal"</span><span class="token punctuation">:</span>        sigmas2_ <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">]</span> <span class="token operator">-</span> mus_<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">*</span> p<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> psum<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>        sigmas1_ <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sigmas2_<span class="token punctuation">)</span>        sigmas_ <span class="token operator">=</span> np<span class="token punctuation">.</span>full<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_components<span class="token punctuation">,</span> sigmas1_<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        sigmas_ <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmas    <span class="token keyword">return</span> gammas_<span class="token punctuation">,</span> mus_<span class="token punctuation">,</span> sigmas_<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="em算法的收敛性">EM算法的收敛性</h1><ul><li>在上面推导的部分，我其实已经证明了，EM算法一定会收敛到一个稳定点。<a href="https://www.cnblogs.com/pinard/p/6912636.html" target="_blank" rel="noopener">刘建平Pinard的博客</a>也有一个证明，大家可以一起看一下。</li><li>EM算法并不能保证收敛到极大似然解，其很有可能陷入局部最优值。这很大程度上取决了初始值的设置。</li></ul><h1 id="参考">参考</h1><ul><li><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">Wiki</a></li><li><a href="https://www.cnblogs.com/pinard/p/6912636.html" target="_blank" rel="noopener">EM算法原理总结-刘建平Pinard</a></li><li><a href="https://zhuanlan.zhihu.com/p/40991784" target="_blank" rel="noopener">EM算法详解-Microstrong</a></li><li><a href="https://www.cnblogs.com/mindpuzzle/archive/2013/04/05/2998746.html" target="_blank" rel="noopener">EM算法学习(Expectation Maximization Algorithm)-MindPuzzle</a></li><li><a href="https://link.zhihu.com/?target=http%3A//web.mit.edu/6.435/www/Dempster77.pdf">Maximum Likelihood from Incomplete Data via the EM Algorithm（原文）</a></li><li><a href="https://xuewen.cnki.net/CJFD-BJDZ198703000.html" target="_blank" rel="noopener">EM算法的收敛性</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Methods </category>
          
      </categories>
      
      
        <tags>
            
            <tag> EM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-Integrated Gradients-2017</title>
      <link href="/2020/10/15/paper/dl/paper-integratedgradients-2017/"/>
      <url>/2020/10/15/paper/dl/paper-integratedgradients-2017/</url>
      
        <content type="html"><![CDATA[<h1 id="axiomatic-attribution-for-deep-networks">Axiomatic Attribution for Deep Networks</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/ankurtaly/Attributions" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><p>研究的问题是<strong>将NN的输出归因于其输入特征</strong>。</p><p>定义1：假设有function <span class="math inline">\(F:\mathbb{R}^n\to[0,1]\)</span>是一个NN，其输入是<span class="math inline">\(x=(x_1,\dots,x_n)\)</span>，预测在<span class="math inline">\(x\)</span>上相对于基线输入<span class="math inline">\(x'\)</span>的attribution是<span class="math inline">\(A_F(x,x')=(a_1,\dots,a_n)\in\mathbb{R}^n\)</span>，其中<span class="math inline">\(a_i\)</span>是<span class="math inline">\(x_i\)</span>对于预测<span class="math inline">\(F(x)\)</span>的贡献。</p><p>该问题已经在许多研究中被讨论过了【Baehrens et al., 2010; Simonyan et al., 2013;Shrikumar et al., 2016; Binder et al., 2016; Springenberg et al., 2014】。</p><p>这个工作的意义在于能够更加理解NN的行为，从而使得我们可能进一步对其进行改进。</p><h2 id="two-fundamental-axioms">Two Fundamental Axioms</h2><ul><li><p><strong>Sensitivity</strong>。</p><p>一个attribution方法满足sensitivity即：<strong>如果某个feature的输入和其baseline产生了不同的预测，则此feature应该被给与非0的attribution</strong>。</p><p>梯度违背了sensitivity：比如有下面的网络<span class="math inline">\(f(x)=1-ReLU(1-x)\)</span>，baseline是<span class="math inline">\(x=0\)</span>，输入是<span class="math inline">\(x=2\)</span>，则函数从<span class="math inline">\(0\)</span>变为<span class="math inline">\(1\)</span>，但梯度在<span class="math inline">\(x=2\)</span>时是<span class="math inline">\(0\)</span>。之所以出现这种情况，是因为梯度可能在input的那一点上是“平坦的”【Shrikumar et al., 2016】。这可能导致一些问题（fig2中的fireboat）。</p><p>已有的方法中，Deconvolution和guided back-propagation违反了sensitivity。DeepLift和LRP通过增加baseline和离散积分来避免违反sensitivity，但可惜的是，这些方法违反了另外一条重要的公理。</p></li><li><p><strong>Implementation Invariance</strong></p><p>如果两个网络对于所有的输入都得到相同的输出，则称这两个网络是<strong>functionally equivalent</strong>。“我们”认为attribution方法需要满足Implementation Invariance，即：<strong>对于两个functionally equivalent的NN，attribution需要相同</strong>。</p><p>Gradients是满足此性质的。</p><p>DeepLift和LRP之所以不满足此性质，是因为其使用的是离散梯度，而离散梯度并不符合链式法则，从而其得到不是真实的梯度，而真实的梯度是满足此性质的，所以其离散梯度反而不满足了。</p></li></ul><h3 id="相关工作">相关工作</h3><p>最早的工作之一是【Ribeiro et al., 2016a;b】，其试图使用一个简单的、可解释的模型在局部模仿NN，从而对其进行解释。这个思路无法实现Sensitivity，如果在局部是非常flat的，则这个方法会失效。而且该方法对于像图像这样dense的数据，计算量非常大。</p><p>注意力机制【Bahdanau et al., 2014】被期望能够有解释的能力，但就像LSTM中的门控单元一样，整个网络是复杂的，网络的其他部分可能会和注意力机制部分相互影响，单单考虑注意力机制可能并不能了解到全部的信息。</p><p>之前的一些基于扰动的方法【Samek et al., 2015】的缺陷在于：单纯对单个变量进行扰动对于NN这样复杂的模型并不适合，比如某个很重要的特征在被扰动的时候可能并不会导致预测性能的大量下降，因为其他特征可能会对其进行补偿。</p><p>还有一类方法需要借助人类为图像上的对象绘制标注框，然后计算标注框中像素的百分比。通常来说，图片上的对象是对预测最关键的内容，但在某些情况下也有可能是反的，背景反而提供了更多的信息。（fig2中的蝴蝶和卷心菜）</p><h2 id="methods">Methods</h2><p>直观上，Integrated Gradients就是将Gradients的Implementation Invariance和DeepLift、LRP的Sensitivity结合在一起。</p><p>这里假设样本<span class="math inline">\(x\in\mathbb{R}^n\)</span>，baseline是<span class="math inline">\(x'\in\mathbb{R}^n\)</span>（这个baseline在图像上可以black image，在text上就是zero embedding vector等）。然后，我们计算从baseline到<span class="math inline">\(x\)</span>的直线路径上的梯度积分：</p><p><span class="math display">\[IntegratedGrads_i(x)=(x_i-x_i')\times\int_{\alpha=0}^1{\frac{\partial F(x'+\alpha\times(x-x'))}{\partial x_i}}\]</span></p><h3 id="integrated-gradient的性质">Integrated Gradient的性质</h3><ul><li><p>Completeness：</p><p>即attributions加起来等于<span class="math inline">\(F\)</span>在<span class="math inline">\(x\)</span>和基线<span class="math inline">\(x'\)</span>的输出的差，数学语言描述为：</p><p>如果<span class="math inline">\(F:\mathbb{R}^n\to\mathbb{R}\)</span>是几乎处处可微的，则<span class="math display">\[\sum_{i=1}^n  {IntegratedGrads_i(x)}=F(x)-F(x')\]</span></p><blockquote><p>我们首先需要回顾一下“方向导数”的定义：<span class="math display">\[F_{\overrightarrow{r}}'(x)=\lim_{\Delta\alpha\to0}\frac{F(x+\Delta\alpha\overrightarrow{r})-F(x)}{\Delta\alpha}=F'(x)\cdot\overrightarrow{r}\]</span> 其中<span class="math inline">\(F'(x)\)</span>是<span class="math inline">\(F\)</span>在<span class="math inline">\(x\)</span>上的梯度。现在我们对该定义进行一定的扩展，定义函数： <span class="math display">\[F_{\overrightarrow{r},x}(\alpha)=F(x+\alpha\overrightarrow{r})\]</span> 注意，这是一个一元函数，所以其导函数可以写成： <span class="math display">\[F_{\overrightarrow{r},x}'(\alpha)=\frac{dF_{\overrightarrow{r},x}}{d\alpha}=F'(x+\alpha\overrightarrow{r})\cdot\overrightarrow{r}\]</span> “方向导数”是该导函数在<span class="math inline">\(0\)</span>时的值。 然后我们把上面的性质1的左侧写开： <span class="math display">\[\begin{aligned}  \sum_{i=1}^n{IntegratedGrads_i(x)}&amp;=  \int_{\alpha=0}^n{\sum_{i=1}^n{(x_i-x_i')F_i(x'+\alpha\times(x-x'))}d\alpha} \\  &amp;=\int_{\alpha=0}^n{F'(x'+\alpha\times(x-x'))\cdot(x-x')d\alpha}\end{aligned}\]</span> 可以发现积分式内就是上面的一元函数的导函数，所以直接使用微积分基本定理，得到结果。</p></blockquote><p>如果满足这个性质，则我们可以选择一个baseline使得其预测基本接近<span class="math inline">\(0\)</span>（比如在图像分类中的black image），这样attributions的和就等于该类的输出。</p></li><li><p>Completeness满足可以推出Sensitivity满足。</p></li><li><p>因为Integrated Gradients的计算只是基于梯度的计算，梯度满足Implementation Invariance，所以Integrated Gradients也满足此性质。</p></li></ul><h3 id="integrated-gradients是唯一可选的">Integrated Gradients是唯一可选的</h3><p>首先，我们来扩展Integrated Gradients，我们不再使用直线上的路径积分（如fig1所示）。</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-15-14-02.png"><br></p><p>令<span class="math inline">\(\gamma=(\gamma_1,\dots,\gamma_n):[0,1]\to\mathbb{R}^n\)</span>是一个光滑函数（即一个path），并且满足<span class="math inline">\(\gamma(0)=x',\gamma(1)=x\)</span>。我们有下面的path integrate：</p><p><span class="math display">\[PathIntegratedGrads_i^{\gamma}(x)=\int_{\alpha=0}^1{\frac{\partial F(\gamma(\alpha))}{\partial\gamma_i(\alpha)}\frac{\partial\gamma_i(\alpha)}{\partial\alpha}d\alpha}\]</span></p><p>当<span class="math inline">\(\gamma(\alpha)=x'+\alpha\times(x-x')\)</span>时，我们得到了Integrated Gradients。</p><p><strong>可以知道：path method是满足Implementation Invariance的（只是利用了梯度）；其也是满足Completeness，从而满足Sensitivity。</strong></p><p>有意思的是，path method是满足另外一些性质的唯一的方法（证明见【Friedman, 2004】）：</p><ul><li>Sensitivity（b），如果NN不依赖于某个变量，则在该变量上的attribution是0。</li><li>Linearity，第三个NN由前两个NNs线性组合得到<span class="math inline">\(a\times f_1+b\times f_2\)</span>，则第三个NN的attributions是这两个NNs的attributions的线性组合，权重是<span class="math inline">\(a\)</span>和<span class="math inline">\(b\)</span>。</li><li><strong>Path methods是唯一满足Implementation Invariance、Sensitivity（b）、Linearity、Completness的attribution方法</strong>。</li></ul><blockquote><p>path integrated gradients方法很早就已经在经济学领域使用。</p></blockquote><p>接下来，我们来叙述为什么使用直线路径是更合理的。</p><ul><li><p>计算的简单。</p></li><li><p>保持对称性。</p><p>两个变量相对于函数<span class="math inline">\(F\)</span>满足对称性即：<span class="math inline">\(F(x,y)=F(y,x),\quad \forall x,y\)</span>。<strong>一个attribution方法是对称保持的，即对称变量如果有相同的输入和基线，则应该有相同的attribution值</strong>。</p><p>可以证明：</p><p><strong>Integrated Gradients是唯一的保持对称的path method。</strong></p><blockquote><p>实际上，如果我们能够对多条path的结果进行平均，则该结果也是保持对称的，这一类方法在经济学领域也得到了广泛应用。但这在深度学习领域碰到的一个问题是：计算量太大。</p></blockquote></li></ul><h3 id="实现">实现</h3><ul><li><p>如何选择baseline：<strong>选择的baseline应该尽量保证其输出接近0</strong>。</p><p>当然，还可以有更好的选择。比如对于图像来说，black image和noise image其输出都是接近0的，但使用black image可能更加容易检测出边缘的特征。所以我们可以根据我们的目的来选择使用baseline。</p></li><li><p>如何计算：<strong>可以通过求和有效的来逼近计算积分。</strong></p><p><span class="math display">\[IntegratedGrads_i^{approx}(x)=(x_i-x_i')\times\sum_{k=1}^m{\frac{\partial F(x'+\frac{k}{m}\times(x-x'))}{\partial x_i}\times\frac{1}{m}}\]</span></p><p>在实验中发现，<span class="math inline">\(m\in[20,300]\)</span>就足够了。可以通过检查得到的attributions的和与输入和基线的预测差的差距来判断<span class="math inline">\(m\)</span>是否合适。</p></li></ul><h2 id="results">Results</h2><h3 id="图像分类网络">图像分类网络</h3><p>这个网络是GoogleNet架构，在ImageNet object recognition datasets【Russakovsky et al., 2015】上进行的训练。使用Integrated Gradients计算attributions，其中只计算其中分类概率最高的那个类，使用的baseline是black image。</p><p>结果如下，其是在color channels上进行了聚合。可以看到，相比于gradients，其效果更好。</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-16-47-24.png"><br></p><h3 id="糖尿病视网膜病变预测">糖尿病视网膜病变预测</h3><p>使用的模型是【Gulshan et al., 2016】中提出的，baseline依然是black image，结果如下所示：</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-18-40-39.png"><br></p><h3 id="问题分类">问题分类</h3><p>这里处理的模型是预测我们想要的问题的答案是哪个类型。比如：我们想要的答案是yes/no、或者是时间等等。这里使用的模型是【Kim, 2014】的模型，其训练在WikiTableQuestions数据集【Pasupat &amp; Liang, 2015】上。这里使用的baseline是zero embedding vector。</p><p>下面的结果显示，Integrated Gradients确实找到了那个关键词。</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-18-52-10.png"><br></p><h3 id="机器翻译">机器翻译</h3><p>使用的模型是LSTM-based Neural Machine Translation System【Wu et al., 2016】。baseline是zero embedding vector。结果如下所示：</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-19-07-43.png"><br></p><h3 id="化学模型">化学模型</h3><p>该模型基于分子GNN架构【Kearnes et al., 2016】，能够针对给定的分子预测是否激活了特定靶点（蛋白、酶）。</p><p><img src="/2020/10/15/paper/dl/paper-integratedgradients-2017/paper-IntegratedGradients-2017_2020-10-16-19-10-48.png"><br></p><p>模型显示出有化学键相连的原子贡献了46%，而没有键相连的只贡献了3%。</p><h3 id="识别退化特征">识别退化特征</h3><p>将Integrated Gradients方法应用到了W1N2模型【Kearnes et al., 2016】上，发现了其模型中不合理的地方。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Interpreting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-使用CNN对癌症进行分类-2020</title>
      <link href="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/"/>
      <url>/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/</url>
      
        <content type="html"><![CDATA[<h1 id="convolutional-neural-network-models-for-cancer-type-prediction-based-on-gene-expression">Convolutional neural network models for cancer type prediction based on gene expression</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/chenlabgccri/CancerTypePrediction" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>癌症是人类的第二大死因，大量的研究旨在能够提高癌症诊断和治疗，癌种分类旨在通过现有的数据来学习一个分类器去完成自动化的癌症预测分类过程。</p></li><li><p>DL是人工智能的一个分支，配合如TCGA【7】这样的大规模测序数据，其得到了极大的发展：</p><ul><li>【8】使用6703 tumor和6402 normal samples训练了一个MLP</li><li>【9】使用一个CNN model来进行所有33类癌症的分类，并得到了超过95%的准确率；【10】则利用KNN算法，并结合试图遗传算法进行gene筛选，达到了90%的准确率，在31类分类上</li><li>【12】将genes分为两类：oncogenes和tumor suppressors来确定癌症状态；transcription factors来将癌症分类到起始的组织。该研究在10-CV上得到了97.8%的ACC</li><li>DeepCNA【13】是一个基于CNN的分类器，使用的是来自COSMICS【14】的copy number aberrations（CNAs）数据和来自两个人类细胞系的HiC数据，在25类癌症分类上达到了60%的效果</li></ul><p>虽然以上算法都得到了非常好的精度，但其都没有或很少讨论如何去除组织差异所带来的影响。基于以上研究得到的biomarkers我们无法确定是tissue-specific genes还是cancer-type-specific genes。</p><p>还有“我们”在之前的一项研究【15】中提出了一个基于AEs的模型——GSAE，其可以将功能通路或功能基因集的信息进行提取并得到可解释的结果。“我们”成功应用GSAE进行乳腺癌亚型分类。</p></li><li><p>本研究试图来探索不同类型的CNNs model进行癌症分类的效果，系统的研究了不同容量的卷积核的效果。此外，本研究还提出了一种新的模型解释性方法来筛选关键基因。</p></li></ol><h2 id="methods">Methods</h2><h3 id="数据集">数据集</h3><ol type="1"><li>使用TCGAbiolinks【17】 package下载pan-cancer RNA-seq数据，其中包括10340个33类癌症样本和713个正常组织样本。</li><li>得到<span class="math inline">\(\log_2(FPKM+1)\)</span>。</li><li>在所有样本上，使用mean &lt; 0.5和std &lt; 0.8删除低信息量的genes，最终得到7091个genes。</li><li>另外还收集了964个BRCA样本的PAM50亚型信息，用于验证模型的鲁棒性。</li><li>为了验证模型的鲁棒性，我们为每个gene加入了高斯噪声（<span class="math inline">\(N(0,k\mu)\)</span>，其中<span class="math inline">\(\mu_i\)</span>是第<span class="math inline">\(i\)</span>个gene的平均表达量，<span class="math inline">\(k\in\mathcal{U}(0,5)\)</span>）。最后如果得到的gene的表达量小于0，将其置为0。</li></ol><h3 id="cnn模型设计">CNN模型设计</h3><ul><li>本研究不再研究gene排序所带来的影响，所有的gene将被排序在一个特定的顺序上。</li><li>本研究将着重研究CNN kernels的设计来学习genes间相关性的能力。</li><li>本研究中我们将只使用一层的CNN，shallow model可能在癌症分类这样的问题上已经是足够的，更深的模型在生物学数据上可能并不会带来性能的提示【18】，而且这也减轻了过拟合的风险【19,20】，提高了训练效率。</li></ul><p><strong>矢量化输入的CNN</strong></p><p>接受的是一维向量，使用1-D CNN，之后进行一次maxpooling，然后接一个FC layer和softmax layer进行预测。</p><p>因为这里我们并不确定相邻的gene间是否存在相关性，所以这里将stride设置的和kernel size一样大，从而提取一个kernel的整体信息。</p><p><strong>矩阵输入的CNN</strong></p><p>类似【9】，将样本reshape成2-D matrix，使用2-D CNN提取信息。同样是CNN-maxpooing-fc-softmax的架构。这称为2D-Vanilla-CNN。</p><p><strong>矩阵输入的CNN，但使用1D kernel</strong></p><p>这里使用两个1-D CNN（一个vertically、一个horizontally）来对matrix输入提取特征，之后再将两个的结果concat进入fc layer，可见后面的fig1c。</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-14-15-10-14.png"><br></p><p>另外，“我们”还实现了【9】中的model，称为2D-3layer-CNN，以便进行比较。</p><h3 id="cnn模型解释">CNN模型解释</h3><p>利用keras visualization package——kears-vis【22】的guided gradient saliency visualization方法，得到每个样本在每个gene、每类癌症上的重要性评分，然后在样本上进行平均，得到一个gene-effect matrix（<span class="math inline">\(7091\times 34\)</span>），然后将值归一化到<span class="math inline">\([0,1]\)</span>中。大于0.5的值被认为该gene是一个marker。</p><h2 id="results">Results</h2><h3 id="模型设置和超参数">模型设置和超参数</h3><ul><li><p>使用Keras实现。</p></li><li><p>1D-CNN的输入是gene按照其字母顺序排序得到的1D vector。</p></li><li><p>2D输入是以上vector被reshape成100 x 71的matrix。</p></li><li><p>4个最重要的超参数：kernel的数量和大小、stride、fc layer的nodes数量，展示在下面的table 1和2中，使用【25】中提供的Grid search方法进行挑选。</p></li><li><p>loss是cross entropy，Adam optimizer，epoch和batch size是50和128，early stop的patience是4，激活函数是ReLU。</p></li><li><p>进行训练时没有validation，early stop是利用的train进行的（提前使用8/2的train-validation分割来验证了，在10个epochs后基本就收敛了，而且没有过拟合，这个在fig2a中）。</p><p>可以看到【9】的模型的收敛是最慢的</p></li><li><p>将5-CV重复了6次，计算acc的均值和方差。</p><p>结果在fig2b中，1D-CNN、2D-Vanilla-CNN和2D-Hybrid-CNN分别是<span class="math inline">\(95.5\pm0.1\%\)</span>，<span class="math inline">\(94.87\pm0.04\%\)</span>，<span class="math inline">\(95.7\pm0.1\%\)</span>。</p></li></ul><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-10-07-37.png"><br></p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-10-08-04.png"><br></p><blockquote><p>这里的score是什么？</p></blockquote><h3 id="组织特异性的影响">组织特异性的影响</h3><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-10-54-56.png"><br></p><p>我们首先训练了两个模型：只使用tumor样本和只使用normal样本的1D-CNN。fig2中的混淆矩阵显示，两个模型所出现的错误分类显示出相似的组织特异性，<strong>即在解剖学上位置相近的组织分类直接更容易相互分错类</strong>，这意味着模型学习到组织特异性而不是癌症特异性的风险很大。</p><p>为了克服这个问题，策略是<strong>将normal的样本也加入其中，作为新的一类</strong>。结果显示（fig2b），预测acc相比33类分类，只有轻微的下降（1D-CNN、2D-Vanilla-CNN和2D-Hybrid-CNN分别是<span class="math inline">\(94.5\pm0.1\%\)</span>，<span class="math inline">\(93.9\pm0.6\%\)</span>，<span class="math inline">\(95.0\pm0.1\%\)</span>）。</p><p>进一步，分析了1D-CNN的micro-averaged precision-recall statistics（fig3b）。可以看到其中READ、CHOL、COAD等效果有比较大的差距。</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-11-01-22.png"><br></p><h3 id="探索cancer-marker-genes">探索cancer marker genes</h3><ul><li>探索了所有cancer types的saliency maps的gene-effect scores的分布，发现都服从power law（fig4a）。</li><li>凭借gene-effect scores逐步减少gene数量（0.5 -- 2090 genes，0.9 -- 91 genes），然后使用tSNE可视化（fig4b）。</li><li>之后使用scores &gt; 0.5进行后续分析，一共得到3683个markers（不重复的有2090个），平均每个癌症类型有108个（fig4c）。进一步比较每类得到的markers数量和分类精度，可知，<strong>在分类精度越小的癌症类别上，其筛选得到的变量越少</strong>。</li></ul><p>进一步，“我们”比较了normal markers（99）和BRCA markers（323）在normal vs others和BRCA vs others上的表达差异分布，发现确实存在差异（fig4d-e）。</p><p>在BRCA markers中，确实出现了诸如GATA3【26】和ESR1【27】等众所周知的makers，也发现了一些新的markers（GPRIN1、EFNB1、FABP4）（fig4f）。</p><p>接下来，“我们”对每一类得到的markers进行功能富集分析（MSigDB【28,29】），one-tailed Fisher's exact test（P &lt; 0.001）得到了32个相关功能，其中确实有许多的癌症相关功能（fig4g）。</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-13-06-37.png"><br><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-13-07-11.png"><br></p><h3 id="乳腺癌亚型预测">乳腺癌亚型预测</h3><p>预测4个亚型+normal样本，得到了88.3%的ACC。</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-13-08-57.png"><br></p><h2 id="discussion">Discussion</h2><p>我们进一步总结了这些模型的参数量和表现等等：</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-13-11-58.png"><br></p><p>可以看到，在基因组学上的模型，可能并不需要太过复杂，仅仅一层的1D-CNN就可以达到不错的效果，而且可能因为参数量的较少而使得其过拟合的风险大大降低。2D-Hybrid-CNN因为可以从两个方向来提取信息，所以其效果要略好一些。</p><p>2D-Vanilla-CNN虽然效果相似，但其参数量提高了5倍还多，而且有更多的需要调节的超参数。“我们”通过为输入添加不同比例的噪声来比较1D-CNN和2D-Vanillia-CNN的鲁棒性，结果如下：</p><p><img src="/2020/10/14/paper/omics/paper-cnn-clscancertype-2020/paper-cnn_clsCancerType-2020_2020-10-15-13-41-04.png"><br></p><p>尽管两者的行为非常相似，但1D-CNN的鲁棒性还是要好一些。</p><p>未来的研究方向：</p><ul><li>将GTEx中的转录数据利用【33】</li><li>利用到其他基因组学数据，如DNA mutation、copy number variation和DNA methylation等。</li></ul><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Omics </tag>
            
            <tag> CNNs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-使用神经网络进行Time-to-Event预测-2019</title>
      <link href="/2020/10/12/paper/omics/paper-nnandcox-2019/"/>
      <url>/2020/10/12/paper/omics/paper-nnandcox-2019/</url>
      
        <content type="html"><![CDATA[<h1 id="time-to-event-prediction-with-neural-networks-and-cox-regression">Time-to-Event Prediction with Neural Networks and Cox Regression</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>本研究探索time-to-event预测的方法，其在大量的实践中有应用：</p><ul><li>癌症病人的生存预测</li><li>客户流失</li><li>机械系统的失效时间</li></ul><p>其更加注重可解释性。</p></li><li><p>在time-to-event问题中，一个重要的特点是会出现censored data。</p></li><li><p>本研究中，提出了一种将机器学习技术和生存模型结合的方法：即通过将CoxPH model扩展到NN上，并移除其比例风险假定。并提供了其一个可用的基于pytorch的package —— <a href="https://github.com/havakv/pycox" target="_blank" rel="noopener">pycox</a>。</p></li></ol><h3 id="相关工作">相关工作</h3><ol type="1"><li><p>【Faraggi and Simon (1995)】首先对Cox进行了扩展，其将线性预测器更换为1-hidden-layer MLP，但其并没有超过正常的Cox models【Xiang et al., 2000; Sargent, 2001】。</p><p>DeepSurv【Katzman et al. (2018)】在deep learning的框架下重现对该模型进行了实现，并在C-index上得到了更好的结果。</p><p>但DeepSurv依然受到Cox model的比例假定的限制，本研究对损失函数进行了修改，可以适用于非比例假定的情况。</p><p>同样相似的工作还有SurvivalNet【Yousefi et al., 2017】，其不同之处在于使用Bayesian optimization来进行超参数的调整。</p><p>【Zhu et al. (2016)， Zhu et al. (2017) 】将DeepSurv中的MLP替换为CNNs来进行肺癌病理图片的生存预测。</p></li><li><p>另一类进行time-to-event prediction的方法是将连续的时间离散化，从而计算给定时间段上的survival function或hazard function。</p><p>【Luck et al.(2017)】提出的方法类似DeepSurv，只是其是在离散的outputs上进行的生存预测，使用的损失函数是isotonic regression loss。</p><p>【Fotso (2018)】将multi-task logistic regression with NN应用到离散生存预测上。</p><p>DeepHit【Lee et al. (2018) 】使用NN来估计probability mass function，并结合了log-likelihood和ranking loss。同时，该模型还可以适用于竞争风险模型的情况。</p></li><li><p>另外一个非常常用的生存模型是基于tree的random survival forests（RSF）【Ishwaran et al. (2008)】。RSF使用log-rank test作为splitting criterion来建立random forest，其在叶节点上计算cumulative hazards，并在所有trees上对此进行average。所以，RSF是一种非常灵活的模型，其没有收到比例假定的限制。</p></li></ol><h2 id="methods">Methods</h2><h3 id="生存分析">生存分析</h3><p>对于某一event，其发生的时间<span class="math inline">\(T^*\)</span>是一个随机变量： <span class="math display">\[P(T^*\le t)=\int_0^tf(s)ds=F(t)\]</span> 其中<span class="math inline">\(F(t)\)</span>和<span class="math inline">\(f(t)\)</span>分别是其density 和 cumulative distribution function。</p><p>对于<span class="math inline">\(F(t)\)</span>，另一个可替代的、有实际意义的概念是survival function： <span class="math display">\[S(t)=P(T^*\gt t)=1-F(t)\]</span> 还有hazard function： <span class="math display">\[h(t)=\frac{f(t)}{S(t)}=\lim_{\Delta t\to0}\frac{1}{\Delta t}P(t\le T^*\lt t+\Delta t|T^*\ge t)\]</span></p><blockquote><p>通常来说，hazard function更加能够解释生存模型的本质，拥有明确的意义，而且其限制更少：（只需要保证非负和<span class="math inline">\(\int_0^{\infty}h(t)=\infty\)</span>即可）。所以，大多数生存模型的建模是来对hazard function进行拟合。</p></blockquote><p>进一步，我们可以得到cumulative function： <span class="math display">\[H(t)=\int_0^th(s)ds\]</span> 我们可以得到cumulative function和survival function以下的关系： <span class="math display">\[S(t)=\exp[-H(t)]\]</span></p><p>在真实数据中，我们的随访时间不足以观察到时间的发生，这会造成right censor的出现，这时我们得到的时间为<span class="math inline">\(T=min\{T^*,C^*\}\)</span>，其中<span class="math inline">\(C^*\)</span>是censoring time，同时我们得到一个indicator <span class="math inline">\(D=\mathbb{1}\{T=T^*\}\)</span>来指示时间<span class="math inline">\(T\)</span>是否是一个censored data。</p><p>假设样本<span class="math inline">\(i\)</span>拥有协变量<span class="math inline">\(\mathbf{x}_i\)</span>和观测的时间<span class="math inline">\(T_i\)</span>，我们有下面的likelihood：</p><p><span class="math display">\[L=\prod_i{f(T_i|\mathbf{x}_i)^{D_i}S(T_i)|\mathbf{x}_i}^{1-D_i}=\prod_i{h(T_i|\mathbf{x}_i)^{D_i}\exp[-H(T_i|\mathbf{x}_i)]}\tag{2}\]</span></p><p>或者称为full likelihood。</p><h3 id="coxph-回归">CoxPH 回归</h3><p>Cox proportional hazards model【Cox, 1972】提供一个hazard function的半参数框架： <span class="math display">\[h(t|\mathbf{x})=h_0(t)\exp[g(\mathbf{x})],\quadg(\mathbf{x})=\beta^T\mathbf{x}\tag{3}\]</span></p><p>其中<span class="math inline">\(h_0(t)\)</span>称为non-parameteric baseline hazard，<span class="math inline">\(\exp[g(mathbf{x})]\)</span>称为relative risk function。注意，这里没有intercept，其可以被包括进baseline hazard中。</p><p>整个模型的拟合分为两个部分：</p><ol type="1"><li><p>首先使用partial likelihood来求解relative risk function部分：</p><p><span class="math display">\[L_{cox}=\prod_i(\frac{\exp[g(\mathbf{x}_i)]}{\sum_{j\in\mathcal{R}_i}\exp[g(\mathbf{x}_j)]})^{D_i}\tag{4}\]</span> 其中<span class="math inline">\(\mathcal{R}_i\)</span>表示那些在<span class="math inline">\(T_i\)</span>时刻还处于风险中的个体组成的集合（即在<span class="math inline">\(T_i\)</span>时刻还没有发生event而且没有删失的个体）。</p><p>进一步，可以得到其negative partial log-likelihood作为loss function： <span class="math display">\[loss=\sum_i{D_i\{\log(\sum_{j\in\mathcal{R}_i}\exp[g(\mathbf{x}_i)])-g(\mathbf{x}_i)\}}\tag{5}\]</span></p><p>假设最后得到的参数的估计值为<span class="math inline">\(\hat{\beta}\)</span>。</p></li><li><p>第二步，使用Breslow estimator来得到cumulative baseline hazard function：</p><p><span class="math display">\[\hat{H}_0(t)=\sum_{T_i\le t}\Delta\hat{H}_0(T_i)\\ \Delta\hat{H}_0(T_i)=\frac{D_i}{\sum_{j\in\mathcal{R}_i}\exp[\hat{g}(\mathbf{x_j})]}\tag{6} \]</span></p><p>如果可以，我们可以进一步通过平滑<span class="math inline">\(\hat{H}_0\)</span>的增量来得到<span class="math inline">\(\hat{h}_0\)</span>，但通常来说<span class="math inline">\(\hat{H}_0\)</span>已经能够提供我们足够的信息了。</p><blockquote><p>通过最大化式2，并将<span class="math inline">\(h_0(t)\)</span>看做是piecewise constant between uncensored failure times得到。</p></blockquote></li></ol><h3 id="cox-with-sgd">Cox with SGD</h3><p>Cox partial likelihood的优化一般使用Newton-Raphson's method，但利用minibatch SGD来优化的思路是非常简单的，即<strong>计算每个minibatch的loss优化即可</strong>，这和其他的loss的优化没有区别。</p><p>这对于满足比例假设的loss（DeepSurv）优化是没有问题的，但如果用于后面的非比例假设的loss的优化，将造成比较大的计算量，所以这里试图来得到一个该loss的估计值，更加容易在batches上进行计算。</p><ol type="1"><li><p>首先，假设使用一个risk set<span class="math inline">\(\mathcal{R}_i\)</span>的一个足够大的子集<span class="math inline">\(\tilde{\mathcal{R}}_i\)</span>来估计partial likelihood已经足够，这里还使用了一个weight来保证其足够大：</p><p><span class="math display">\[L=\prod_i(\frac{\exp[g(\mathbf{x}_i)]}{w_i\sum_{j\in\tilde{\mathcal{R}}_i}\exp[g(\mathbf{x}_j)]})^{D_i}\tag{7}\]</span></p></li><li><p>这里保证<span class="math inline">\(i\)</span>总是属于<span class="math inline">\(\tilde{\mathcal{R}}_i\)</span>的。注意，在计算梯度的时候，<span class="math inline">\(w_i\)</span>会被约去，所以其没有必要存在于loss中。另外<span class="math inline">\(D_i=0\)</span>的项也对loss没有贡献。之后，我们再除以样本的数量，得到：</p><p><span class="math display">\[loss=\frac{1}{n}\sum_{i:D_i=1}\log(\sum_{j\in\tilde{\mathcal{R}}_i}\exp[g(\mathbf{x}_j-\mathbf{x}_i)])\tag{8}\]</span></p></li><li><p>在后面的实验中，我们发现，<span class="math inline">\(\tilde{\mathcal{R}}_i\)</span>只有一个<span class="math inline">\(j\)</span>已经足够，所以我们得到：</p><p><span class="math display">\[loss=\frac{1}{n}\sum_{i:D_i=1}\log(1+\exp[g(\mathbf{x}_j)-g(\mathbf{x}_i)]),\quad j\in\mathcal{R}_i\backslash\{i\}\tag{9}\]</span></p></li></ol><p>注意，式8比式5更加易于理解，因为式8固定了risk sets的大小，从而使得值可以进行比较。式9的值的范围可以进行计算：<span class="math inline">\((0, 0.693]\)</span>。</p><p>其实risk set的sampling可以在流行病学研究中被设计，通过nested case-control design。其中，case即<span class="math inline">\(i\)</span>，而controls即<span class="math inline">\(j\)</span>。【Goldstein and Langholz (1992)】已经证明了对于CoxPH，sampled risk sets给出了一致的参数估计，虽然此没有在non-linear models中得到证明，但式8作为一个loss function是合理的。</p><h3 id="非线性的cox">非线性的Cox</h3><p>这里使用NN来构建<span class="math inline">\(g(\mathbf{x})\)</span>，而likelihood和loss都不需要改变。</p><p>之后，case-control近似得到的loss（式8）使用Cox-MLP（CC）来代表，而使用原始的loss（式5）的使用Cox-MLP（DeepSurv）来代表。</p><p>对于非线性模型，loss并不能保证存在唯一的解，所以这里还需要加入一个惩罚以保证输出不能距离0太远：</p><p><span class="math display">\[penalty=\lambda\sum_{i:D_i=1}\sum_{j\in\tilde{\mathcal{R}}_i}|g(\mathbf{x}_j)|\]</span></p><blockquote><p>这个问题在实践中碰到过。</p></blockquote><h3 id="非比例假设的cox-time">非比例假设的Cox-Time</h3><p>传统处理非比例假设的模型，做法是将将协变量分层，然后在每一层分别拟合cox模型【Klein and Moeschberger, 2003, chap. 9】，而这里我们使用参数化的方法来实现这一功能：</p><p><span class="math display">\[h(t|\mathbf{x})=h_0(t)\exp[g(t,\mathbf{x})]\]</span></p><p>即将时间当做一个协变量加入模型中。</p><p>以上模型有类似的loss function：</p><p><span class="math display">\[loss=\frac{1}{n}\sum_{i:D_i=1}\log(\sum_{j\in\tilde{\mathcal{R}}_i}\exp(g(T_i,\mathbf{x}_j)-g(T_i,\mathbf{x}_i)))\tag{12}\]</span></p><p>同样，式10的penalty也要用到，只是用<span class="math inline">\(g(T_i,\mathbf{x}_j)\)</span>来替换<span class="math inline">\(g(\mathbf{x}_j)\)</span>，这个模型称为Cox-Time。</p><p>主要，因为在loss中对于<span class="math inline">\(\mathbf{x}_i\)</span>和<span class="math inline">\(\mathbf{x}_j\)</span>都是使用<span class="math inline">\(T_i\)</span>进行计算，所以如果使用式5进行计算，则时间复杂度是<span class="math inline">\(O(n\cdot|\mathcal{R}_i|)=O(n^2)\)</span>。而如果使用式12进行计算，因为<span class="math inline">\(|\tilde{\mathcal{R}}_i|\)</span>是一个固定的数，所以时间复杂度是<span class="math inline">\(O(n)\)</span>。</p><blockquote><p>对于传统的CoxPH，因为可以只计算<span class="math inline">\(g(\mathbf{x}_j)\)</span>一次，然后在计算risk sets复用，所以其时间复杂度也是<span class="math inline">\(O(n)\)</span>。</p></blockquote><p>之后我们可以继续使用式6来对cumulative baseline hazard进行估计。</p><h3 id="预测">预测</h3><p>对于比例假设的模型，可以使用下面的公式来预测生存函数：</p><p><span class="math display">\[\hat{S}(t|\mathbf{x})=\exp[-\hat{H}(t|\mathbf{x})]=\exp[-H_0(t)\exp(g(\mathbf{x}))]\]</span></p><p>而对于非比例假定的模型，因为relative risk function部分也依赖于时间，所以必须用下面的方法来估算：</p><p><span class="math display">\[\begin{aligned}    H(t|\mathbf{x})&amp;=\int_0^t{h_0(s)\exp[g(s,\mathbf{x})]ds} \\    &amp;\approx\sum_{T_i\le t}{\Delta \hat{H}_0(T_i)\exp[\hat{g}(T_i,\mathbf{x})]} \\    \Delta\hat{H}_0(T_i)&amp;=\frac{D_i}{\sum_{j\in\mathcal{R}_i}\exp[\hat{g}(T_i,\mathbf{x}_j)]} \tag{13}\end{aligned}\]</span></p><h2 id="evaluation-criteria">Evaluation Criteria</h2><h3 id="concordance-index">Concordance Index</h3><p>C-Index【Harrell Jr et al., 1982】和ACC、AUC有着密切的关系【Ishwaran et al., 2008，Heagerty and Zheng, 2005】。简单来说，<strong>其估计了一个概率：对于随机的一对样本pair，其预测的生存时间和真实的生存时间顺序相关的概率。</strong></p><p>因为C-index只依赖于预测的顺序，所以对于CoxPH model，因为其顺序不会依赖于时间的改变，所以使得使用relative risk function就可以进行评价。</p><p>然后对于非比例假设的模型，就必须使用time-depend C-index【Antolini et al. (2005)】，其估计了观测<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>在“可比”的前提下是“一致”的概率：</p><p><span class="math display">\[C^{td}=P\{\hat{S}(T_i|\mathbf{x}_i)\lt\hat{S}(T_i|\mathbf{x}_j)|T_i\lt T_j,D_i=1\}\]</span></p><p>另外还进行了【Ishwaran et al. (2008, Section 5.1, step 3)】的修改，为了能够保证当预测独立于协变量<span class="math inline">\(\mathbf{x}\)</span>时，得到<span class="math inline">\(C^{td}=0.5\)</span>。</p><h3 id="brier-score">Brier Score</h3><p>BS本来是对于二分类的一个评价指标：</p><p><span class="math display">\[BS=\frac{1}{N}\sum_i(y_i-\hat{p}_i)^2\]</span> 其中<span class="math inline">\(y_i\)</span>是标签，<span class="math inline">\(\hat{p}_i\)</span>是预测的概率。</p><p>【Graf et al. (1999)】将Brier score扩展到了time-to-event data领域：</p><p><span class="math display">\[BS(t)=\frac{1}{N}\sum_i^N[    \frac{\hat{S}(t|\mathbf{x}_i)^21\{T_i\le t,D_i=1\}}{\hat{G}(T_i)}+    \frac{(1-\hat{S}(t|\mathbf{x}_i))^21\{T_i\gt t\}}{\hat{G}(t)}]\]</span></p><p>其中<span class="math inline">\(N\)</span>是观测的数量，<span class="math inline">\(\hat{G}(t)\)</span>是censoring survival function的Kaplan-Meier估计 <span class="math inline">\(P(C^*\lt t)\)</span>（即将删失作为event构建的生存函数），这里假设censor和event是独立的。</p><p>BS可以进一步扩展为integrated Brier score：</p><p><span class="math display">\[IBS=\frac{1}{t_2-t_1}\int_{t_1}^{t_2}{BS(s)ds}\]</span></p><p>实践中，一般将区间进行分块来近似计算这个积分（100个分割点足够了）。</p><h3 id="binomial-log-likelihood">Binomial Log-likelihood</h3><p><span class="math display">\[BLL(t)=\frac{1}{N}\sum_{i=1}^N[    \frac{\log[1-\hat{S}(t|\mathbf{x}_i)]1\{T_i\le t,D_i=1\}}{\hat{G}(T_i)} +    \frac{\log[\hat{S}(t|\mathbf{x}_i)]1\{T_i\gt t\}}{\hat{G}(t)}]\]</span></p><p>同样的，可以得到一个integrated version：</p><p><span class="math display">\[IBLL=\frac{1}{t_2-t_1}\int_{t_1}^{t_2}{BLL(s)ds}\]</span></p><h2 id="simulation">Simulation</h2><p>模拟以验证以上提到的算法是否可行。classical cox使用Lifelines packages来实现。</p><p>这里简单介绍以下模拟的方法：</p><p>假设我们的模型有下面的形式： <span class="math display">\[h(t|\mathbf{x})=h_0(t)\exp[g(t,\mathbf{x})]\]</span> <span class="math inline">\(H(t|\mathbf{x})=\int_0^t{h(s|\mathbf{x})ds}\)</span>是连续的累积风险函数，<span class="math inline">\(V\)</span>是参数为1的指数分布（<span class="math inline">\(P(V\gt v)=\exp(-v)\)</span>）。则我们可以通过下面的公式来采样得到符合上述累计风险函数的生存时间：</p><p><span class="math display">\[T^*=H^{-1}(V|\mathbf{x})\]</span></p><blockquote><p>因为<span class="math inline">\(S(t|\mathbf{x})=P(T^*\gt t|\mathbf{x})=P(H^{-1}(V|\mathbf{x})\gt t)=P(V\gt H(t|\mathbf{x}))=\exp[-H(t|\mathbf{x})]\)</span></p></blockquote><p>为了能够构造出<span class="math inline">\(H^{-1}\)</span>，所以一般需要<span class="math inline">\(g(t,\mathbf{x})\)</span>简单一些。</p><h3 id="模拟探索损失函数8的行为">模拟探索损失函数8的行为</h3><p>首先，我们探索loss function 8的行为，即不同controls samples的数量的结果和使用正常的偏似然函数（loss 5）之间的差别。</p><p>模拟数据来自proportional hazards model： <span class="math display">\[h(t|\mathbf{x})=h_0(t)\exp[g(\mathbf{x})]\\g(\mathbf{x})=\beta^T\mathbf{x}\]</span> 其中使用constant baseline hazard <span class="math inline">\(h_0(t)=0.1\)</span>和<span class="math inline">\(\beta=[0.44,0.66,0.88]^T\)</span>，协变量采样自<span class="math inline">\(\mathcal{U}(-1, 1)\)</span>。censoring time来自constant hazard <span class="math inline">\(c(t)=\frac{1}{30}\)</span>，其和协变量的采样是独立的，并设置了截止时间为30。以上的设置大约导致了30%的删失。然后采样了10000个样本作为training，10000个样本作为test。</p><p>使用loss function 8中描述的方式来拟合Cox model（称为Cox-SGD），四个模型分别是control 采样数为1, 2, 4, 8。所有的实验都重复了100次，test中的mean partial log-likelihood（MPLL）作为评价指标，结果如下图：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-05-02.png"><br></p><p>我们可以看到，其对于收敛的速度并没有影响，但采样数量越多会带来更大的计算复杂度。之后，为了证明样本量的减少不会影响模拟结果，使用1000个样本的training也进行了相同的实验，其结果与上图基本一致。</p><p>接下来，我们比较一下cox-SGD所拟合的参数和classical cox所拟合参数的不同。结果展示在下图中：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-10-41.png"><br></p><p>在样本量较少的时候，cox-SGD拟合的参数要小一些，而且似乎control采样数越少，这个趋势越明显。但随着样本量的增加，这个基本就不存在了。</p><p>最后，我们想要比较一下两个方法likelihood（full likelihood，式2）的差别。这里看的是training的likelihood，因为我们只想知道不同的方法的优化能力，而非模型的泛化能力。结果如下图所示：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-15-18.png"><br></p><p>可以看到，似乎control采样数越多，cox-SGD的结果越接近classical cox，但随着样本的增加，两者的差距缩小。classical cox的MLL大约是-2.2作用，所以即使对于最小样本量下，cox-SGD所带来的影响也小于0.1%，所以这也说明了该方法的有效性。</p><h3 id="非线性和非比例假设模型">非线性和非比例假设模型</h3><blockquote><p>该内容在Appendix C。</p></blockquote><p>非线性模型：</p><p><span class="math display">\[g(\mathbf{x})=\beta^T\mathbf{x}+\frac{2}{3}(x_1^2+x_3^2+x_1x_2+x_1x_3+x_2x_3)\]</span></p><p>cox-MLP使用的是1-hidden layer（64个节点）的模型，然后绘制了其和cox-SGD在2000个test点上的PLL散点图：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-20-11-27.png"><br></p><p>可以看到对于非线性问题，Cox-MLP有着更好的结果。</p><p>非比例假设模型：</p><p><span class="math display">\[g(t,\mathbf{x})=a(\mathbf{x})+b(\mathbf{x})t,\\a(\mathbf{x})=g_{ph}(\mathbf{x})+sign(x_3),\\b(\mathbf{x})=|0.2(x_0+x_1)+0.5x_0x_1|\]</span></p><p>cox-MLP和cox-Time都是用4-hidden layer的NN，每个layer是128个节点，dropout rate是0.1。其PLL的散点图为：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-20-16-17.png"><br></p><p>进一步，我们绘制了几个样本的生存曲线，可以看到，Cox-Time拟合的效果要好于Cox-MLP：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-20-17-55.png"><br></p><h2 id="experiments">Experiments</h2><p>本部分，将使用真实数据来比较各类模型的表现。</p><h3 id="小规模数据集实验">小规模数据集实验</h3><h4 id="使用数据集">使用数据集</h4><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-22-37.png"><br></p><p>前三个来自【Katzman et al. (2018)】，由DeepSurv python package提供。最后一个有R package survival提供（移除了chapter协变量）。</p><h4 id="使用的方法">使用的方法</h4><ul><li>使用control sampling的proportional Cox method：Cox-MLP(CC)</li><li>使用control sampling的non-proportional Cox method：Cox-Time</li><li>Classical Cox（linear）</li><li>DeepHit</li><li>Random Survival Rorests（RSF）</li><li>Cox-MLP（MLP），此方法与DeepSurv的不同在于使用的是minibatch SGD来训练，使用的loss是式5</li></ul><p>关于数据集的处理：</p><ul><li>对于使用NN的方法，我们首先将协变量标准化，然后使用entity embedding的方法将分类协变量变为长度是其类别数一半的向量【Guo and Berkhahn, 2016】。</li><li>对于Classical Cox（linear），分类协变量是one-hot的。</li><li>对于RSF，协变量不做任何处理。</li></ul><p>对于NN的架构：</p><ul><li>所有的NN使用相同的架构，每一层有相同的节点数、ReLU激活、BN。</li><li>使用了dropout、normalized decoupled weight decay【Loshchilov and Hutter, 2019】和early stopping来进行正则化。</li><li>SGD的方法是AdamWR【Loshchilov and Hutter, 2019】，并使用【Smith (2017)】的方法来找到学习率。</li></ul><p>整个验证过程：</p><ul><li>5-CV。</li><li>对于NN，每一折中，都对总共300多对参数组合进行random hyperparameter search，找到最优的参数组合，这里使用的评价指标是partial log-likelihood（比例假定的模型）和式12（Cox-Time）。</li><li>而DeepHit和 RSF的超参数调整使用的是time-dependent c-index【Antolini et al., 2005】。我们也使用了RSF作者建议的超参数调整方法，即通过计算concordance of the mortality【】，这两种方法得到的模型分别称为RSF（<span class="math inline">\(C^{td}\)</span>）和RSF（Mortality）。</li></ul><blockquote><p>这里使用的超参数的设置可以参见Appendix A1部分。</p></blockquote><h4 id="结果">结果</h4><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-44-02.png"><br></p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-44-22.png"><br></p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-14-44-36.png"><br></p><p>以上的3个tables展示了3种评价指标的结果：</p><ul><li><p>在C-index上，非比例假设的模型的结果要普遍好于比例假设的模型。RSF（<span class="math inline">\(C^{td}\)</span>）要好于RSF（Mortality），这可能是因为前者就是使用C-index来进行超参数调整的原因。而总的看来，Cox-Time的效果要略好于RSF，尽管其并不是使用C-index来进行的超参数调整。总的来说，似乎DeepHit表现最好，但这是其以其低效的生存预测为代价所得到的。</p><blockquote><p>注意，C-index高只需要保证顺序对就可以，其生存函数的预测可能是非常差的。</p></blockquote></li><li><p>在IBS和IBLL上，前三个数据集上Cox-Time都表现很好，在最后一个数据集上反而是以CC和DeepSurv为最高，这说明比例假定可能在此数据集上更加合适。</p><p>而在这两个指标中，DeepHit的表现不好。从其loss的形式中可以看出，其综合了两方面：negative log-likelihood和ranking loss，并使用一个超参数<span class="math inline">\(\alpha\)</span>来进行调节。超参数搜索得到的<span class="math inline">\(\alpha\)</span>都偏小，即更加便偏向于使用ranking loss的部分来进行拟合，从而其得到了较好的C-index，但拟合的生存函数较差。</p></li></ul><h3 id="大样本数据集实验">大样本数据集实验</h3><h4 id="数据集">数据集</h4><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-16-49-32.png"><br></p><p>WSDM KKBox's churn prediction challenge由Kaggle在2017年举办，为了预测音乐流媒体的客户流失现象。</p><p>如果一个客户在上次订阅后30天内没有续订，则认为此客户流失了，这是我们的event。协变量只使用最基础的那些（共有15个）。有些客户可能在流失后又续订，这被看做是一个新的样本。最终数据集被分为train、valid和test，详细信息如上表所示。</p><blockquote><p>关于此数据集的详细信息可见Appendix B1部分。</p></blockquote><h4 id="方法">方法</h4><p>使用的方法和“小样本数据集实验”中一致，但因为样本量太大，所以将classical cox替换为cox-SGD（linear）。</p><p>训练NN时将学习率乘以0.8，为了稳定训练。</p><p>因为样本量非常大，所以在进行超参数搜索的时候，不再包括weight decay，只是在一个小数量的合适的参数中寻找。找到的最优参数组合是：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-19-04-33.png"><br></p><p>至于RSF，基于<span class="math inline">\(C^{th}\)</span>的模型发现每次split采样8个协变量、每个叶节点最少50个样本，基于mortality的模型发现每次split采样2个协变量、叶节点的size最小是10。500个trees足够，但其和250个trees的结果没有什么差别。</p><blockquote><p>这里使用的超参数的设置可以参见Appendix A2部分。</p></blockquote><h4 id="结果-1">结果</h4><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-19-08-13.png"><br></p><p>每类模型都拟合5次，并将得到的评价指标的均值作为最后的结果。可以看到，趋势和小样本时是相似的。</p><p>之后，我们将每个时间点的BS计算出来（注意，这里越小越好）：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-19-17-39.png"><br></p><p>这里可以看到，依然是DeepHit是最差的，Cox-Time是最好的。Cox-MLP(DeepSurv)在长时间的预测中表现最好。BLL的图像和BS非常类似。</p><h4 id="生存曲线">生存曲线</h4><p>生存分析相对于分类任务的一个优势就是，可以给出生存曲线，有着更强的解释性。比如下面是Cox-Time在test上9个样本上的估计生存曲线：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-19-40-02.png"><br></p><p>为了能够对预测有更加general的视角，这里我们将test的预测生存曲线进行聚类。每个样本预测<span class="math inline">\(0=\tau_0\lt\tau_1\lt\cdots\lt\tau_m\)</span>这些时间点上的生存概率，然后将其作为feature进行k-means聚类，聚类数为10。各类的生存曲线在下图中：</p><p><img src="/2020/10/12/paper/omics/paper-nnandcox-2019/paper-NNandCOX-2019_2020-10-13-19-38-27.png"><br></p><p>我们可以看到：</p><ul><li>第一大类（19%的样本）是一条非常稳定的曲线</li><li>第二大类（18%）则有着非常高的脱落的风险</li><li>许多曲线没30天都有一次波动，这可能是因为月底付费所导致的</li><li>最少的那一类，则是在预定大约400天后急剧下降，查询他们的数据可以知道，这一类人大多在订阅400天后不再订阅。</li></ul><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Survival Analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-GSAE-2018</title>
      <link href="/2020/10/06/paper/omics/paper-gsae2018/"/>
      <url>/2020/10/06/paper/omics/paper-gsae2018/</url>
      
        <content type="html"><![CDATA[<h1 id="gsae-an-autoencoder-with-embedded-gene-set-nodes-for-genomics-functional-characterization">GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>gene set分析来解释gene expression data，是一个非常重要的生物信息学工具。</p><p>首先是常用的功能富集，比如常用的GSEA【1】、DAVID【2,3】和其他【4-6】。</p><p>另外还可以用来进行分类，比如PAM50【7】和【8,9】等。</p><p>但也有一些研究指出，不同研究所得到的gene set之间重合度较小【10】，所以最好通过整合多个不同的gene sets来提高其一致性。</p></li><li><p>最近深度学习的发展开始渗入到分子和细胞表达数据的分析中。</p><p>CNNs用来进行DNA-protein结合位点的预测【11】或用来检测表型相关细胞亚型【12】。</p><p>【13-15】使用AEs来进行降维。</p><p>【13】提出了一种NN model，其整合PPI和PDI（protein DNA interaction）了对single-cell RNAseq数据建模，但其只是使用这些先验信息来提高降维和细胞特异性识别的性能，而没有分析合并PPI节点所带来的影响。</p></li><li><p>本研究中提出Gene Superset AutoEncoder（GSAE）模型，其利用到了一个先验定义的gene sets来保证一些生物学特性。</p><p>本研究提出了gene superset的概念，目的是来确定学习到的gene supersets间的功能性或临床上的相关性。</p><p>使用TCGA的数据进行了验证。</p></li></ol><h2 id="methods">Methods</h2><h3 id="数据集">数据集</h3><p>来自TumorMap【16】整理的TCGA Pan-cancer RNAseq dataset，有9806 samples，33 cancer types。</p><p>使用BRCA（1099 samples）来characterize network nodes。</p><p>使用LUAD（515 samples）来进行survival analysis。</p><p>使用LUAD、BRCA、LGG（523 samples）和SKCM（469 samples）来比较supersets的复现性。</p><p>使用的表达量数据是TPM，并进行了log transform（<span class="math inline">\(\log_2(TPM+1)\)</span>）。</p><h3 id="gene-superset-autoencoder">Gene superset autoencoder</h3><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-06-16-50-31.png"><br></p><p>GSAE的结果如上图所示。</p><blockquote><p>就是一个AEs。</p></blockquote><h3 id="将基因集纳入编码层">将基因集纳入编码层</h3><p>将encoder的第一个hidden layer的节点作为gene set的表示，具体做法就是：<strong>表示某一具体gene set的节点只和在这个gene set中的genes连接</strong>。【13】使用的数据集是来自MSigDB【1,17】的CGP collection。</p><p>然后将gene set layer的输出输入到fc layer中，得到是superset表示（即AEs的瓶颈层表示）。这里的每个节点被看做是一个superset，是gene sets的组合表示。这里superset layer的节点数目是200。</p><h3 id="消除基因集间的依赖性">消除基因集间的依赖性</h3><p>CGP collection中的gene sets很多拥有高度的相似性，所以需要降低其依赖性。</p><p>这里使用的方法是【18】中的方法：</p><ol type="1"><li><p>首先忽略小于15或大于500个genes的gene sets；</p><blockquote><p>这也是GSEA的设置。</p></blockquote></li><li><p>计算gene sets间的kappa统计量，然后将<span class="math inline">\(p\lt10^{-7}\)</span>的gene sets进行聚类，使用最大的那个gene sets作为这个cluster的表示</p><p>最后，我们得到了2334个CGP sets和18107个genes。</p></li></ol><h3 id="实现">实现</h3><p>使用Keras 1.2.2。参数初始化使用的是uniform initialization。训练使用的optimizer是SGD（<span class="math inline">\(lr=0.05,decay=10^{-6},momentum=0.9,Nesterov=1\)</span>。</p><p>使用5%的数据作为validation，并使用early stopping防止过拟合。</p><h3 id="其他方法">其他方法</h3><ul><li>t-SNE，用来将supersets结果降维到2。</li><li>HDBSCAN，用来将t-SNE的结果进行聚类。</li></ul><h3 id="聚类结果的评价">聚类结果的评价</h3><ul><li><p>Dunn index：</p><p><span class="math display">\[\frac{min_{i,j,i\ne j}d_B(C_i,C_j)}{max_kd_W(C_k)}\]</span></p><p>其中<span class="math inline">\(d_B(C_i,C_j)\)</span>表示cluster <span class="math inline">\(C_i\)</span>和<span class="math inline">\(C_j\)</span>间的类间距，<span class="math inline">\(d_W(C_k)\)</span>表示cluster <span class="math inline">\(C_k\)</span>的类内距离。</p><blockquote><p>R package clv</p></blockquote></li><li><p>Silouette index：在所有clusters上的mean silhouettes的mean。</p><blockquote><p>R package clValid</p></blockquote></li><li><p>inter-intra distance (IID) index：</p><p><span class="math display">\[\frac{\frac{1}{n_B}\sum_{i,j;i\ne j}d_B(C_i,C_j)}{\frac{1}{n_W}\sum_kd_W(C_k)}\]</span></p><p>其中<span class="math inline">\(n_B\)</span>和<span class="math inline">\(n_W\)</span>表示cluster pairs和clusters的数量。</p></li></ul><h3 id="差异superset分析">差异superset分析</h3><p>使用HDBSCAN对t-SNE的结果分亚型，然后使用单尾的Mann-Whitney-Wilcoxon U test来寻找两组间的差异supersets。其中在group1中值更大的称为up-supersets，反之称为down-supersets。</p><p>然后我们构建第<span class="math inline">\(i\)</span>个gene set对第<span class="math inline">\(j\)</span>个superset的贡献，即gsScore：</p><p><span class="math display">\[gsScore_{ij}=(\mu_1^i-\mu_2^i)\times w_{ij}\]</span></p><p>其中<span class="math inline">\(\mu_1,\mu_2\)</span>分别表示第<span class="math inline">\(i\)</span>个gene set在两组的均值，<span class="math inline">\(w_{ij}\)</span>是model中第<span class="math inline">\(i\)</span>个gene set与第<span class="math inline">\(j\)</span>个superset间连接的权重大小。</p><p>在up-supersets中，gsScore大于positive cutoff的gene sets被选择；而在down-supersets中，gsScore小于negative cutoff的被选择。</p><h3 id="sueprset上的生存分析">sueprset上的生存分析</h3><p>对于每个superset和gene set，使用median分为两组，然后比较两组的生存差异。</p><h2 id="results">Results</h2><h3 id="在低维编码中依然保留了癌症类型的信息">在低维编码中依然保留了癌症类型的信息</h3><p>这里使用TCGA PanCancer RNAseq logTPM数据，使用<span class="math inline">\(\mu\gt1\)</span>和<span class="math inline">\(\sigma\gt0.5\)</span>来筛选到15975个genes，9806个samples，然后使用GSAE提取supersets features。在supersets features上使用t-SNE，并可视化：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-07-13-31-46.png"><br></p><p>我们可以看到，使用GSAE并没有导致癌症分类信息的丢失。进一步用3种聚类评价指标来衡量GSAE降维前后的相似性：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-07-13-34-08.png"><br></p><p>尽管前后维度降低了接近98%，但综合上面的3个指标的结果可以得出结论：<strong>GSAE在降维的时候并没有导致癌症类型相关信息的丢失</strong>。</p><h3 id="与乳腺癌亚型相关的gene-sets">与乳腺癌亚型相关的gene sets</h3><p>上面fig2中可以看到，BRCA被分成了2个部分，我们对此进行进一步的研究。</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-07-13-38-34.png"><br></p><p>结果如上图所示。</p><ul><li>依然使用<span class="math inline">\(\mu\gt1\)</span>和<span class="math inline">\(\sigma\gt0.5\)</span>的标准，得到15183 genes和1099 samples，然后进行t-SNE，使用HDBSCAN可以自然地将其聚类为两个亚型：G1（red）和G2（green）。</li><li>基于WWU test（location shift mu=9，<span class="math inline">\(P\lt0.01\)</span>），可以确定4个up-supersets和3个down-supersets（Tab S1）。</li><li>gsScore &gt; 2 sd（gsScore在superset中的标准差）的gene sets被视为high impact gene sets。</li></ul><p>最显著的up-superset和down-superset的top15 gene sets如下所示，其中的<span class="math inline">\(PScore=-\log_{10}(P-value)\)</span>：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-08-58-45.png"><br></p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-00-03.png"><br></p><p>其中有许多与乳腺癌亚型高度相关的gene sets【24,25,26,27,28】。</p><p>之后，我们对G1/G2也进行了GSEA分析，发现124个high impact gene sets中的53个（42.7%）也是GSEA的富集gene sets（P&lt;0.05），说明了GSAE方法找到的这些super sets是合理的。</p><p>另外，top3 up-supersets的Venn diagram展示在上面的fig 3d中，其中的大多数城府gene sets和Basal subtype相关，Up-superset 1另外相关于estrogen related gene sets，up-superset 2有许多gene sets相关于ERBB2。</p><h3 id="使用superset分类器预测乳腺癌pam50亚型">使用superset分类器预测乳腺癌PAM50亚型</h3><p>将decoder替换为了一个softmax分类器，则我们的模型可进行分类。</p><p>使用的数据集是821 x 15183的BRCA样本，对PAM50亚型（Basal、LumA、LumB和Her2）进行分类，使用10-CV进行验证，结果如下所示：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-12-57.png"><br></p><p>其中Gene set指的是没有superset layer，直接将gene sets layer的结果输入分类器；而n-fc表示使用n层的fc搭建的MLP作为encoder。可以看到，superset layer得到了最好的结果。</p><p>之后，通过10次10-CV，我们计算了分类器的灵敏度和特异度：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-34-30.png"><br></p><h3 id="肺腺癌数据的生存分析">肺腺癌数据的生存分析</h3><p>数据集：TCGA LUAD，515 x 15188。</p><p>首先使用log-rank test确定了6个supersets。然后通过gsScore选择出每个superset中的top20 gene sets（Additional File 3: Table S2），这些gene sets在gene set level上的log-rank test也是显著的。</p><p>以下是选择的第1和第4顺位的supersets及其top15 genes（选择第4是因为其与第1的重叠gene sets是最少的）：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-40-10.png"><br></p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-41-35.png"><br></p><p>许多文献研究也支持了以上的结果【33-43】。</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-10-09-50.png"><br></p><h3 id="supersets可以提高生存分析的重现性">supersets可以提高生存分析的重现性</h3><p>这里使用BRCA、LUAD、SKCM和LGG 4个数据来验证，使用<span class="math inline">\(\mu\gt1\)</span>和<span class="math inline">\(\sigma\gt0.5\)</span>来筛选变量，然后分割60%和40%作为train和test set。在train set上训练GSAE，在train和test set上得到superset表示。之后在train、test set上使用median分组，并进行log-rank检验来得到显著的生存相关supersets和gene sets。然后我们来比较train和test上得到的显著supersets、gene sets的相似性，使用的指标是Jaccard index和proportions z-test。结果如下所示：</p><p><img src="/2020/10/06/paper/omics/paper-gsae2018/paper-GSAE2018_2020-10-14-09-57-23.png"><br></p><p>可以看到，总体来说，supersets的重现性要好于gene sets。</p><h2 id="discussion">Discussion</h2><p>和其他的机器学习方法类似，GSAE方法尽管在不同的超参数设置下可以得到类似的loss和分类结果，但其学习得到的supersets可能是不同的，那些更加显著的supersets可能有更高的频率出现。导致这个问题的原因可能来自gene sets的重叠和权重的初始化。</p><p>该算法的另一个问题在于需要大量的样本量。这可能意味着GSAE可能更加适合单细胞数据，single-cell RNAseq的测序深度低，但有更多的样本量。</p><p>supersets的概念不仅提供了更强的复现性，而且也为理解gene sets间的依赖性提供了一个机会。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
            <tag> AutoEncoder </tag>
            
            <tag> Gene sets </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-使用gene表达数据进行癌症分类-2018</title>
      <link href="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/"/>
      <url>/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/</url>
      
        <content type="html"><![CDATA[<h1 id="deep-learning-based-tumor-type-classification-using-gene-expression-data">Deep Learning Based Tumor Type Classification Using Gene Expression Data</h1><ul><li>杂志: bioRxiv</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>Next Generation Sequencing（NGS）技术的发展极大地提高了人类基因组学的研究，其中TCGA计划是其中的重要代表。</p><p>利用这些数据一个目的是筛选biomarkers，但这一般都是data specific的，无法利用到其他癌种的信息。</p></li><li><p>另外，利用所有的癌种数据对癌种分类建模本身有着其诊断的意义。但在这个任务上也有着困难：</p><p>变量（genes）多，很多genes是weak features，在许多模型中会遇到“维度灾难”的问题；</p></li><li><p>虽然深度学习在基因组学还处于开始阶段，但其在计算机视觉上的成功毋庸置疑。另外，如Taylor decomposition、layer-wise decomposition和Grad-CAM【16】等可视化方法也增强了深度学习的可解释性。</p><p>这提示我们可以利用深度学习技术来建模癌种分类模型，其适合进行变量多、关系复杂的建模。</p><p>更进一步，如果我们对癌种分类贡献较大的变量更加重要，则我们可以利用上刚才我们提到的可视化方法得到变量的重要性评分，筛选biomarkers。</p></li><li><p>本研究首先使用方差来筛选变量，然后将高维表达数据（<span class="math inline">\(10381\times1\)</span>）整理成2-D image（<span class="math inline">\(102\times120\)</span>），然后使用3-layers的CNN对其进行分类，并使用10-CV对其进行评价。基于Guide Grad-CAM【16】，我们对每个类生成重要性热图，得到biomarkers，并在功能分析中证明了筛选的biomarkers都是有生物学意义的。</p></li></ol><h3 id="相关工作">相关工作</h3><ol type="1"><li><p>GA/KNN【11】方法，进行多癌种分类，在31类上得到了90%的正确率，并且可以生成一个top genes set。</p></li><li><p>【5】首先使用stacked auto-encoder来提取high-level features，然后进行ANN中进行分类，其在癌或非癌的分类任务上得到了94%的acc。此模型如果应用到多癌种分类上，将会变得特别复杂，难以实施。</p><p>为了得到top set genes，其将stAE中每层的权重相乘从而得到每个gene的权重。这个想法和本研究中使用的可视化方法类似。</p></li><li><p>Deep Taylor decomposition、layer-wise relevance propagation（LRP）【1,2】和Guided Grad-CAM是在深度学习领域进行解释性可视化的方法，本研究使用的是Guided Grad-CAM。</p></li></ol><h2 id="methods">Methods</h2><p>流程图如下：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-14-58-19.png"><br></p><h3 id="数据">数据</h3><p>共有33个癌种，10267个样本，20531个genes。</p><h3 id="预处理">预处理</h3><ol type="1"><li>数据是normalized read count，首先将小于1的数值变成0，并进行<span class="math inline">\(log_2(x+1)\)</span>变换。</li><li>将genes match到annotation file（04/03/2018，from NCBI），其中有1000个genes没有在annotation file中找到了，并使用var=1.19来进行变量筛选，最终得到10381个genes。</li><li>首先根据其染色体编号，将其排序，然后将其reshape成<span class="math inline">\(102\times102\)</span>的image，在最后一行pad zeros来加成。</li><li>将所有生成的imagesnormalized到0-255范围内。</li></ol><p>最后生成的figures：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-05-51.png"><br></p><h3 id="分类">分类</h3><p>使用的架构如下图所示：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-06-33.png"><br></p><p>在进入fc之前加了一个0.25的dropout，进行了10-CV来进行评价。</p><p>使用的评价指标有ACC、average precision、average recall、average F1 score。</p><h3 id="热图">热图</h3><p>利用guide Grad-CAM可以为每一张image的每一绘制heat-map，其中值越高代表该pixel在最后的分类中贡献更大。</p><h3 id="验证">验证</h3><ol type="1"><li>每个癌种选择top 400 genes来进行pathway analysis。</li><li>研究前一步中没有人格结果的tumor type的top 5 genes，来寻找其和肿瘤的关系。</li></ol><h2 id="results">Results</h2><h3 id="分类-1">分类</h3><p>结果如下：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-38-12.png"><br></p><p>进一步，我们绘制了confusion matrix：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-38-53.png"><br></p><p>可以看到：</p><ul><li>READ（直肠癌） samples容易被错分为COAD（结肠癌），这可能是因为两类癌症有着比较近的空间关系。</li><li>许多CHOL（胆管癌）样本会被错分为LIHC（肝细胞癌），这可能因为CHOL的样本量太少。</li></ul><p>tab3进一步显示了在每个癌症类型上和【11】的比较，可以看到在READ和UCS（子宫癌）的分类上，本研究的方法有着较大的提升。</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-14-59-48.png"><br></p><h3 id="生成的热图">生成的热图</h3><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-45-21.png"><br></p><p>上面的每一行表示一种癌症，而每一列表示一折的结果。从上面的例子中我们可以看到，尽管每一折产生的热图有所不同，但还是显示出清晰的、相似的模式。</p><h3 id="top-genes的验证">Top genes的验证</h3><p>对于每一类的热图，我们将其intensity的变化绘制成fig4：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-50-04.png"><br></p><p>我们可以看到每一类都表现出相似的性质，即在top 100 genes上其scores下降的很快，而从大约400个genes开始，其下降开始变得非常平缓，最后又有一个非常迅速的下降。<strong>这说明top 400 genes可能拥有更强的作用，所以选择这些genes进行富集分析。</strong></p><p>使用<a href="https://david.ncifcrf.gov/home.jsp" target="_blank" rel="noopener">David website</a>来进行KEGG pathway analysis，其中p值小于0.001的展示在tab4中：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-15-54-12.png"><br></p><p>其中有24个癌种被发现有显著的通路富集，其中16个癌症在这400个genes中有至少一个相关通路，在这些通路中的genes可以看做是biomarkers。</p><p>另外8个癌种中，虽然没有明确的相关通路，但有两条显著的富集通路：hsa04512和hsa04510，但其在不同癌种中的genes不相同。</p><p>在剩下的9个癌种中，没有显著的通路。因为CHOL和KICH的样本量有限，我们忽略他们。READ的预测acc很低，我们也忽略。然后我们查看他们的top 5 genes，并在<a href="www.genecards.org">GeneCards</a>中查看他们的信息：</p><p><img src="/2020/10/06/paper/omics/paper-cnn-yan-chong-fen-lei-2018/paper-cnn癌种分类2018_2020-10-06-16-12-31.png"><br></p><blockquote><p>OV中的MUC16就是CA125，被认为是OV中唯一可靠的诊断标志物。</p></blockquote><p>可以通过查看这些genes的信息，确定筛选到的genes中有一部分和癌症密切相关，可以看做是潜在的biomarkers。</p><h2 id="discussion">Discussion</h2><p>通过错分样本的分析，限制本研究模型性能的一个原因可以在于imbalanced dataset，所以使用一些oversampling methods（SMOTE）可能有助于性能的提升。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
            <tag> CNNs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-变分图自编码器-2016</title>
      <link href="/2020/09/30/paper/dl/paper-vgae2016/"/>
      <url>/2020/09/30/paper/dl/paper-vgae2016/</url>
      
        <content type="html"><![CDATA[<h1 id="variational-graph-auto-encoders">Variational Graph Auto-Encoders</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><p>本研究提出了一种新的graph上的无监督学习架构，称为variational graph autoencoder（VGAE），其基于VAE，来学习可解释的latent representation。这里我们使用GCN作为encoder、inner product作为decoder，并应用到citation networks上的link prediction任务，并取得了不错的效果。</p><h2 id="methods">Methods</h2><p>这里使用的是undirected、unweighted graph <span class="math inline">\(\mathcal{G}=(\mathcal{V}, \mathcal{E})\)</span>，其中节点数为<span class="math inline">\(N=|\mathcal{V}|\)</span>，graph的邻接矩阵为<span class="math inline">\(\mathbf{A}\)</span>、degree矩阵为<span class="math inline">\(\mathcal{D}\)</span>。</p><p>latent variables是<span class="math inline">\(\mathbf{z}_i\)</span>，将所有节点组合成矩阵<span class="math inline">\(\mathbf{Z}\in\mathbb{R}^{N\times F}\)</span>。节点特征矩阵为<span class="math inline">\(\mathbf{X}\in\mathbb{R}^{N\times D}\)</span>。</p><h3 id="inferece-model">Inferece model</h3><blockquote><p>编码器</p></blockquote><p><span class="math display">\[q(\mathbf{Z}|\mathbf{X},\mathbf{A})=\prod_{i=1}^Nq(\mathbf{z}_i|\mathbf{X},\mathbf{A}),\quad\text{with}\quad q(\mathbf{z}_i|\mathbf{X},\mathbf{A})=\mathcal{N}(\mathbf{z}_i|\mathbf{\mu}_i,diag(\mathbf{\sigma}_i^2))\]</span></p><p>其中<span class="math inline">\(\mathbf{\mu}=GCN_{\mu}(\mathbf{X},\mathbf{A})\)</span>，<span class="math inline">\(\log\mathbf{\sigma}=GCN_{\sigma}(\mathbf{X},\mathbf{A})\)</span>。这两个GCN都是2-layers，其共享第一层的参数。</p><h3 id="generative-model">Generative model</h3><blockquote><p>解码器</p></blockquote><p><span class="math display">\[q(\mathbf{A}|\mathbf{Z})=\prod_{i=1}^N\prod_{j=1}^Np(A_{ij}|\mathbf{z}_i,\mathbf{z}_j),\quad\text{with}\quad p(A_{ij}|\mathbf{z}_i,\mathbf{z}_j)=\sigma(\mathbf{z}_i^T\mathbf{z}_j)\]</span></p><h3 id="learning">Learning</h3><p><span class="math display">\[\mathcal{L}=\mathbb{E}_{q(\mathbf{Z}|\mathbf{X},\mathbf{A})}[\log p(\mathbf{A}|\mathbf{Z})]-KL[q(\mathbf{Z}|\mathbf{X},\mathbf{A})||p(\mathbf{Z})]\]</span></p><p>其中<span class="math inline">\(p(\mathbf{Z})\)</span>是先验分布，使用Gaussian prior。</p><p>训练的时候是使用full-batch gradient descent。对于featureless approach，<span class="math inline">\(\mathbf{X}\)</span>被identity matrix替代。</p><h3 id="gae-model">GAE model</h3><p>这是一个比较模型，即确定性的graph autoencoder。</p><p><span class="math display">\[\hat{\mathbf{A}}=\sigma(\mathbf{Z}\mathbf{Z}^T),\quad\text{with}\quad\mathbf{Z}=GCN(\mathbf{X},\mathbf{A})\]</span></p><h2 id="results">Results</h2><p>这里使用不同的方法来学习节点表示，然后使用下面的公式来对graph的link进行预测：</p><p><span class="math display">\[\sigma(\mathbf{Z}\mathbf{Z}^T)\]</span></p><p>使用的数据来自【1】，首先会将其中5%和10%的边作为validation和test去掉。</p><ul><li>对于VGAE和GAE，其使用Adam（lr=0.01）训练了200个iterations，然后使用了32-dim的hidden layer和16-dim的latent variables。</li><li>对于SC，使用的embedding dimension是128。</li><li>对于DW，使用的是【8】的标准设置。</li></ul><p>结果如下所示：</p><p><img src="/2020/09/30/paper/dl/paper-vgae2016/paper-VGAE2016_2020-09-30-10-43-44.png"><br></p><p>GAE和VGAE都得到了不错的结果，特别是使用上节点特征会显著提高预测结果。实际上使用Gaussian prior是个非常差的选择，但依然取得了不错的效果。</p><h2 id="conclusion">Conclusion</h2><p>以后可以需要探索更合适的prior、更加灵活的generative models和随机梯度下降的使用。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Graph Neural networks </tag>
            
            <tag> Variational Inferece </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-VGCN-2019</title>
      <link href="/2020/09/25/paper/dl/paper-gcn2019/"/>
      <url>/2020/09/25/paper/dl/paper-gcn2019/</url>
      
        <content type="html"><![CDATA[<h1 id="variational-graph-convolutional-networks">Variational Graph Convolutional Networks</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>GCN解决了节点的半监督分类问题，并且结构简单，不需要进行特征分解；</p></li><li><p>但其一个主要假设是使用的graph是正确可靠的（这也是大多数GNNs的假设），但实际上并不是（噪声影响、和分类问题相关程度不高等）；</p></li><li><p>本研究试图通过bayesian方法来的图的结构进行优化，并克服了以下两个问题：</p><ol type="a"><li><p>使用随机变分推断去计算后验分布；</p></li><li><p>需要优化<span class="math inline">\(O(N^2)\)</span>个参数；</p></li></ol></li></ol><h3 id="相关工作">相关工作</h3><ol type="1"><li>【28】第一次试图对GNN进行概率描述，其将graph视为一个mixed membership stochastic block models【1】，但这样的方法并没有将参数视为后验的（即随观测发生变化）；</li><li>【20】使用到了高斯过程（GP）进行建模啊；</li><li>【5】去开发了一种生成模型来进行图结构的学习；</li><li>【14】提出了变分图自编码器，其和本文的工作目的并不一致。</li></ol><h2 id="methods">Methods</h2><h3 id="bayesian-gcns">Bayesian GCNs</h3><blockquote><p>这里介绍likelihood和prior</p></blockquote><p><span class="math inline">\(\mathbf{X}\in\mathbb{R}^{N\times D}\)</span>是<span class="math inline">\(N\)</span>个实例的<span class="math inline">\(D\)</span>维features，其对应的labels是<span class="math inline">\(\mathbf{Y}=\{\mathbf{y}_n\}\)</span>。这些labels有些是观测到的，而另外一些是未观测到的，其都是one-hot向量：<span class="math inline">\(\mathbf{y}_n\in\{0,1\}^C\)</span>。<strong>我们的任务是使用上面的数据对未观测的标签进行预测，这里基于的框架是GCN。</strong></p><p><span class="math inline">\(\mathcal{G}=(\mathcal{V},\mathcal{E})\)</span>表示一个无向图，其中有<span class="math inline">\(N\)</span>个节点：<span class="math inline">\(v_i\in\mathcal{V}\)</span>，其对应的边是<span class="math inline">\((v_i,v_j)\in\mathcal{E}\)</span>，邻接矩阵是binary的：<span class="math inline">\(\mathbf{A}\in\{0,1\}^{N\times N}\)</span>。</p><p>依据上面的设置并假设可观测的labels是条件独立的，则我们可以写出：</p><p><strong>likelihood</strong></p><p><span class="math display">\[p_{\mathbf{\theta}}(\mathbf{Y}^o|\mathbf{X},\mathbf{A}) =\prod_{\mathbf{y}\in\mathbf{Y}^o}{p_{\mathbf{\theta}}(\mathbf{y}_n|\mathbf{X}, \mathbf{A})}\quad\text{with}\quadp_{\mathbf{\theta}}(\mathbf{y}_n|\mathbf{X}, \mathbf{A})=Cat(\mathbf{y}_n|\mathbf{\pi}_n)\]</span></p><p>如果是使用GCN的话，我们有：</p><p><span class="math display">\[\mathbf{\Pi}=\mathbf{f}^{L}(\mathbf{X},\mathbf{A})=softmax(\tilde{\mathbf{D}}^{-1/2}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-1/2}relu(\tilde{\mathbf{D}}^{-1/2}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-1/2}\mathbf{W_0})\mathbf{W_1})\]</span></p><p>其中<span class="math inline">\(\mathbf{\Pi}\)</span>的每一行是一个<span class="math inline">\(\mathbf{\pi}_n\)</span>。</p><p>接下来，我们考虑：</p><p><strong>graph priors</strong></p><p><span class="math display">\[p(\mathbf{A})=\prod_{ij}p(A_{ij})\quad\text{with}\quadp(A_{ij})=Bern(A_{ij}|\rho_{ij}^o)\]</span></p><p>注意到，这个先验是可以通过多种方式来构造的，比如我们已知一个图结构，则我们可以通过下面的方式来构造这个先验：</p><p><span class="math display">\[\rho_{ij}^o=\bar{\rho}_1\bar{\mathbf{A}}_{ij}+\bar{\rho}_0(1-\bar{\mathbf{A}}_{ij})\]</span></p><p>其中<span class="math inline">\(\bar{\mathbf{A}}\)</span>是我们手上拥有的图邻接矩阵（binary），<span class="math inline">\(0\lt\bar{\rho}_1,\bar{\rho}_0\lt1\)</span>是超参数。</p><blockquote><p>即这里的先验并不是说graph有边的地方就是1、无边的地方就是0，而是有边的地方是<span class="math inline">\(\bar{\rho}_1\)</span>、无边的地方是<span class="math inline">\(\bar{\rho}_0\)</span>。</p></blockquote><h3 id="依靠平滑参数进行graph-structure-inference">依靠平滑参数进行graph structure inference</h3><blockquote><p>这里介绍如何通过likelihood和prior来推断posterior</p></blockquote><p>这里的关键在于对后验的structure进行估计：<span class="math inline">\(p(\mathbf{A}|\mathbf{X},\mathbf{Y}^o)\propto p_{\mathbf{\theta}}(\mathbf{Y}^o|\mathbf{X},\mathbf{A})p(\mathbf{A})\)</span>，这里我们使用VI【11】的方法来对其进行估计。</p><p><strong>变分分布</strong></p><p>假设graph中每条边存在与否服从的伯努利分布是独立的，则后验分布的变分分布有如下的形式：</p><p><span class="math display">\[q_{\mathbf{\phi}}(\mathbf{A})=\prod_{ij}q(A_{ij})\quad\text{with}\quadq_{\mathbf{\phi}}(A_{ij})=Bern(A_{ij}|\rho_{ij})\]</span></p><p><span class="math inline">\(\mathbf{\phi}\)</span>表示的是变分分布的可训练参数，在上面的形式中，可以看到，这个参数就是<span class="math inline">\(\mathbf{\phi}={\rho_{ij}}\)</span>，这称为<strong>“free” parameterization</strong>。</p><blockquote><p>如果我们有1000个nodes，则我们设置的参数的数量是1000000，也就是说free parameterization带来的是参数数量的过多。</p><p>实际上条件独立性是一个非常强的假设，这也是不符合实际的，这也是导致参数数量过多的一个原因。大量的参数<span class="math inline">\(\rho_{ij}\)</span>实际上是高度相关的，比如说参数<span class="math inline">\(a_1\)</span>和<span class="math inline">\(a_2\)</span>高度相关，则当我们进行梯度下降进行训练的时候，更新<span class="math inline">\(a_1\)</span>或<span class="math inline">\(a_2\)</span>都会得到相似的结果，这反而平摊了整个效应，或者导致梯度的剧烈震荡和不稳定。</p><p>在supplementary中，fig2也证明了以上的观点。</p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-25-16-34-27.png"><br></p></blockquote><p>相对的，有以下的设置方法，称为<strong>"smooth" parameterization</strong>：</p><p><span class="math display">\[\rho_{ij}=\sigma(\mathbf{z}_i^T\mathbf{z}_j+b_i+b_j+s),\quad\mathbf{z}_i\in\mathbb{R}^d,\quad\{b_i,s\in\mathbb{R}\}\quadi,j=1,\dots,N\]</span></p><blockquote><p>我们可以看到，实际上，这里就是尽量使用较少的参数来生成<span class="math inline">\(\rho_{ij}\)</span>。如果将上面的式子写成矩阵形式，即： <span class="math display">\[\Rho=\sigma(\mathbf{Z}^T\mathbf{Z}+B\mathbf{1}^T+\mathbf{1}B^T+s)\]</span> 其中<span class="math inline">\(\mathbf{Z}=(\mathbf{z}_1,\dots,\mathbf{z}_N)^T\)</span>，<span class="math inline">\(B=(b_1,\dots,b_N)^T\)</span>，<span class="math inline">\(\mathbf{1}=(1,\dots,1)^T\)</span>。 其实就是使用低秩矩阵，并且通过dot-product来构造这个低秩矩阵，使得参数之间存在相关。</p></blockquote><p>现在，我们开始来最小化ELBO来得到<span class="math inline">\(\mathbf{\phi}\)</span>的估计，其中最general的方法是score function method【22】，其使用Monte Carlo方法得到了梯度的无偏估计，但方差太大【23】。</p><p>另外一条路，则是使用re-parameterization trick【13,24】，其会极大地降低估计的方差。但不幸的是，这无法应用到离散分布中。所以我们采用【10,16】的Concrete distributions：</p><p><span class="math display">\[q_{\phi}(\mathbf{A}_{ij})=BinConcrete(\mathbf{A}_{ij}|\rho_{ij},\tau)\]</span></p><blockquote><p>gambel-softmax采样【10】的改进。</p></blockquote><blockquote><p>这里我们对BinConcrete的形式进行一定的介绍，详细请见其原文【16】：</p><p><span class="math display">\[A_{ij}\sim BinConcrete(\lambda_{ij},\tau)\quad\Leftrightarrow\quadA_{ij}=\sigma(B_{ij}),B_{ij}\sim Logistic(\frac{\log\lambda_{ij}}{\tau}, \frac{1}{\tau})\]</span></p><p><span class="math display">\[B_{ij}\sim Logistic(\frac{\log\lambda_{ij}}{\tau}, \frac{1}{\tau})\quad\Leftrightarrow\quadB_{ij}=\frac{\log\lambda_{ij}+L}{\tau},L\sim Logistic(0,1)\]</span></p><p><span class="math display">\[L\sim Logistic(0,1)\quad\Leftrightarrow\quadL=\sigma^{-1}(U)=\log U-\log(1-U),U\sim Uniform(0,1)\]</span></p><p>综合上面的式子，我们得到：</p><p><span class="math display">\[A_{ij}\sim BinConcrete(\lambda_{ij},\tau)\quad\Leftrightarrow\quadA_{ij}=\sigma(\frac{\log\lambda_{ij}+\sigma^{-1}(U)}{\tau}),U\sim Uniform(0,1)\]</span></p><blockquote><p>这里对Logistic分布进行一些简单的介绍，便于理解：</p><p>Logistic分布的累积分布函数就是logistic函数的变体，其导函数就是其密度函数，呈现中间高两头低的效果，类似正态分布。</p><p><span class="math display">\[F_{\mu,\sigma}(x)=\frac{1}{1+e^{-\frac{x-\mu}{\sigma}}}\]</span> <span class="math display">\[f_{\mu,\sigma}(x)=\frac{1}{\sigma}e^{-\frac{x-\mu}{\sigma}}[1+\exp\{-\frac{x-\mu}{\sigma}\}]^{-2}\]</span></p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-25-20-21-59.png"><br></p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-25-20-22-13.png"><br></p><p>其类似正态分布，也是location-scale决定了其所有性质。当<span class="math inline">\(\mu=0,\sigma=1\)</span>时，得到的是标准logistic分布，</p><p><span class="math display">\[F(x)=\frac{1}{1+e^{-x}}\]</span> <span class="math display">\[f(x)=e^{-x}[1+e^{-x}]^{-2}\]</span></p><p>其图像如下：</p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-25-20-23-52.png"><br></p><p>根据“逆分布函数采样法”，我们只要找到<span class="math inline">\(F(x)\)</span>的反函数，我们就可以进行采样，而其反函数是非常好计算的：</p><p><span class="math display">\[F^{-1}(x)=\log x-\log(1-x)\]</span></p></blockquote></blockquote><p><strong>ELBO</strong></p><p><span class="math display">\[\mathcal{L}_{ELBO}(\mathbf{\phi})=\mathbb{E}_{q_{\phi}}{\log p_{\mathbf{\theta}}(\mathbf{Y}^o|\mathbf{X},\mathbf{A})}-KL[q_{\phi}(\mathbf{A})||p(\mathbf{A})]\]</span></p><p>其中<span class="math inline">\(p(\mathbf{A})\)</span>是prior。</p><p>进一步，我们将不同分布的的KL散度的具体计算：</p><p>对于两个binary discrete distributions <span class="math inline">\(q(a|\rho)\)</span>和<span class="math inline">\(p(a|\rho^o)\)</span>：</p><p><span class="math display">\[KL[q(a|\rho)||p(a|\rho^o)]=\rho[\log\rho-\log\rho^o]+(1-\rho)[\log(1-\rho)-\log(1-\rho^o)]\]</span></p><p>根据上面的式子，我们可以写出ELBO的re-parameterized version：</p><p><span class="math display">\[\begin{aligned}    \mathcal{L}_{ELBO}(\phi)&amp;=    \mathbb{E}_{q_{\phi,\tau}(\mathbf{A})}[        \log p_{\mathbf{\theta}}(\mathbf{Y}|\mathbf{X},\mathbf{A})-        \log\frac{q_{\phi,\tau}(\mathbf{A})}{p_{\tau_o}(\mathbf{A})}] \\    &amp;=\mathbb{E}_{g_{\phi,\tau}(\mathbf{B})}[        \log p_{\mathbf{\theta}}(\mathbf{Y}|\mathbf{X},\sigma(\mathbf{B}))-        \log\frac{q_{\phi,\tau}(\sigma(\mathbf{B}))}        {p_{\tau_o}(\sigma(\mathbf{B}))}    ] \\    &amp;=\mathbb{E}_{g_{\phi,\tau}(\mathbf{B})}[        \log p_{\mathbf{\theta}}(\mathbf{Y}|\mathbf{X},\sigma(\mathbf{B}))-        \log\frac{q_{\phi,\tau}(\sigma(\mathbf{B}))}        {f_{\tau_o}(\mathbf{B})}    ]\end{aligned}\]</span></p><p>其中 <span class="math display">\[g_{\phi,\tau}(\mathbf{B})=Logistic(B_{ij}|\frac{\log\lambda_{ij}}{\tau},\frac{1}{\tau}),\quadf_{\tau_o}(B_{ij})=Logistic(B_{ij}|\frac{\log\lambda_{ij}^o}{\tau_o},\frac{1}{\tau_o})\]</span></p><p><strong>predict</strong></p><p>预测时，使用下面的式子：</p><p><span class="math display">\[p(\mathbf{Y}^{u}|\mathbf{Y}^o,\mathbf{X})=\sum_{\mathbf{A}}{    p_{\mathbf{\theta}}(\mathbf{Y}^{u}|\mathbf{X},\mathbf{A})    p(\mathbf{A}|\mathbf{Y}^o,\mathbf{X})\approx    \frac{1}{S}\sum_{s=1}^S{        p_{\mathbf{\theta}}(\mathbf{Y}^u|\mathbf{X},\mathbf{A}^{(s)})    }}\]</span></p><p>其中<span class="math inline">\(\mathbf{A}^{(s)}\)</span>是从后验分布<span class="math inline">\(q_{\phi}(\mathbf{A})\)</span>中的采样，而<span class="math inline">\(p_{\theta}(\mathbf{Y}^u|\mathbf{X},\mathbf{A})\)</span>是通过GCN得到的likelihood。</p><h2 id="results">Results</h2><h3 id="数据集">数据集</h3><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-26-09-46-10.png"><br></p><ul><li>citation network的节点是文档，边表示两篇文章之间是否引用，节点类别是文章的subject。</li><li>TWITTER的节点是Twitter user，边表示用户转换过另外一个用户的推文，每个节点的特征是用户的行为和用户的tweet texts，节点的类别是用户的hatefulness status。</li></ul><p>我们corrupt网络，通过增加一些fake links，增加的fake links的数量与存在的边的数量的比例是固定的，这个参数称为corruption factor。</p><h3 id="实现细节">实现细节</h3><p>对于先验分布的smoothing parameters，这里探索了多个：<span class="math inline">\(\bar{\rho}_1=\{0.25,0.5,0.75\},\bar{\rho}_0=10^{-5}\)</span></p><p>对于standard GCN，使用的就是标准的2层GCN网络，最小化cross-entropy来进行训练，并使用了dropout、L2regularization、Glorot weight initialization和row-normalization of input-feature vectors。超参数使用【15】中效果的最好的那一组（dropout rate=0.5，L2 regularization=<span class="math inline">\(5\times10^{-4}\)</span>，16 hidden units）。使用Adam optimizer（lr=0.01）。</p><p>GAT，使用是【26】中的架构：第一层K=8，隐层变量的维度F=8，激活函数是ELU，第二层直接进行分类。L2=0.0005，dropout=0.6。</p><p>GraphSAGE，使用mean aggregator functions，邻接点采样深度K=2，邻接点数量S1=S2=32，dropout=0.5、L2=0.0005。</p><p>对于本研究的方法，GCN使用的设置与上面的相同。对于先验分布的smoothing parameters，这里探索了多个：<span class="math inline">\(\bar{\rho}_1=\{0.25,0.5,0.75\},\bar{\rho}_0=10^{-5}\)</span>。<span class="math inline">\(\mathbf{Z}\)</span>的维度是<span class="math inline">\(N\times1000\)</span>，<span class="math inline">\(b_i\)</span>和<span class="math inline">\(s\)</span>被初始化为<span class="math inline">\(0\)</span>和<span class="math inline">\(-20\)</span>，temperatures被设置为<span class="math inline">\(\tau_0=\tau_1=0.1\)</span>。训练的epoches数是5000，进行梯度估计时的采样数是<span class="math inline">\(S=3\)</span>。</p><h3 id="结果">结果</h3><p>比较的指标是test上的acc和mean log likelihood，两个指标都是越高越好。</p><p>CITESEER和CORA的结果如下：</p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-30-08-29-26.png"><br></p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-30-08-36-42.png"><br></p><p>可以看到，当有较高噪声干扰的时候，该方法的效果是显著的。</p><p>进一步，本研究探索了hidden units数量（Q）和构建图时使用的邻居数（K）对性能带来的影响，这里横坐标是Q-K：</p><blockquote><p>这里构建网络的方法参照【9】，即使用一个单隐层的NN（隐层节点数为16或32），带有dropout=0.5，然后我们将隐层节点取出，利用其构建一个graph。</p></blockquote><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-30-08-40-41.png"><br></p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-30-08-44-00.png"><br></p><p>至于TWITTER数据的结果：</p><p><img src="/2020/09/25/paper/dl/paper-gcn2019/paper-GCN2019_2020-09-30-08-45-03.png"><br></p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Semi-Supervised Learning </tag>
            
            <tag> Variational Inference </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-DeepGCNs-2019</title>
      <link href="/2020/09/25/paper/dl/paper-deepgcns2019/"/>
      <url>/2020/09/25/paper/dl/paper-deepgcns2019/</url>
      
        <content type="html"><![CDATA[<h1 id="deepgcns-can-gcns-go-as-deep-as-cnns">DeepGCNs: Can GCNs Go as Deep as CNNs?</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>因为non-Euclidean数据的大量增加以及CNNs在上面的不良表现，GCNs收到了更大的关注；</p></li><li><p>GCNs的应用：社会网络关系预测【36】、建模蛋白质【54,40】、提高推荐系统的预测准确性【24,50】，有效分割点云【42】；</p></li><li><p>CNNs成功的一个重要因素是可以训练非常深的CNNs，但这还无法应用于GCN【19,43,53】，这会引起vanishing gradient problem，即反向传播会导致过度平滑，导致graph上学习到的特征区域相同的值【19】，所以大多数的GCNs不会超过4层；</p></li><li><p>梯度消失在CNNs中也出现过，但ResNet、DenseNet等的提出解决了这些问题；而至于多层多pooling导致的spatial信息丢失则通过Dilated Conv【51】得到解决；</p></li><li><p>本研究希望将上述3个想法应用到GCNs领域，来解决GCNs的问题。将得到的非常深的GCNs（56层）应用于point cloud semantic segmentation（S3DIS），得到了非常大的提升（3.7%）；</p></li><li><p>贡献：</p><ol type="a"><li>将residualconnections，dilated conv整合到了GCNs中；</li><li>在point cloud data上显示了这个深度GCNs的效果；</li></ol></li></ol><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-35-20.png"><br></p><h3 id="相关工作">相关工作</h3><ol type="1"><li><p>GCNs的应用：上面提到了一些，这里再补充一些</p><ol type="a"><li><p>自然语言处理【2,23】；</p></li><li><p>GCNs在图像的应用：进行分割的时候，一般对象间的关系使用graph来描述，可以用来预测场景中各个对象间的关系【30,44,48,20】，或者通过各个对象间的关系生成一张图【17】；</p></li><li><p>在视频中识别人体的关节【47,16】；</p></li><li><p>GCNs处理点云数据，【35,9,3,22,5,28,32,37】试图将点云数据表示成graph，而【27,29,8,14,49】则试图直接处理点云数据；</p><p>这里点云数据就是使用三维坐标描述的点集合，可以利用最近邻、分块等技术来构建点和点之间的graph。</p><p>EdgeConv【42】就是使用GCNs来处理点云，使用距离在每一层动态地计算每个点的最近邻，显示了GCNs处理点云数据的能力（本研究正是在【42】的基础上进行的）；</p></li></ol></li><li><p>Deeper GCNs：</p><ol type="a"><li><p>【18】表示在超过3层的时候，GCNs在半监督节点分类任务上会变得不好；</p></li><li><p>【26】提出了Column Network，最佳分类效果是10层；</p></li><li><p>【31】使用了Highway GCN应用于社交媒体地理位置建模，但发现6层的时候效果最好；</p></li><li><p>【46】提出了Jump Knowledge Network进行表示学习，也只能到6层；</p></li><li><p>【19】研究了GCNs的深度问题，发现深度的GCNs会导致over-smoothing问题，导致每个连接的点内的特征会趋向于相同的值；</p></li><li><p>【43,53】等也显示出堆叠过多的GCN layers会导致复杂的梯度和梯度消失等问题；</p></li></ol></li><li><p>这里特别提一下Dilated conv，其通过提高感受野的方法，使得卷积得到的分辨率较低但没有使用pooling，防止了信息的丢失；</p></li></ol><h2 id="methods">Methods</h2><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-34-15.png"><br></p><h3 id="图上的表示学习">图上的表示学习</h3><p>这里使用的理论框架是：</p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-20-35.png"><br></p><p>其中aggregate过程是将节点及其邻接点的信息结合，update则是将得到的信息使用非线性函数计算新的节点表示。</p><ol type="1"><li><p>aggregate可以是mean【18】、max-pooling【27,10,42】、attention【39】、LSTM【25】；</p></li><li><p>Update可以是multi-layer perception【10,7】、gated network【21】等；</p></li></ol><p>下面是更加具体的公式：</p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-21-15.png"><br></p><p>其中<span class="math inline">\(\rho\)</span>是aggregate函数，<span class="math inline">\(\phi\)</span>是update。</p><p><strong>在本研究中，使用的aggregate是max-pooling of difference，因为没有学习参数：</strong></p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-22-02.png"><br></p><p><strong>使用的update是一个MLP，使用BN和relu，其输入是原始节点信息<span class="math inline">\(\mathbf{h}_{vl}\)</span>和上面的<span class="math inline">\(\rho\)</span>函数得到的值。</strong></p><h3 id="动态边">动态边</h3><ol type="1"><li><p>大多是GCNs使用的都是固定的graph，而只更新节点特征，而最近的一些研究可以在每一层动态的改变网络的连接模式，学习到更多的特征；</p></li><li><p>ECC【34】使用dynamic edge-conditional filters去学习一个edge-specific weight matrix，EdgeConv【42】则使用最近邻来建立一个graph进行图卷积操作，Graph-Convolution GAN【38】也是这个思想；</p></li><li><p>本研究发现在GCNs中动态地改变邻接点可以有效缓解over-smoothing的问题，并有更大的感受野，所以在本研究中，<strong>通过Dilated k-NN函数在每一层重新计算节点间的边</strong>，只有Dilated k-NN将在下面进行介绍。</p></li></ol><h3 id="gcns上的residual-link">GCNs上的residual link</h3><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-25-54.png"><br></p><p>特征是vertex-wise addition的。</p><h3 id="gcns上的dense-link">GCNs上的dense link</h3><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-26-42.png"><br></p><p>其中操作<span class="math inline">\(\mathcal{T}\)</span>表示vertex-wise concatenation操作，因为上一层也会将上上一层concat，所以在第<span class="math inline">\(l\)</span>层就是将之前所有层的结果都concat到了一起； 注意到，不然输入是多少，<span class="math inline">\(\mathcal{F}\)</span>函数在每个节点上的输出都是<span class="math inline">\(D\)</span>维度的，所以在第<span class="math inline">\(l+1\)</span>层上节点特征的维度是<span class="math inline">\(D_0+D×(l+1)\)</span>。</p><h3 id="gcns的dilated聚合">GCNs的Dilated聚合</h3><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-34-57.png"><br></p><ol type="1"><li><p>Dilated wavelet conv来自于小波领域【12,33】，为了避免pooling带来的信息损失，【51】提升了dilated conv来解决，因为其没有分辨率的损失但提高了感受野，在图像分割等领域应用比较多；</p><blockquote><p>因为一般conv filters都会一次用很多个做，所以第一个conv filter没有识别到的信息可以用第二个conv filter来识别，但如果做了pooling，那损失了的信息这些filters是都看不到的</p></blockquote></li><li><p>本研究提出了Dilated k-NN来在每一层寻找dilated neighbors并构建Dilated Graph，</p><ol type="a"><li><p>首先通过当前空间中的距离（本研究使用的是l2）来定义每个节点的neighbors；</p></li><li><p>如果定义的dilated rate是<span class="math inline">\(d\)</span>，考虑的邻居数量是<span class="math inline">\(k\)</span>，则先对每一个节点找到和其最近的<span class="math inline">\(k\times d\)</span>个邻居，并排序 <span class="math inline">\((u_1,u_2,\dots,u_{k\times d})\)</span>。</p></li><li><p>然后每隔<span class="math inline">\(d\)</span>个邻居选择一个出来，得到的邻居集合是</p><p><span class="math display">\[\mathcal{N}^{(d)}(v)=\{u_1,u_{1+d},u_{1+2d},\dots,u_{1+(k+1)d}\}\]</span></p></li><li><p>然后上述节点和v节点有边相连，边的方向是从v指向这些邻居节点；</p></li><li><p>对所有的节点进行上述操作，得到一张图；</p></li></ol></li><li><p>为了增加泛化能力，这里使用的是stochastic dilation：</p><ol type="a"><li><p>training：即用高概率<span class="math inline">\(1-\epsilon\)</span>来实施上面叙述的dilated操作，而比较小概率对于一些节点使用随机dilated操作（从<span class="math inline">\(k\times d\)</span>个邻居中随机采样<span class="math inline">\(k\)</span>个邻居）；</p></li><li><p>testing：没有随机性了，就是使用上面提到的确定性的dilated策略；</p></li></ol></li></ol><h2 id="results">Results</h2><h3 id="实验设置">实验设置</h3><ol type="1"><li><p>使用的图是通过上面叙述的dilated k-NN来得到的，并且是在特征空间中创建的；</p></li><li><p>预测的是每个点的类别；</p><p>评价指标是overall acc（OA）和mean intersection over union（mIoU）在所有类别上，其中IoU计算为 <span class="math inline">\(TP/(TP+T-P)\)</span>。</p><p>其中<span class="math inline">\(TP\)</span>是true positive points，<span class="math inline">\(P\)</span>是预测positive的points，<span class="math inline">\(T\)</span>是真实positive的points；</p></li></ol><h3 id="实现细节">实现细节</h3><p>所有的网络架构都包含3个部分：GCN backbone block、fusion block和MLP prediction block，3种网络架构只在GCN backbone block上有连接模式的差别，但参数数量是一致的，因为这里使用的是图像，所以实现全连接都是使用1x1conv实现的。</p><ol type="1"><li><p>GCN backbone block的输入维度都是4096个点，输出也是4096个点：</p><ol type="a"><li><p>其dilation rate是随着深度增加而线性增加的；</p></li><li><p>对于PlainGCN，是堆叠了28个EdgeConv【42】，使用的是dynamic k-NN，每个和DGCNN【42】使用的类似；</p></li><li><p>对于ResGCN，是每个EdgeConv的输出和输入会加在一起再往下计算；</p></li><li><p>对于DenseGCN，是将之前所有EdgeConv的输出都concat到一起在往下计算的，可能为了保证参数的相同，除了第一层其他层的filters数量是前面的一半，变成了32（但实际上我进行了简单的计算，发现其参数也是比较多的）；</p></li><li><p>注意到，所有GCN layers的输出都会最终被concat在一起输出，不管使用的是哪个网络结构；</p></li></ol></li><li><p>Fusion block【27,42】是用来将global信息和multi-scale local信息进行融合的：</p><ol type="a"><li><p>首先将GCN backbone block的输出经过一个1x1 conv，映射到1024的维度，然后在整个图上将4096个batch size x 1024的矩阵进行global max-pooling，得到一个batch size x 1024的矩阵表示global information；</p></li><li><p>将这个信息concat到GCN backbone block的输出中去，就是在每个节点的特征矩阵后面再concat这个batch size x 1024矩阵；</p></li></ol></li><li><p>MLP prediction是3层，依次得到512、256、13的输出维度，给每个节点进行分类</p></li></ol><p>其他：</p><ol type="1"><li>使用Tensorflow，两张Tesla V100，每张batch size是8；</li><li>Adam，lr=0.001，每经过300000 steps学习率降低50%；</li><li>每一层使用BN，在MLP的第二层使用0.3的dropout；</li><li>对于dilated k-NN，其<span class="math inline">\(\epsilon=0.2\)</span>；</li><li>没有用任何的数据增强和预训练技术，端对端的进行训练；</li></ol><blockquote><p>PyG中已经有此模型的实现。</p></blockquote><h3 id="结果">结果</h3><p>进行了不同参数的探索，其结果在tab1中，因为ResGCN-28训练比较快，所以各种超参数的探索是基于此做的，但应该DenseGCN也是符合的。</p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-42-31.png"><br></p><ul><li><p><strong>residual link</strong></p><p>从tab1中可以看出，不管是什么样的配置，只要去掉了残差连接，那么都会导致mIoU的下降，和reference值相差一个残差连接的下降了12.02的mIoU。</p></li><li><p><strong>dilation</strong></p><p>使用dilation会导致IoU的提高（row 2 vs 3），得到了2.85的提升；</p><p>实际性的实施并没有很大的提升（row1 vs 2），0.51；</p><p>如果没有残差连接或dense连接，dilation反而会导致性能的降低（row 1 vs 8），这解释为梯度的不正确所导致的。</p></li><li><p><strong>Dynamic k-NN</strong></p><p>固定住边，而且没有使用dilation，会有4.11的下降（row1 vs 5）；</p><p>如果进一步去掉残差连接，其效果下降的更大了。</p></li><li><p><strong>dense link</strong></p><p>为了适应内存，所以使用了8邻居、32filters的设置，发现了ResGCN效果差不多；</p><p>但因为效率的问题，还是使用ResGCN更好。</p></li><li><p><strong>other</strong></p><ul><li>邻居越多确实可以提高性能;</li><li>深度增加可以提高预测性能；</li><li>这里的宽度是filters的大小，宽度增加可以提升性能；</li></ul></li></ul><p>定性结果见fig4，显然ResGCN-28和DenseGCN-28要好于PlainGCN-28。</p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-50-40.png"><br></p><p>另外，也和state-of-the-art进行了比较，如下：</p><p><img src="/2020/09/25/paper/dl/paper-deepgcns2019/paper-DeepGCNs2019_2020-09-25-14-51-31.png"><br></p><blockquote><p>这里使用死的是EdgeConv，后面本研究又对其他4种GCN结构（GCN、SAGE、GIN、MRGCN）进行了相同的处理，即通过res、dynamic k-NN graph来对他们进行加深，发现确实都提示他了其效果，相关内容见文章的附录。</p></blockquote><h2 id="conclusion">Conclusion</h2><ol type="1"><li><p>即便使用比较小的邻居数量，但因为使用了dilated技术，也能够有比较高的表现；</p></li><li><p>还训练了ResGCN-151 80个epoch，其只是用了3个邻居，但得到了和ResGCN-28和ResGCN-56相似的结论；</p></li><li><p>除了能够解决了over-smoothing的问题，网络加深、加宽还可以提升性能；</p></li><li><p>未来可能更多的将CNN领域的一些成功技术转移到GCN领域，比如deformable conv【6】、比如feature pyramid architectures【52】等其他架构，也可以考虑使用其他的距离来度量邻居，在每一层使用不同数量的邻居，更好的dilation策略【4,41】等；</p></li><li><p>对于点云语义分割的特定任务，使用1m x 1m的处理数据的形式并不是最佳的，应该探索更合适的形式。</p></li></ol><hr><h2 id="questions">Questions</h2><ol type="1"><li>这里根据resnet的思想，一般经过多层的映射后才实行残差连接的，这里只进行一层效果好吗？</li><li>这里对于GCN block的详细配置没有说明，只是指出其和DCGCN类似，这必须通过看代码来知道了。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Netowrks </tag>
            
            <tag> Point Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-Point-GNN-2020</title>
      <link href="/2020/09/22/paper/dl/paper-pointgnn2020/"/>
      <url>/2020/09/22/paper/dl/paper-pointgnn2020/</url>
      
        <content type="html"><![CDATA[<h1 id="point-gnn-graph-neural-network-for-3d-object-detection-in-a-point-cloud">Point-GNN: Graph Neural Network for 3D Object Detection in a Point Cloud</h1><ul><li>杂志: CVPR</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>点云数据是理解3D环境的一个重要的数据形式，但其稀疏、不规则的特性使得其无法以常规的手段（如CNN）处理它。（或者会耗费大量的计算）</p></li><li><p>最近的在NN方面的突破【3,22】使得开始可以处理点云数据，但这些方法大多需要进行迭代的sample和group来得到point set representation，计算非常昂贵。</p><p>最近的3D detection技术还会混合grid和set的技术【10,21,16】，但这些技术也显示出其不足。</p></li><li><p>在本研究中，我们使用graph来对点云进行表示，并设计了一个新的GNN称为Point-GNN来进行目标检测。为了能够降低GNN的translation variance，这里使用了一个auto-registration的机制。另外还设计了box merging和scoring operation从多个点整合detection结果。</p><p>【15,9,2,17】已经验证了使用GNN进行分类和分割点云的能力，但使用GNN进行3D目标检测还是比较少的。</p></li></ol><h3 id="相关工作">相关工作</h3><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-22-21-23-30.png"><br></p><ul><li><p>grids点云</p><p>将点云数据转换成规则的grid数据，然后使用CNN。</p><ul><li>【20】将点云数据转换到2D bird‘s eye view（BEV），然后使用2DCNN进行目标检测。</li><li>【4】将点云数据转换到BEV和Front View（FV）然后使用2DCNN。</li><li>【23】将点云转换成3D voxels数据，然后使用3DCNN。但这计算花费太高了。</li><li>【19】继承上面的研究，使用sparse convolution减小计算花费。</li></ul></li><li><p>set点云</p><ul><li>【3,22】（PointNet、DeepSet）对每个点使用MLP来得到point feature，然后使用average或max来得到global feature。</li><li>【14】进一步提出对point features进行层次的聚合以提取局部信息。</li></ul><p>虽然以上的算法避免了映射成grids，但sampling和grouping也增加了另外的计算开销。</p><p>大多数目标检测的算法都将以上的NN当做整个pipeline的一部分：</p><ul><li>【13】从camera images中生成object proposals，然后使用【14】的算法分割点云并预测bounding box。</li><li>【16】直接使用【14】作为backbone来生成bounding box，然后使用second-stage point network来refine bounding box。</li><li>【23,19,10,21】都使用【3】来从local point sets中提取特征。</li></ul></li><li><p>graph点云</p><p>相比于基于set的操作，graph能够保证通过edge的连接来实现更复杂的操作，而且也不需要进行sampling和grouping。</p><ul><li>【15】使用recurrent GNN在RGBD数据上进行语义分割。</li><li>【9】将点云划分成简单的几何图形</li><li>【2,17】直接使用GNN对点云进行分类</li></ul><p>但使用GNN对点云进行目标检测的还非常少。</p></li></ul><h2 id="methods">Methods</h2><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-23-14-47-20.png"><br></p><h3 id="构建graph">构建graph</h3><p>点云<span class="math inline">\(P=\{p_1,\dots,p_N\}\)</span>，其中<span class="math inline">\(p_i=(x_i,s_i)\)</span>，<span class="math inline">\(x_i\in\mathbb{R}^3\)</span>是点的3D坐标，<span class="math inline">\(s_i\in\mathbb{R}^k\)</span>是点的k维特征，表征点的属性（比如反射的激光强度和编码等）。</p><p>我们定义一个graph <span class="math inline">\(G=(P,E)\)</span>，其中</p><p><span class="math display">\[E=\{(p_i,p_j)|||x_i-x_j||_2\lt r\}\]</span></p><p><span class="math inline">\(r\)</span>是一个固定的半径，即认为如果两个点距离小于此，则认为两者相连。</p><p>正常来说，一个点云会有数万个点，如果全使用，会导致较高的计算负担。所以这里使用voxel downsample点云（follow 【10,23】，使用MLP和Max func来提取特征），之后再建立graph。</p><h3 id="带有auto-registration机制的gnn">带有Auto-Registration机制的GNN</h3><p>GNN的更新机制为：</p><p><span class="math display">\[\begin{aligned}    v_i^{t+1}&amp;=g^t(\rho(\{e_{ij}^t|(i,j)\in E\}), v_i^t) \\    e_{ij}^t&amp;=f^t(v_i^t,v_j^t)\end{aligned}\]</span></p><blockquote><p>这个表示可能比massage passing的一般表示更加general一些，但大体上，两者可以算作是一样的东西。比如我们把<span class="math inline">\(e_{ij}\)</span>的内容写到前一个式子中，则整个公式将和massage passing一致。</p></blockquote><p>本研究使用的GNN的更新机制为：</p><p><span class="math display">\[s_i^{t+1}=g^t(\rho(\{f^t(x_j-x_i,s_j^t)\}), s_i^t)\]</span></p><p>即我们不光考虑邻接点的特征，而且还要考虑邻接点相对于更新的节点的相对位置。使用相对位置使得我们在全局上保持了一个平移不变性，但在局部依然有一定的问题。<strong>如果目标节点的坐标出现一个小小的移动，则其邻接点相对于其的坐标都会发生变化，尽管这可能与之前并没有什么不同。</strong></p><p>为了解决上面的问题，这里认为有部分信息储存在其属性特征中，所以我们需要进一步利用这些特征来校正相对位置，所以使用下面的auto-registration机制：</p><p><span class="math display">\[\begin{aligned}    \Delta x_i^t&amp;=h^t(s_i^t) \\    s_i^{t+1}&amp;=g^t(\rho(\{f(x_j-x_i+\Delta x_i^t)\}), s_i^t)\end{aligned}\]</span></p><p>如果fig2中所示，这里的<span class="math inline">\(f^t,g^t,h^t\)</span>都使用MLP来拟合，而<span class="math inline">\(\rho\)</span>则使用Max，<span class="math inline">\(g^t\)</span>上加上一个residual link。</p><p>当经过<span class="math inline">\(T\)</span>层的迭代计算后，使用两个MLP基于节点特征分别预测类别和bounding box。</p><h3 id="损失函数">损失函数</h3><p>作为目标检测，损失函数包括两个部分，即分类部分和bounding box regression的部分。</p><ul><li><p>classification，对于每个点，其都会被分配一个类别：如果其存在在某一类的bounding box中，则其属于此类；如果其不属于任何物体的bounding box中，则属于background类。</p><p>然后对每个点使用交叉熵损失即可。</p></li><li><p>bounding box regression。</p><p>对于每个点，我们需要预测7个值：其中3个表示bounding box的中心节点，另外3个表示bounding box的长宽高，还有一个表示box的yaw angle（偏航角）。</p><p>当然，这个我们回归的是相对值：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-23-16-06-31.png"><br></p><p>如果该点在box内，则我们计算ground truth和其预测的Huber loss【7】，否则为0。所以其公式可以表示为：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-23-16-08-17.png"><br></p></li></ul><p>最后，我们在加上权重项的L1正则化以防止over-fitting：</p><p><span class="math display">\[l_{total}=\alpha l_{cls} + \beta l_{loc} + \gamma l_{reg}\]</span></p><h3 id="box-merging-and-scoring">Box Merging and scoring</h3><p>因为会有许多的点在同一个bounding box中，所以会导致有大量重合的bounding box prediction，所以我们需要使用NMS来选择出其中得分最大的那个，而去抑制其他的boxes。</p><p>但使用分类的分数并不足以反应定位的质量，比如被遮挡的物体，其分类的分数最高的框可能并不是最正确的那个框。所以这里使用一种新的算法来替代NMS：</p><ul><li><p>计算多个重叠框的median作为最终的结果(boxes)，而不是分类概率最大的那个。</p></li><li><p>boxes的confidence score由最终结果和重叠框的IoU和重叠因子计算而来，重叠因子的算法为：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-06-55.png"><br></p></li></ul><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-23-16-48-32.png"><br></p><h2 id="results">Results</h2><h3 id="数据集">数据集：</h3><p>KITTI【6】，7481 training samples，7518 testing samples，每个都有point cloud和camera image。</p><p>评价指标是Car、Pedestrian（行人）和Cyclist（自行车）的AP，根据【10,23,19,21】的惯例，为Car训练一个net，为Pedestrian和Cyclist训练一个net。</p><h3 id="实现细节">实现细节</h3><ul><li>T=3（GNN层数）</li><li>训练时每个点的度最大为256，预测时使用所有的edges</li><li>auto-registration的MLP为（64,3）</li><li>分类的MLP为（64，类别数）</li><li>定位的MLP为（64,64,7）</li></ul><blockquote><p>更详细的见原文</p></blockquote><h3 id="数据增强">数据增强</h3><ul><li>global rotation（<span class="math inline">\(\mathcal{N}(0,\pi/8)\)</span>）</li><li>global flipping（x轴，<span class="math inline">\(p=0.5\)</span>）</li><li>box translation and vertex jitter（<span class="math inline">\(\Delta x\sim\mathcal{N}(0,3),\Delta y=0,\Delta z\sim\mathcal{N}(0,3)\)</span>）</li></ul><h3 id="结果">结果</h3><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-18-10.png"><br></p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-18-21.png"><br></p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-19-54.png"><br></p><h3 id="消融实验">消融实验</h3><p>将train set分割成train（3712）和valid（3769），重点只关注Car这个类别。</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-20-50.png"><br></p><p>从上面的表中可以看出，这三种机制不同程度的提高了模型的性能。</p><p>另外，我们进一步可视化了auto-registration机制所带来的影响：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-25-13.png"><br></p><p>本研究也对使用的GNNs的层数进行了研究：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-11-26-02.png"><br></p><p>另外，还探索了scaling line不同所带来的影响，scaling line越多，则点云越密集，自然计算量越大。这里使用k-means来模拟scaling line的减少，结果如下所示：</p><p><img src="/2020/09/22/paper/dl/paper-pointgnn2020/paper-pointgnn2020_2020-09-25-13-51-46.png"><br></p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Point Cloud </tag>
            
            <tag> Graph Nueral Networks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-使用GCN对癌症进行分类-2020</title>
      <link href="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/"/>
      <url>/2020/09/13/paper/omics/paper-gcnclscancertype-2020/</url>
      
        <content type="html"><![CDATA[<h1 id="classification-of-cancer-types-using-graph-convolutional-neural-networks">Classification of Cancer Types Using Graph Convolutional Neural Networks</h1><ul><li>杂志: frontiers in physics</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/RicardoRamirez2020/GCN_Cancer" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>癌症早期筛检和分类有助于提高患者的生存概率。</p></li><li><p>现在很多机器学习方法被应用到公开数据库进行分析：</p><ul><li><p>使用TCGA数据，K近邻进行基因选择和癌症分类，并达到了90%以上的准确率【10】</p></li><li><p>使用fully connected deep neural networks，在tumor samples（6703）和normal samples（6402）上进行训练，并评估了各个基因对最终分类的贡献【12】</p></li><li><p>【13】使用CNN对2-dimensional mapping of the gene expression进行癌症分类，并达到了超过95%的准确率</p><p>具体其实就是将10381个genes映射到染色体位置上，并通过补0，将每个样本都reshape成102x102的image</p></li><li><p>【14】本课题组使用一个auto-encoder system将pathways和functional gene-sets进行embedding，然后进行癌症分类</p></li><li><p>【15】本课题组还将TCGA数据随机变换成2-D data，使用CNN进行预测，也达到了95%的准确率</p></li></ul></li><li><p>但gene与gene之间的调控关系（mRNA水平）还没有被用到。最近GCNs的发展，使得我们可以将这类信息融合到model中：</p><ul><li>使用STRING数据库预测乳腺癌的转移【17-20】</li></ul></li><li><p>另一个问题是去确定重要的标记物</p></li><li><p>本研究使用TCGA数据和4类gene network训练GCNs模型，对癌症进行分类，并进行了变量筛选的研究。</p></li></ol><h2 id="methods">Methods</h2><h3 id="数据集">数据集</h3><ol type="1"><li><p>使用TCGAbiolinks【25】packages下载，共有10340个tumor samples、731个normal samples</p></li><li><p>共有56716个genes，使用指标是<span class="math inline">\(\log_2(FPKM+1)\)</span>。</p><p>为了降低模型的复杂度，这里使用<span class="math inline">\(mean \gt 0.5\)</span>和<span class="math inline">\(std \gt 0.8\)</span>来进行基因筛选，得到7091个genes（拥有最多的信息）</p></li><li><p>然后将所有的表达量水平归一化到0-1之间。</p></li></ol><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-55-22.png"><br></p><h3 id="graphs">Graphs</h3><ul><li><p>Co-expression</p><p>使用MATLAB计算了gene间的spearman correlation【26】，然后令<span class="math inline">\(cor &gt; 0.6\)</span>且<span class="math inline">\(p &lt; 0.05\)</span>为存在一条边连接两个genes</p><p>如果将没有边相连的genes都删除，最后得到只有3866个genes之间的co-expression network，其adjacency matrix记为<span class="math inline">\(W_{co-expr}\)</span></p></li><li><p>PPI</p><p>来自STRING数据库【22,23】</p><p>先把7091个genes都送入BioMart databased，找到其对应的Ensembl protein IDs【27】，然后找到其STRING中的对应关系</p><p>因为非编码gene的存在，最后可以建立PPI network的genes数量是4444，记其adjacency matrix为<span class="math inline">\(W_{PPI}\)</span></p></li><li><p>Singleton Nodes</p><p>上面介绍的两个网络都没有包括所有的7091个genes。这里使用0将<span class="math inline">\(W_{co-expr}\)</span>和<span class="math inline">\(W_{PPI}\)</span>补充到7091x7091的维度，分别作为co-expression+singleton和PPI+singleton networks。</p><blockquote><p>虽然我们使用0来进行的填补，好像这些新补充的genes并不会参与到计算中。但实际上，大多数GCNs实现时，会先将adjacency matrix的对角线补成1，或者更新节点特征的时候单独拿出一部分来考虑自身对其的影响。</p><p>singleton的补充相当于将这些节点直接加到了graph中，作为孤立点存在，补充了一部分的信息</p></blockquote></li></ul><p>这4个网络的基本信息如下：</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-08-11-40.png"><br></p><h3 id="gcn-models">GCN models</h3><p>主要包含这几部分：graph convolutional layers、coarsening or pooling、fc。</p><ul><li><p>ChebConv和GCNConv：略</p></li><li><p>Coarsening (Pooling)</p><p>本研究使用一种贪婪的、简单的图粗化方法，这样每次大约降低一半的节点数量。</p><p>每次选择一个节点和其邻接点加在一起。如果选择到的是singleton node，则随机选择另外一个节点进行加和。</p><blockquote><p>其使用的很有可能是ChebConv中的粗化方法。</p></blockquote></li><li><p>fc和softmax</p></li></ul><p>整个网络结构是一层GCN+两层coarsening+fc（1024 hiddens）+softmax。</p><p>5-CV，训练使用的是Adam，epoch=20，batch size=200。使用基于acc和loss的random search来进行超参数的调整。</p><p>这里需要进行调整的参数即学习率（0.001-0.005）。</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-55-51.png"><br></p><h3 id="计算gene扰动">计算gene扰动</h3><p>即通过对gene添加扰动，查看扰动对预测结果的影响，来评价变量在分类任务中的重要性。【12】</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-13-20-20-08.png"><br></p><ol type="1"><li><p>筛选样本</p><p>将没有任何一类的预测概率<span class="math inline">\(\gt0.5\)</span>的样本去掉，这些样本对于其所属的类别没有足够的代表性。</p></li><li><p>为每个分类（共34类）计算贡献分数</p><blockquote><p>上面的伪代码介绍的更加详细</p></blockquote><p>对于一个样本，将某个gene的值改为0和1，重新计算在该样本的类上的概率，记录变化最大的那个值为score。将某类的所有样本的score都加和在一起，即该gene对该类的贡献分数。</p><p>最终我们得到的贡献分数是一个分类数（34）x genes数量的一个matrix。</p></li><li><p>Normalization</p><p>对于每一类别，将上面得到的贡献得分归一化到0-1之间。</p><p>如果想，还可以将所有的cancer的列别的归一化贡献得分加总，得到一个Overall Cancer的得分。</p></li></ol><h2 id="results">Results</h2><h3 id="预测准确性">预测准确性</h3><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-09-14-40.png"><br></p><ol type="1"><li><p>上图是预测结果。</p><p>PPI model的预测准确性是最低的，其只含有可编码为蛋白质的gene和基于STRING数据库的交互作用。非编码gene没有包括其中，许多其他类型的gene调控也没有被包含其中，这可能导致了其性能较差。</p><p>PPI+singleton model有超过5%的性能提升，提示没有被包括在PPI中的gene可能也起到了重要的作用。</p><p>co-expression model拥有类似PPI+singleton model的性能，增加singleton并没有得到明显的提升。这可能是因为我们co-expression networks中已经包括了一些重要的非编码genes。从另一个方面说，这也说明剩下的这些singleton genes是“不太重要的”，其本身也是没有通过相关性检验的。</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-09-43-59.png"><br></p></li><li><p>在附录中有5-CV训练过程中的loss和acc的收敛情况，用来判断是否存在过拟合。其中使用PPI网络的model拥有最长的收敛时间但最低的validation loss。</p></li><li><p>进一步对co-expression和co-expression+singleton models的结果进行precision-recall分析和confusion matrix分析，发现：</p><ul><li>READ（直肠癌）和COAD（结肠癌）的错分是导致性能降低的关键所在。另外错分比较多的还有CHOL（胆管癌）和LIHC（肝细胞癌）、UCS（子宫癌肉瘤）和UCEC（子宫内膜样癌）。</li><li>以上这些错分都存在两个特点：错分的pair基本都在同一个器官或组织中，每一对pair中都存在一类其样本量非常少</li></ul><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-59-21.png"><br></p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-59-45.png"><br></p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-11-00-05.png"><br></p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-11-00-38.png"><br></p></li></ol><h3 id="癌症特异性">癌症特异性</h3><blockquote><p>因为癌症类型不同一般也意味着组织类型不同，所以我们建立的分类模型可能只是捕获到了其分类组织的信息（即tissue-specific）。这显然不是我们想要的，所以这里是来讨来model捕获到的信息除了tissue-specific，还有cancer-specific。</p></blockquote><p>之前的研究都进行癌症的分类，而且效果都不错【32,10,13】。但这些研究都没有包括normal samples，所以无法判断其分类是tissue-specific还是cancer-specific。最近的研究【12,15】提示可能是cancer-specific的。</p><p>本研究去看了一下normal samples的分类结果：92%，也就是731个中的672个样本都被分对了，无论这些样本来自哪些组织器官，其都被正确分类，说明model使用的更多的是cancer-specific信息。</p><h3 id="建模后分析">建模后分析</h3><p>gene perturbation的方法进行gene筛选，会让那些孤立点更容易被选择，所以这里不使用加了singleton的graph model。又因为PPI graph model的性能比较差，所以这里选择co-expression graph model进行建模后分析。</p><blockquote><p>非孤立点被扰动后，其信息可以有其邻接点信息进行补充。所以其带来的性能的差异可能不会太大，就不容易被选出。</p></blockquote><p>使用0.3的阈值（查看直方图选择的），我们一共找到了428个潜在的biomarks。这些biomarks在每类癌症上的分布：</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-26-52.png"><br></p><p>以breast cancer为例，其排名前20的genes中，前9个gene都是Y染色体相关的，即其学习到了判断乳腺癌的第一个关键是性别。剩下的genes也在breast cancer的研究中报道过。</p><p><img src="/2020/09/13/paper/omics/paper-gcnclscancertype-2020/paper-GCNclsCancerType-2020_2020-09-14-10-32-17.png"><br></p><h2 id="discussion">Discussion</h2><ol type="1"><li><p>本研究使用的genes筛选的标准（mean &gt; 0.5和std &gt; 0.8）是否可靠，GCN model对于此阈值选择的敏感性需要进一步的研究。</p></li><li><p>co-expression graphs建立时使用的阈值（cor &gt; 0.6和 p &lt; 0.05）是最好的那个，如何确定这个阈值可能需要进一步的研究。</p></li><li><p>除了FPKM外，还有TPM。本研究从UCSC TumorMap上下载了TPM数据，并将其和FPKM数据进行了比较。发现不管数值上的、还是依据其进行的co-expression都是非常相似的。所以两者应该会有相似的结果。</p></li><li><p>MI可以捕获到非线性信息，但其计算复杂。</p><p>在之前的研究中【36,37】，比较了MI-based和correlation-based methods之间的表现和效率，correlation-based method表现更好。</p><p>很多研究【38】也认为，gene间的关系大多是线性的、单调的，所以本研究选择使用correlation。</p></li><li><p>我们可以将PPI和其他的gene关系（如调控等）综合成一个完整的graph，进行相关研究。</p><p>一个可行的方法是进行文献数据挖掘，比如【39】。</p></li><li><p>深度学习是纯粹数据驱动的，而如果想要将生物学信息融入其中，可能需要对GNNs进行彻底的修改来完成【40,41】。</p></li></ol><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-NICE-2014</title>
      <link href="/2020/09/10/paper/dl/paper-nice-2014/"/>
      <url>/2020/09/10/paper/dl/paper-nice-2014/</url>
      
        <content type="html"><![CDATA[<h1 id="nice-non-linear-independent-components-estimation">NICE: NON-LINEAR INDEPENDENT COMPONENTS ESTIMATION</h1><ul><li>杂志: ICLR 2015</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>深度学习实际上是一个表示学习，自然带出一个问题：</p><p><strong>什么是好的表示？</strong></p><p>基于最近的研究【Kingma and Welling, 2014; Rezende et al., 2014; Ozair and Bengio, 2014】，本研究认为：</p><p><strong>一个好的表示意味着数据的分布容易被建模。</strong></p></li><li><p>本研究希望能够学习一个transformation（随机变量函数）<span class="math inline">\(h=f(x)\)</span>，可以将数据映射到新的空间，而在新的空间中各成分是独立的：</p><p><span class="math display">\[p_H(h)=\prod_{d}{p_{H_d}(h_d)}\]</span></p><p>如果<span class="math inline">\(f\)</span>是可逆的（invertible）并且输入维度和输入维度相同，则可以得到：</p><p><span class="math display">\[p_X(x)=p_H(f(x))|\det \frac{\partial f(x)}{\partial x}|\tag{1}\]</span></p><p>根据此公式我们可以计算给定<span class="math inline">\(x\)</span>的概率密度（Inference）。</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-10-06-56.png"><br></p><p>如果<span class="math inline">\(f\)</span>的逆映射我们可以得到，则对<span class="math inline">\(X\)</span>进行采样（sample），就可以以下面的形式进行：</p><p><span class="math display">\[h\sim p_H(h),\quad x=f^{-1}(h)\tag{2}\]</span></p><p>而我们进行训练可以以下面的方式，应用极大似然法（learning）：</p><p><span class="math display">\[\max_{f}{\log(p_X(x))}=\max_{f}\{\log(p_H(f(x)))+\log(|\det(\frac{\partial f(x)}{\partial x})|)\}\tag{3}\]</span></p></li><li><p>本研究的贡献在于，经过特殊的设计，可以通过NN来拟合<span class="math inline">\(f\)</span>，并且其计算雅克比行列式和<span class="math inline">\(f^{-1}\)</span>非常方便。</p></li></ol><h3 id="相关研究">相关研究</h3><ul><li><p>DBM【Salakhutdinov and Hinton, 2009】，需要使用MCMC采样，而且无法获得明确的log-likelihood的估计。就算是使用已知最好的技术——annealed importance sampling（AIS）【Salakhutdinov and Murray, 2008】也会过度乐观【Grosse et al., 2013】。</p></li><li><p>至于有向图模型，VAE【Kingma and Welling, 2014; Rezende et al., 2014; Mnih and Gregor, 2014; Gregor et al., 2014】得到了极大的发展。</p><p>但VAE使用的是log-likelihood的变分下界，其得到的可能是一个次优解，使得生成的结果带有更多的噪声，看起来不太自然。</p><p>实际上，NICE可以看做是一类特殊的VAE。其中的encoder是<span class="math inline">\(f\)</span>，decoder是<span class="math inline">\(f^{-1}\)</span>，其KL散度项就是<span class="math inline">\(\log(p_H(f(x)))\)</span>，其entropy项就是<span class="math inline">\(\log(|\det\frac{\partial f(x)}{\partial x}|)\)</span>，反应的是在每一点上局部概率的“膨胀比例”。</p></li><li><p>ICA【Hyvarinen and Oja, 2000】</p></li><li><p>【Rippel and Adams, 2013】提出了学习这些transformations的想法，但因为没有使用双射，所以被迫使用一个带有regularization的AEs来解决的。</p></li><li><p>GAN</p></li><li><p>triangular structure在另外一类density models也出现过——neural autoregressive networks【Bengio and Bengio, 2000】，其最近的成功是NADE【Larochelle and Murray, 2011】。</p><p>但作为一个自回归模型，其在采样的时候是无法并行化的，从而使得其在高维数据上应用有限。</p></li></ul><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-19-47-00.png"><br></p><h2 id="methods">Methods</h2><h3 id="学习">学习</h3><p>这里对learning的过程再进行一下解释。</p><p>分布<span class="math inline">\(p_H(h)\)</span>这里称为prior distribution，如果其实factorial（各个维度是独立的），则此时公式3的估计称为<strong>non-linear independent components estimation（NICE）</strong>。</p><p><span class="math display">\[\max_{f}{\log(p_X(x))}=\max_{f}\{\sum_{d=1}^D\log(p_{H_d}(f_d(x)))+\log(|\det(\frac{\partial f(x)}{\partial x})|)\}\tag{4}\]</span></p><p>我们将后面的Jacobian determinant部分看做是一个正则化项，则作用是：<strong>使得函数<span class="math inline">\(f\)</span>在数据点出现的位置有更高的密度增长，因为<span class="math inline">\(p_H(h)\)</span>是预先固定的，则<span class="math inline">\(f\)</span>变化将把数据点都推到有更高概率密度的地方</strong>。</p><h3 id="架构">架构</h3><p>这里将<span class="math inline">\(f\)</span>称为encoder、将<span class="math inline">\(f^{-1}\)</span>称为decoder。</p><p>我们先聚焦于单个layer的计算，此时我们的目标有两个：构造一个双射函数、其Jacobian determinant好算。</p><blockquote><p>这两者也是相关的，如果我们构造的Jacobian matrix是可逆的，则函数也就是双射的。</p></blockquote><p><strong>仿射变换</strong></p><p>最早的想法是layer是一个affine transformation（线性的，就是乘以一个矩阵<span class="math inline">\(W\)</span>）。</p><p>这样一个affine transformation的Jacobian matrix就是<span class="math inline">\(W^T\)</span>，为了让这个矩阵的行列式好算，可以让这个<span class="math inline">\(W\)</span>是对角、上三角、下三角矩阵。</p><p>当我们堆叠多层的时候，上三角、下三角矩阵的相乘也能够覆盖一部分普通的square matrix。</p><p>但总的来说，这种方法能够拟合的函数只是线性的，而且也只是线性函数的一部分。</p><p>现在我们进一步推广上面的想法，我们现在去考虑这样一组函数，其Jacobian是上三角或下三角即可。</p><p><strong>耦合层</strong></p><p><span class="math inline">\(x\in\mathcal{X}\)</span>，<span class="math inline">\(I_1\)</span>和<span class="math inline">\(I_2\)</span>是index <span class="math inline">\([1,D]\)</span>的一个划分，其中<span class="math inline">\(d=|I_1|，\)</span><span class="math inline">\(m\)</span>是定义在<span class="math inline">\(\mathbb{R}^{d}\)</span>上的一个任意函数。现在我们定义<span class="math inline">\(y=(y_{I_1},y_{I_2})\)</span>：</p><p><span class="math display">\[y_{I_1} = x_{I_1} \\y_{I_2} = g(x_{I_2};m(x_{I_1}))\]</span></p><p>其中<span class="math inline">\(g:\mathbb{R}^{D-d}\times m(\mathbb{R}^d)\to\mathbb{R}^{D-d}\)</span>称为general coupling law，给定第二个参数（<span class="math inline">\(m(x_{I_1})\)</span>）后，这个函数是对于第一个参数（<span class="math inline">\(x_{I_2}\)</span>）可逆的。</p><p>我们可以计算这个函数的Jacobian matrix：</p><p><span class="math display">\[\frac{\partial y}{\partial x} = \begin{bmatrix}  I_d &amp; 0 \\  \frac{\partial y_{I_2}}{\partial x_{I_1}} &amp; \frac{\partial y_{I_2}}{\partial x_{I_2}}\end{bmatrix}\]</span></p><p>其中<span class="math inline">\(I_d\)</span>是<span class="math inline">\(d\)</span>维的单位矩阵。我们发现，<span class="math inline">\(\det \frac{\partial y}{\partial x}=\det\frac{\partial y_{I_2}}{\partial x_{I_2}}\)</span>。</p><p>另外，也容易验证，该映射<span class="math inline">\(y=f(x)\)</span>是可逆的，其逆映射是：</p><p><span class="math display">\[x_{I_1}=y_{I_1} \\x_{I_2}=g^{-1}(y_{I_2};m(y_{I_1}))\]</span></p><p><strong>我们称呼这是一个带有coupling function <span class="math inline">\(m\)</span>的coupling layer。</strong></p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-15-31-08.png"><br></p><p><strong>加性耦合层</strong></p><p>为了简单，我们直接使用additive coupling law <span class="math inline">\(g(a;b)=a+b\)</span>，则这时候我们得到了最常见到的形式：</p><p>encoder：</p><p><span class="math display">\[y_{I_1} = x_{I_1} \\y_{I_2} = x_{I_2}+m(x_{I_1})\]</span></p><p>decoder:</p><p><span class="math display">\[x_{I_1}=y_{I_1} \\x_{I_2}=y_{I_2}-m(y_{I_1})\]</span></p><p>逆映射和正映射的计算量是相同的。</p><p>另外，其Jacobian determinant是1。</p><blockquote><p>这时，我们可以令<span class="math inline">\(m\)</span>是一个从<span class="math inline">\(d\)</span>维向量映射到<span class="math inline">\(D-d\)</span>维向量的NN。</p></blockquote><p>其实，还有其他很多coupling law可以选择，比如：</p><ul><li><p>multiplicative coupling law ：</p><p><span class="math display">\[g(a;b)=a\odot b\]</span></p></li><li><p>affine coupling law：</p><p><span class="math display">\[g(a;b)=a\odot b_1+b_2\]</span></p></li></ul><p>当然，additive coupling因为其简单，稳定性更好。</p><p><strong>结合多个coupling layers</strong></p><p>因为有一部分维度的数据是不变的，所以我们需要组合多个coupling layers、并且在不同layers间划分的两部分数据所扮演的角色。<strong>至少需要3层coupling layers，一般来说要用4层。</strong></p><p>组合之后，整个网络的Jacobian determinant也是1，也就是说保持体积的。但注意到，尽管我们使用的数据有<span class="math inline">\(D\)</span>维，但很多维度可能是冗余的，所以在我们进行encoder的时候也保持这个维度，会浪费很多维度，使得效果不好。</p><p>解决方法是每个维度再乘以一个可训练的缩放系数<span class="math inline">\(h=s\cdot f(x)\)</span>，这样整个映射依然是可逆的，但模型可以自动进行维度的“缩放”，如果<span class="math inline">\(h\)</span>的某个维度不重要，则该维度的缩放系数会趋于无穷大，使该维度失效。</p><p>此时，我们的极大似然估计也需要进行一定的改变：</p><p><span class="math display">\[\max_{f}{\log(p_X(x))}=\max_{f}\{\sum_{d=1}^D[\log(p_{H_d}(s_df_d(x)))+\log(s_d)]\}\tag{5}\]</span></p><blockquote><p>尺度变化参数的另一个理解：</p><p>如果我们使用的prior distribution是独立的标准正态分布，则其方差都为1。但我们也可以让其方差不为1，而是一个可训练的参数。此时这个可训练的方差参数和上面的尺度参数是一个东西（尺度参数是方差参数的倒数）。</p><p>当尺度参数趋于无穷大的时候，方差趋于0，此时该维度的正态分布坍缩为一个单点，也就意味着减小了一个维度。就算不使该维度坍缩，但仅仅是降低其方差也意味着该维度信息量的降低。</p></blockquote><h3 id="先验分布">先验分布</h3><p>介绍了2种先验分布：</p><ul><li>gaussian distribution</li><li>logistic distribution</li></ul><p>本研究使用的是logistic distribution，其拥有更好的梯度特性。</p><h2 id="results">Results</h2><p>使用的数据集：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-15-31-52.png"><br></p><p>首先需要对其进行连续化（加上一个1/256均匀分布的噪声，然后将数据归一化到0——1，对于CIFAR-10是1/128和-1——1）</p><p>网络架构：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-15-35-07.png"><br></p><p>其中<span class="math inline">\(I_1\)</span>是奇数，<span class="math inline">\(I_2\)</span>是偶数。<span class="math inline">\(m\)</span>是5层的nn，其中最后一层不加ReLU激活。对于MNIST，hidden units是1000，对于TFD是5000，对于SVHN和CIFAR-10是2000。</p><p>prior distribution是logistic distribution。</p><p>训练使用的是Adam，lr=<span class="math inline">\(10^{-3}\)</span>，momentum是0.9，<span class="math inline">\(\beta_2=0.01,\lambda=1,\epsilon=10^{-4}\)</span>。1500个epochs后在valid data上通过log-likelihood选择最好的model。</p><p>结果如下：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-15-40-27.png"><br></p><p>下面是NICE的采样：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-15-41-47.png"><br></p><h3 id="inpainting任务">Inpainting任务</h3><p>这里使用一个训练好的模型，然后进行projected gradient ascent，其方式如下：</p><ol type="1"><li><p>观察到的数据是<span class="math inline">\(x_O\)</span>；</p></li><li><p>使用下面的公式进行迭代：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-19-45-21.png"><br></p></li><li><p>将最后得到的<span class="math inline">\(x_H\)</span>使用模型映射回<span class="math inline">\(x\)</span>，得到填补好的图片。</p></li></ol><p>下面是结果：</p><p><img src="/2020/09/10/paper/dl/paper-nice-2014/paper-NICE-2014_2020-09-10-19-47-46.png"><br></p><h2 id="conclusion">Conclusion</h2><ol type="1"><li>当前模型的架构似乎可以整合更多归纳信息，比如toroidal subspace analysis（TSA）【Cohen and Welling, 2014】。</li></ol><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Deep Leanring </tag>
            
            <tag> Flow Models </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-Transformer-2017</title>
      <link href="/2020/09/08/paper/dl/paper-transformer2017/"/>
      <url>/2020/09/08/paper/dl/paper-transformer2017/</url>
      
        <content type="html"><![CDATA[<h1 id="attention-is-all-you-need">Attention Is All You Need</h1><ul><li>杂志: nips</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>RNN、LSTM【12】、GRU【7】是当前进行sequence建模的最优模型，【31,21,13】进一步对其进行了推广和构建基于此的encoder-decoder模型。</p></li><li><p>当使用上述模型时，一个挑战在于无法并行化，从而拖慢了训练和运行的速度。</p></li><li><p>Attention机制正在兴起【2,16,22】，但这些研究中还是将其与其他模型融合使用。</p><p>本研究中，我们完全使用attention机制，构建了一种新的架构——Transformer，其可以并行化的运行，并在非常短时间的训练后就得到了超越的效果。</p></li></ol><h3 id="背景">背景</h3><ol type="1"><li><p>构建并行化的序列模型，之前的工作【20,15,8】大多采用CNNs。但其存在的问题是，难以建立距离非常远的两点间的关系。</p><p>而Transformer没有此问题。尽管attention weighted sum降低了有效的分辨率（损失了信息），但这可以通过使用multi-head attention来进行弥补。</p></li><li><p>self-attention机制已经在许多任务中表现惊人【4,22,23,19】。</p></li><li><p>end-to-end memory networks是基于recurrent attention机制的，已经在一些简单的语言问题上被证明有着不错的效果【28】。</p></li></ol><h2 id="methods">Methods</h2><h3 id="encoder-decoder架构">Encoder-Decoder架构</h3><p>整个模型使用encoder-decoder架构【5,2,29】。</p><p>其接受输入<span class="math inline">\((x_1,\dots,x_n)\)</span>，将其转换为连续的表示<span class="math inline">\(\mathbf{z}=(z_1,\dots,z_n)\)</span>。给定一个<span class="math inline">\(\mathbf{z}\)</span>，decoder生成一个输出序列<span class="math inline">\((y_1,\dots,y_m)\)</span>。进行生成的时候，模型是auto-regressive，即将上一次的结果作为输入来生成本次的输出。</p><p>整个模型可以有下面来的图来表示：</p><p><img src="/2020/09/08/paper/dl/paper-transformer2017/paper-transformer2017_2020-09-08-15-15-03.png"><br></p><ul><li><p>Encdoer:</p><p>encoder堆叠了6个相同的layers。</p><p>每个layer有两个sublayers堆叠而来：</p><ul><li>第一个是multi-head self-attention</li><li>第二个是一个简单的fc layer</li></ul><p>每个sublayer都有残差连接，并且之后再跟上一个layer normalization【1】（<span class="math inline">\(LayerNorm(x+Sublayer(x))\)</span>）。</p><p>为了方便使用残差连接，hidden layer units都是512。</p></li><li><p>Decoder:</p><p>decoder也是堆叠了6个相同的layers。</p><p>每个layer除了encoder有的2个sublayers外，还插入了另外一个sublayers。这个layer是一个相同的multi-head self-attention，其接受encoder的输出，混合decoder的输入从而生成序列。</p><p>decoder只能看到前面的东西来生成后面元素（我们要保证自回归特性成立）。所以，decoder的输入需要先mask掉后面的内容（后面会说到，这个mask是在self-attention中实现的），然后向右平移一个位置，从而能够使得其只看到当前位置前面的元素。</p></li></ul><h3 id="attention机制">Attention机制</h3><p>attention机制中，有query、key和value（都是向量）。其中只有一个query，而key和value有很多，并成对存在。计算时，<strong>query和每个key进行计算，得到attention scores；attention scores作为weights将对values进行weighted sum操作，得到输出</strong>。</p><ol type="1"><li><p>Scaled Dot-Product Attention</p><blockquote><p>这是本研究提出的新的attention计算方式</p></blockquote><p>这里设定query和key的维度是<span class="math inline">\(d_k\)</span>，value的维度是<span class="math inline">\(d_v\)</span>。我们将所有的query、key和value都组合成matrix，分别记做<span class="math inline">\(Q,K,V\)</span>，即：</p><p><span class="math display">\[dim(Q)=(|Q|,d_k),\quad dim(K)=(|S|,d_k),\quad dim(V)=(|S|,d_v)\]</span></p><p>其中<span class="math inline">\(|Q|\)</span>表示query的数量，<span class="math inline">\(|S|\)</span>表示key-value pairs的数量，这一般就是序列的长度。</p><p>我们进行如下计算：</p><p><span class="math display">\[Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span></p><blockquote><p>现在只关注于一个样本。</p><p>前面的softmax计算的就是attention score，得到的维度是<span class="math inline">\(|Q|\times|S|\)</span>，即对于每个query，在序列的每个位置上都有一个分数，每一行之和是1。再乘以<span class="math inline">\(V\)</span>，最终结果的维度是<span class="math inline">\(|Q|\times d_v\)</span>，即对于每个query都有一个结果。</p></blockquote><blockquote><p>对于attention来说，最常用的就是additive attention和dot-product attention。dot-product attention相对于additive更加有效率，因为其可以利用矩阵乘法进行加速。</p><p>如果<span class="math inline">\(d_k\)</span>不大，则两者的效果差不多。但当<span class="math inline">\(d_k\)</span>比较大时，additive attention要优于dot-product attention。本研究怀疑这是因为当<span class="math inline">\(d_k\)</span>较大时计算的内积比较大，会进入softmax的梯度消失区域，所以这里使用<span class="math inline">\(\sqrt{d_k}\)</span>进行scale。</p></blockquote><p><img src="/2020/09/08/paper/dl/paper-transformer2017/paper-transformer2017_2020-09-08-15-37-01.png"><br></p></li><li><p>Multi-head Attention</p><p>在进行注意力机制的计算的时候，我们会先分别使用3个线性映射将<span class="math inline">\(Q,K,V\)</span>映射到指定的<span class="math inline">\(d_k,d_k,d_v\)</span>维度，然后再使用上面所描述的attention机制，得到<span class="math inline">\(d_v\)</span>维度的结果。</p><blockquote><p>线性映射前<span class="math inline">\(Q,K,V\)</span>有着相同的维度<span class="math inline">\(d_{model}\)</span>。使用不同的参数来进行映射，意味着对于<span class="math inline">\(Q,K,V\)</span>，其提取的信息应该是不同的。</p></blockquote><p>multi-head attention就是平行的进行多次上面的操作，然后将结果concat到一起，最后再执行一次线性映射，得到输出：</p><p><span class="math display">\[ head_i = Attention(QW_i^Q,KW_i^K,VW_i^V) \\ MultiHead(Q,K,V)=Concat(head_1,\dots,head_h)W^O \]</span></p><p>其中<span class="math inline">\(W_i^Q\in\mathbb{R}^{d_{model}\times d_k},W_i^k\in\mathbb{R}^{d_{model}\times d_k},W_i^V\in\mathbb{R}^{d_{model}\times d_v}\)</span>和<span class="math inline">\(W^O\in\mathbb{R}^{hd_v\times d_{model}}\)</span></p><p>本研究中，<span class="math inline">\(h=8\)</span>（8个heads），<span class="math inline">\(d_k=d_v=d_{model}/h=64\)</span>，<span class="math inline">\(d_{model}=512\)</span>。</p></li><li><p>在模型中，各处使用的attention是不一样的：</p><ul><li><p>encoder-decoder attention layer（也就是decoder中插入的第二个attention layer）</p><p>它的query是来自上一个decoder layer；其keys和values是encoder的输出。这使得进行decoder的每次输出的时候，都会将整个encoder序列都看一遍。【31,2,8】</p></li><li><p>encoder使用是self-attention，其query、key和value都是前一层的输出。</p></li><li><p>decoder中的第一个sublayer也是self-attention，其接受的是输出序列。为了保证自回归假设，需要在scaled dot-product attention时进行mask（输入softmax之前，将需要去掉的值设为<span class="math inline">\(-\infty\)</span>）。</p></li></ul></li></ol><h3 id="position-wise的fc-layers">Position-wise的FC Layers</h3><blockquote><p>我们可以看到，attention sublayers中并没有加入多少非线性，非线性主要是由FC layers加入的。</p></blockquote><p>每个位置上都使用一个权重共享的fc，实际上是使用<span class="math inline">\(1\times 1\)</span>卷积实现的。</p><p>实际上叠加了2层fc，中间夹了一个ReLU，输入和输出自然是<span class="math inline">\(d_{model}=512\)</span>，中间层节点数是<span class="math inline">\(2048\)</span>。</p><h3 id="embedding-and-softmax">Embedding and Softmax</h3><p>我们使用的数据是预先学习好的embedding，其维度是<span class="math inline">\(d_{model}\)</span>。</p><p>同样，我们使用一个linear transformation和一个softmax来根据decoder输出的embeddding来预测是哪个词。做法类似【24】。</p><h3 id="位置编码">位置编码</h3><p>整个模型中没有利用到位置信息，所以需要想办法将这个信息放到模型中。</p><p>位置编码要求将位置也编码成<span class="math inline">\(d_{model}\)</span>维度的向量，有多种方式【8】。本研究中使用的是下面的：</p><p><span class="math display">\[PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}}) \\PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})\]</span></p><p>其中<span class="math inline">\(pos\)</span>表示位置，<span class="math inline">\(i\)</span>表示维度。</p><p>本研究也试验了学习一个位置编码，但其效果和上面这个相差无几。</p><h2 id="自注意力">自注意力</h2><blockquote><p>这里将self-attention和cnn、rnn进行了比较，叙述为什么使用self-attention。</p></blockquote><p>这里在3个方面进行了讨论：</p><ul><li>每一层的计算复杂度</li><li>可以并行化的计算量</li><li>网络中远程依赖关系的路径长度</li></ul><p>下表是其比较结果：</p><p><img src="/2020/09/08/paper/dl/paper-transformer2017/paper-transformer2017_2020-09-09-08-38-41.png"><br></p><p>结论：</p><ul><li><p>除了rnn之外，其他模型的并行化都较好</p></li><li><p>如果模型的序列长度小于表示的维度，则self-attention是要比rnn计算量小的，如果想要进一步缩小self-attention的计算量，可以使用只限制在邻域上的self-attention，但其路径长度会随之增加。</p></li><li><p>cnn一般来说计算复杂度要高于rnn和self-attention。分离卷积可以有效降低计算量（<span class="math inline">\(O(knd+nd^2)\)</span>），但相对于self-attention和point-wise fc来说依然计算量较高。</p><p>cnn另一个问题是其学习远程依赖的能力，普通的cnn的路径长度是<span class="math inline">\(O(n/r)\)</span>，就算使用空洞卷积，路径长度依然有<span class="math inline">\(O(\log_k(n))\)</span>。</p></li></ul><h2 id="训练">训练</h2><ul><li><p>数据集：</p><p>standard WMT 2014 English-German dataset，包含4.5m个sentence pairs。sentences使用byte-pair encoding【3】，37000个tokens。</p><p>larger WMT 2014 English-French dataset，包含36m个sentences，32000个tokens。</p></li><li><p>硬件：</p><p>8个NVIDIA P100 GPUs，每个training step是0.4s。</p><p>train base models 100000 steps（12h）；train big models，每个step是1.0s，300000 steps（3.5d）。</p></li><li><p>Optimizer：</p><p>Adam（<span class="math inline">\(\beta_1=0.9,\beta_2=0.98,\epsilon=10^{-9}\)</span>）</p><p>学习率使用下面的公式进行改动：</p><p><span class="math display">\[lr=d_{model}^{-0.5}\cdot min(step_num^{-0.5},step_num\cdot warmup_steps^{-1.5})\]</span></p></li><li><p>正则化，使用3种：</p><ul><li>每个sub-layer的输出都进行一次dropout，然后才和输入相加进行layer norm，<span class="math inline">\(P_{drop}=0.1\)</span>。</li><li>embeddings和positional encodings相加后，进行一次dropout，<span class="math inline">\(P_{drop}=0.1\)</span>。</li><li>使用label smoothing <span class="math inline">\(\epsilon_{ls}=0.1\)</span>【30】。</li></ul></li></ul><h2 id="results">Results</h2><h3 id="机器翻译">机器翻译</h3><p><img src="/2020/09/08/paper/dl/paper-transformer2017/paper-transformer2017_2020-09-09-09-16-13.png"><br></p><p>base model的预测结果是最后5个checkpoints的结果。big model是最后20个checkpoints的结果。</p><blockquote><p>base model和big model的配置在下面。</p></blockquote><h3 id="模型变体">模型变体</h3><p><img src="/2020/09/08/paper/dl/paper-transformer2017/paper-transformer2017_2020-09-09-09-19-10.png"><br></p><p>这里改变模型的不同超参数，然后去探索不同参数的影响。结果在tab3中。</p><h2 id="conclusion">Conclusion</h2><p>未来的一个研究方向可能是研究local restricted attention（只关注于neighborhoods），从而提高其对于大型输入、输出的处理能力。</p><hr><h2 id="questions">Questions</h2><blockquote><p>关于实现：</p><ul><li>pytorch有直接的实现</li><li>对于pointwise fc，在pytorch中没有必要使用1x1 cnn来实现，linear也有此功能。</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Attention </tag>
            
            <tag> Natural Language Processing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-DeepWalk-2014</title>
      <link href="/2020/09/07/paper/dl/paper-deepwalk2014/"/>
      <url>/2020/09/07/paper/dl/paper-deepwalk2014/</url>
      
        <content type="html"><![CDATA[<h1 id="deepwalk-online-learning-of-social-representations">DeepWalk: Online Learning of Social Representations</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li>网络的稀疏性是一把双刃剑，其有益于高效离散算法的开发，但使得统计学习变得困难（【15,37,11,5,22】这些网络算法都必须解决这些问题）；</li><li>本研究中提出了一种新的算法DeepWalk，来学习graph节点的social representation，即捕捉节点的邻居相似性和所在社区的资格信息（community membership），其灵感来源于NLP，并结合randomly-generated walks在graph上实现；</li><li>在Karate network（空手道网络）中的结果显示在fig1中，显示了DeepWalk得到的特征对于分类的有效性，此外在多标签的网络分类问题中也对该方法进行了测试，显示除了优于其他算法的表现，即使使用简单的logistic回归，DeepWalk的特征都表现出色；</li><li>本研究的贡献：<ol type="a"><li>使用deep learning来分析图，并建立了稳健的网络结构表示；</li><li>在多个social networks中基于多标签分类任务对方法进行了评价，发现Micro F1都能有5%-10%的提升，甚至在某些情况下能够减少60%训练样本的使用；</li><li>展示了DeepWalk方法的可扩展性，并描述了如何对方法进行进一步的改进；</li></ol></li></ol><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-07-00.png"><br></p><h3 id="相关工作">相关工作</h3><ul><li><p>本研究和其他研究的不同：</p><ol type="1"><li>学习潜在表示，而不是计算统计特征【12,41】；</li><li>不去试图去扩展分类模型【37,20】；</li><li>只需要局部信息，而其他方法需要全局信息【16,39,41】（即可以在线学习）；</li><li>将无监督学习用于graph</li></ol></li><li><p>关系学习</p><ol type="1"><li>比较著名的，比如pagerank等技术来将graph的信息进行整合；</li><li>还有Graph kernel【42】，但其非常慢；</li><li>【12,16,39-41】；</li></ol></li><li><p>无监督特征学习</p><p>【17,3,9,21,7,6】；</p></li></ul><h2 id="methods">Methods</h2><h3 id="问题定义">问题定义</h3><ol type="1"><li><span class="math inline">\(G=(V, E), E\in(V\times V)\)</span>, 定义带有节点特征和节点标签的图为 <span class="math inline">\(G_L=(V,E,X,Y),X\in\mathbb{R}^{|V|\times S},Y\in\mathbb{R}^{|V|\times|Y|}\)</span>。</li><li>一般上述问题被称为relational classification（collective classification），传统解决方法是使用无向Markov网络来建立模型，并使用近似推理方法（迭代分类【31】、Gibbs抽样【14】、标签松弛【18】）来计算标签的后验分布概率；</li><li>本研究的思路则是先去学习每个节点的表示<span class="math inline">\(X_E\in\mathbb{R}^{|V|\times d}\)</span>，其包含了X和graph结构的信息，然后再使用这些特征进行分类，这避免了迭代模型中出现的<strong>cascading errors问题</strong>【33】，并且其可扩展性也更强(易于和简单的机器学习方法进行结合)；</li></ol><blockquote><p>什么叫做cascading errors问题？</p></blockquote><h3 id="社会表示学习">社会表示学习</h3><p>我们希望学习到的social representation有以下的性质：</p><ol type="a"><li>Adaptability：能够根据新的关系进行学习，并且不会重复之前的学习；</li><li>Community aware：网络中节点间的social similarity应该在学习到的representation中有所表示；</li><li>Low dimensional；</li><li>Continuous：这可以得到更可靠的分类；</li></ol><h3 id="随机游走">随机游走</h3><ol type="1"><li>定义在节点<span class="math inline">\(v_i\)</span>上的random walk为<span class="math inline">\(W_{v_i}\)</span>，其是一个随机过程，拥有随机变量<span class="math inline">\(W_{v_i}^1,\dots,W_{v_i}^k\)</span>，其中<span class="math inline">\(W_{v_i}^{k+1}\)</span>是这个随机过程中第<span class="math inline">\(k\)</span>步节点随机选择的邻居节点，<span class="math inline">\(W_{v_i}^0=v_i\)</span>。</li><li>该方法可以用来进行相似度度量【11】和community detection【1】，也可以用来计算灵敏度【38】；</li><li>本方法使用random walk来生成stream来描述这个节点的信息，这带来了2个优点：<ol type="a"><li>可以轻松并行化；</li><li>基于从short random walks得到的信息，是没有必要关注到全局的，所以对图进行的更新后，没有必要从新开始训练；</li></ol></li></ol><h3 id="连接幂率">连接：幂率</h3><ol type="1"><li><p>如果度分布服从幂律分布（scare-free），则在short random walk中节点出现的频率也是服从幂律分布的；</p><blockquote><p>无标度网络的特点即大多数节点只和很少的节点相连，而有极少数的节点和很多节点相连，即随机抽取一个节点，其度为<span class="math inline">\(k\)</span>的概率是<span class="math inline">\(P(d=k)\propto k^{−r}\)</span>，一般这个<span class="math inline">\(r\)</span>的值在<span class="math inline">\(2-3\)</span>之间。这个特点使得无标度网络对意外故障有强大的承受能力，而面对协同攻击时显得脆弱。</p></blockquote></li><li><p>自然语言中的词频率拥有类似的分布（fig2），所以本研究希望将建模自然语言的技术用于网络；</p><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-16-45.png"><br></p></li></ol><h3 id="语言模型">语言模型</h3><ol type="1"><li><p>语言模型一般来建模在语料库中出现特定词的概率，即给定一个词序列<span class="math inline">\(W_1^n=(w_0,w_1,…,w_n)\)</span>，然后最大化<span class="math inline">\(Pr⁡(w_n│w_0,w_1,…,w_{n−1})\)</span>；</p></li><li><p>将random walk类比为词序列，然后也来最大化相似的似然<span class="math inline">\(Pr⁡(v_i│v_1,…,v_{i−1})\)</span>，来学习一个latent representation。其中representation使用一个函数<span class="math inline">\(\Phi:v\in V\to \mathbb{R}^{|V|×d}\)</span>得到，最终可以表示为<span class="math inline">\(Pr⁡(v_i│\Phi(v_1 ), …, \Phi(v_{i−1}))\)</span>；</p></li><li><p>进一步对上述方法的拓展为NLP带来了曙光【26,27】：</p><ol type="a"><li>首先，不使用上下文来预测单词，而是使用单词预测上下文；</li><li>上下文是该单词左右（可能不止每侧一个）的单词；</li><li>去除了顺序的影响，直接最大化上下文中所有单词的概率，而不需要offset；</li></ol><p>最终，得到模型: <span class="math display">\[\max_{\Phi}{\log Pr(\{v_{i-w},\dots,v_{i-1},v{i+1},\dots,v_{i+w}\})}\]</span></p><p>这些扩展对于graph representation学习非常有用：</p><ol type="a"><li>没有offset使得模型可以有效捕捉random walk带来的"近距离"感；</li><li>这样可以一次训练一个节点，容易加快训练速度；</li></ol></li><li><p>这里我们可以看到，拥有相似邻接点的特征会拥有相似的表示；</p></li></ol><h3 id="算法">算法</h3><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-37-46.png"><br></p><ol type="1"><li><p>DeepWalk</p><ol type="a"><li><p>Random walk generater：</p><ol type="i"><li><p>这里有两个超参数需要调整，即random walk的长度<span class="math inline">\(t\)</span>，一共需要几轮random walk <span class="math inline">\(\gamma\)</span>，相应的有两个嵌套的循环；</p></li><li><p>外部的训练次数是<span class="math inline">\(\gamma\)</span>，random walk的总轮数<span class="math inline">\(S\)</span>（pass），可以认为是epoch数，即每pass对每一个节点都random walk一次，相当于得到了一个<span class="math inline">\(|V|\times t\times S\)</span>的数据矩阵，然后使用这个矩阵来训练，和正常的SGD过程一样，每次得到上面的矩阵的时候，都会先把节点的顺序都shuffle一遍，这样一般loss会降的快，而且泛化能力更强；</p></li><li><p>内部的训练可以认为是batch，但这里是batch size=1，即每一次都用一个点的random walk来更新参数，这里使用的是SkipGram模型来作为<span class="math inline">\(\Phi\)</span>，另外长度<span class="math inline">\(t\)</span>不必是固定的，因为可能会回到root node，所以如果决定回到root就停下，则得到的序列长度就不是固定的<span class="math inline">\(t\)</span>，但这并不会有大的影响；</p></li></ol><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-38-14.png"><br></p></li><li><p>Update procedure（SkipGram）：</p><ol type="i"><li><p>其具体算法见algorithm2。</p><p>这里有个超参数<span class="math inline">\(w\)</span>需要调整，对每个节点的每个<span class="math inline">\(w\)</span>窗口内的所有其他节点，使用该节点的特征进行softmax预测，然后进行一次参数更新，这里一共进行了<span class="math inline">\(2wt\)</span>次参数更新；</p></li><li><p>这里唯一一个问题在于，预测的节点分类数量太多，所以不能使用传统的方法来进行计算，需要使用层次softmax【29,30】来近似概率分布；</p></li></ol><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-38-28.png"><br></p></li></ol></li><li><p>Hierarchical Softmax：</p><ol type="a"><li><p>因为需要进行分类的类别数实在太多（比如有10000个分类），则softmax的分母需要加10000次<span class="math inline">\(\exp\)</span>，这无疑会增加计算量以及计算的难度；</p></li><li><p>层次softmax的想法是将多个分类概率使用多个二分类的乘积的形式来近似表示，则对于10000分类的问题可以简化为log10000个乘积运算，使得计算称为可能；</p><blockquote><p>但实际上这只是一个近似，这样的方式并不能得到所有的可能的概率模式；</p></blockquote></li><li><p>为了进一步加快速度，可以使用<strong>Huffman coding</strong>进一步进行加速；</p></li></ol></li><li><p>Optimization</p><ol type="a"><li><p>我们需要优化更新的部分有两个，一个是<span class="math inline">\(\Phi\)</span>，一个是计算层次softmax是使用的二叉树<span class="math inline">\(T\)</span>；</p></li><li><p>使用SGD进行训练，初始学习率是2.5%，之后根据看到的节点的数量进行线性的衰减；</p></li></ol></li><li><p>并行训练：</p><p>因为是幂率分布，即大多数参数的更新都是稀疏的，所以使用ASGD会更快，而且实验（fig4）显示其也没有造成性能的丢失；</p></li></ol><h3 id="算法变种">算法变种</h3><p>这里对上面介绍的算法进行了一些变种，来研究算法的性能</p><ul><li><p>Streaming</p><blockquote><p>我的理解：直接从某个节点开始random walk，然后并不停下。这样会形成一个无限长的节点序列，然后使用<span class="math inline">\(w\)</span>的窗口来进行SkipGram训练，这另外带来了两个训练上的改变：</p></blockquote><ol type="a"><li>学习率是固定的，不会根据看到的节点数量进行改变；</li><li>没有必要每次SkipGram训练都重现建立一颗tree，直接在最开始的时候建立一颗最大的tree来分配即可；</li></ol></li><li><p>Non-random walk：有些图上的节点本身就是有顺序的，则我们直接使用这个顺序形成序列；</p></li></ul><h2 id="results">Results</h2><h3 id="数据集">数据集</h3><ol type="1"><li>BlogCatalog【39】：博客博主形成的社会网络，节点类别表示的是其博客的类型；</li><li>Flicker【39】：照片共享网站上用户的关系网络，节点类别表示的是用户的兴趣组，比如黑白照片；</li><li>YouTube【40】：YouTube上的用户关系网络，节点类别表示的用户喜欢的视频类别；</li></ol><blockquote><p>这些数据中节点是没有特征的，和我们普通的machine learning任务进行类别，每个节点可以看做是一个样本，但样本间不是独立的，每个样本只有标签，希望使用这些样本间的关系进行学习。</p></blockquote><h3 id="基线方法">基线方法</h3><ol type="1"><li><p>SpectralCluster【41】：使用图的归一化Laplacian的最小的<span class="math inline">\(d\)</span>个特征向量来得到特征矩阵；</p></li><li><p>Modularity【39】：使用图的模块化矩阵的前<span class="math inline">\(d\)</span>个特征向量；</p></li><li><p>EdgeCluster【40】：使用k-means去聚类邻接矩阵，其相比于Modularity的优点是不需要进行矩阵分解；</p></li><li><p>wvRN【24】：即使用某个节点的邻接点该类别的概率的加权求和来计算这个节点该类别的概率：</p><p><span class="math display">\[Pr(y_i|N_i)=\frac{1}{Z}\sum_{v_i\in N_i}{w_{ij}Pr(y_j|N_j)}\]</span></p></li><li><p>Majority：直接统计训练集中每个类别的节点数目；</p></li></ol><h3 id="多标签分类任务">多标签分类任务</h3><p>首先从图中随机采样出training，剩下的是test，这个过程重复10次，计算micro-F1和macro-F1的均值。</p><blockquote><ul><li>Micro-F1先分别计算TP、FP、TN、FN，在根据公式计算F1。</li><li>Macro-F1是先对每一类计算F1，然后计算其平均。</li></ul></blockquote><p>所有的方法使用的分类器都是one-vs-rest的logistic regression，DeepWalk的参数是<span class="math inline">\(\gamma=80,w=10,d=128\)</span>，其他方法使用的维度是<span class="math inline">\(d=500\)</span>。</p><ul><li><p>BlogCatalog：训练集比例从0.1-0.9，结果见下表，只有SpectralClustering有一定的竞争力，但在较少训练集的时候其也比不过DeepWalk；</p><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-45-00.png"><br></p></li><li><p>Flickr：训练集比例从0.01-0.1，看到特别是在极小训练样本的情况下，DeepWalk的效果是极好的；</p><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-46-21.png"><br></p></li><li><p>YouTube：训练集比例从0.01-0.1，因为太大，一些基线方法无法计算，发现DeepWalk方法远远好于其他方法，特别是在极小样本量的情况下（0.01）；</p><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-46-45.png"><br></p></li></ul><h3 id="参数灵敏度">参数灵敏度</h3><p>探索改变其超参数，对算法性能的影响，其中<span class="math inline">\(w=10，t=40\)</span>是固定的，改变的是维度<span class="math inline">\(d\)</span>、pass数量<span class="math inline">\(\gamma\)</span>、训练集大小；（fig5）</p><ol type="1"><li>维度的影响：<ol type="a"><li>最佳的维度数会受到训练集大小的影响；</li><li>对于<span class="math inline">\(\gamma\)</span>的改变，DeepWalk是稳健的；</li></ol></li><li><span class="math inline">\(\gamma\)</span>的影响：<ol type="a"><li>增加<span class="math inline">\(\gamma\)</span>会对结果有影响；</li><li>但随着<span class="math inline">\(\gamma\)</span>的增加，影响逐渐有限；</li><li>仅需要少量的random walk，即可以学习到有效的潜在表示；</li></ol></li></ol><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-49-53.png"><br></p><p>下面是并行化对运行时间和性能的影响：</p><p><img src="/2020/09/07/paper/dl/paper-deepwalk2014/paper-deepwalk2014_2020-09-07-09-55-59.png"><br></p><h2 id="conclusion">Conclusion</h2><ol type="1"><li>DeepWalk可以成功在大的graph上运行，而且性能显著优于其他为了sparse设计的算法；</li><li>因为利用了NLP中的知识，所以NLP中的发展也可以促进DeepWalk的提升；</li><li>未来会进一步研究该方法的理论依据。</li></ol><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Graph Embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-HetSANN-2019</title>
      <link href="/2020/09/05/paper/dl/paper-hetsann2019/"/>
      <url>/2020/09/05/paper/dl/paper-hetsann2019/</url>
      
        <content type="html"><![CDATA[<h1 id="an-attention-based-graph-neural-network-for-heterogeneous-structural-learning">An Attention-based Graph Neural Network for Heterogeneous Structural Learning</h1><ul><li>杂志: AAAI</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>graph embedding的方法力图将graph数字化，现存的方法（比如DeepWalk）都是针对同质图（homogeneous graphs），但现实世界中大多数图都是异质的（heterogeneous）。</p></li><li><p>Heterogeneous Information Network（HIN），包含超过两种类型的nodes和edges，并且边是有向的，如下图所示。因此，我们面临以下挑战：</p><ul><li>如果建模不同类型的nodes？</li><li>如何保留不同类型edges的语义？比如对于下面的学术网络，author和author之间可能有引用关系，两者也可能是合著了一篇文献的关系。（边和边是不一样的）</li></ul></li><li><p>当前的大多数研究处理HIN的方式是通过meta-path【Shi et al. 2016】来转换成homogeneous graphs，然后进行进一步的处理（如fig1b所示）。【Dong, Chawla, and Swami 2017, Wang et al. 2019】都是这样处理的。</p><p>但我们需要手工来构建合适的meta-path，这带来了下面的问题：</p><ul><li>meta-path的构建依赖于专家，我们也无法穷举求解最好的meta-path。</li><li>在meta-path上的节点（比如下图所示的paper和conference）会丢失，这可能会导入较差的性能</li></ul></li><li><p>本研究提出了一种新的方法，其没有使用meta-path，能够学习到graph的包含结构和语义信息的低维表示。</p><p>这里我们使用了GNN模型，设计了一种type-aware attention Layer来代替常规的GNN Layer，其可以将不同类型的节点映射到不同的空间中，并且注意到了不同类型edges的影响。</p><p>另外，我们开发了一种新的attention scoring function。</p><p>我们在3个数据集的实验上验证了我们的想法。</p></li></ol><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-15-50-54.png"><br></p><h3 id="相关工作">相关工作</h3><p>以下方法都是依赖于meta-path的：</p><ul><li>metapath2vec 【Dong, Chawla, and Swami 2017】</li><li>HERec【Shi et al. 2018】</li><li>【Chen and Sun 2017】</li><li>【Wang et al. 2019】</li></ul><h2 id="methods">Methods</h2><p>首先介绍一下使用的符号：</p><p>图 <span class="math inline">\(\mathcal{G}=(\mathcal{V}, \mathcal{E})\)</span>，另外还有节点类型集合和边类型集合 <span class="math inline">\(\mathcal{A}\)</span>和<span class="math inline">\(\mathcal{R}\)</span>。对于每个节点，存在一个mapping，将其映射到某个类别上 <span class="math inline">\(\phi(v)=p\in\mathcal{A},\forall v\in\mathcal{V}\)</span>。对于每条边，我们可以这样表示 <span class="math inline">\(e=(i,j,r)\in\mathcal{E}\)</span>，其中<span class="math inline">\(i,j\in\mathcal{V},r\in\mathcal{R}\)</span>。所有的边都是有向的，而且边的方向改变可能还伴随着类型的改变（“写”和“被写”是两种类型的relationships），<span class="math inline">\(e\)</span>的反向边记做<span class="math inline">\(\widetilde{e}=(j,i,\widetilde{r}),\widetilde{r}\in\mathcal{R}\)</span>。</p><p>我们的任务是，对于每个节点<span class="math inline">\(i\)</span>，学习一个低维表示<span class="math inline">\(\mathbf{h}_i\in\mathbb{R}^{n_{\phi(i)}}\)</span>，可以看到，我们希望将不同类型的节点映射到不同的空间中去。</p><blockquote><p>正因为不同处于不同的空间中，所以在利用两个节点来表示不同类型的edge时才会体现出其语义的不同。</p></blockquote><p>以下是整个模型的架构：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-15-57-52.png"><br></p><h3 id="type-aware-attention-layer-tal">Type-aware Attention Layer (TAL)</h3><p>下图是TAL的流程示意图：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-49-57.png"><br></p><ol type="1"><li><p>首先为了个节点赋予一个self-loop，表示<span class="math inline">\(\phi(i)\)</span>.</p></li><li><p>然后设置一个cold start state <span class="math inline">\(\mathbb{h}_i^{(0)}\in\mathbb{R}^{h_{\phi(i)}^{(0)}}\)</span>作为起始embedding，可以是节点拥有的特征，如果没有特征则使用one-hot向量替代。</p></li><li><p><strong>Transformation Operation</strong>：对于目标节点<span class="math inline">\(j\)</span>，将其neighborhoods进行一次线性变换，如果是multi-head的话，则需要进行<span class="math inline">\(m\)</span>次。注意，不同类型的节点间的变化是不同的。</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-17-09-10.png"><br></p></li><li><p><strong>Aggregation of Neighborhood</strong>：为了能够保持不同类型边的语义，需要使用<span class="math inline">\(|\mathcal{R}|\)</span>种attention scoring functions：<span class="math inline">\(\mathcal{F}^(l+1,m)=\{f_r^{(l_1,m)}|r\in\mathcal{R}\}\)</span>。</p><p>对于目标节点<span class="math inline">\(j\)</span>，其邻接边上的attention coefficient可以如下表示：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-17-15-50.png"><br></p><p>其中<span class="math inline">\(\sigma\)</span>是激活函数，这里是LeakyRELU。实际上，不同类型的边甚至可以有不同形式的attention scoring functions，这里为了方便，使用相同的函数形式，但拥有不同的参数。</p><p>最自然的形式是GAT中的concat product：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-23-02.png"><br></p><p>之后，使用softmax来normalize attention coefficient，得到attention scores：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-24-34.png"><br></p><p>之后我们聚合这些邻接点特征来更新目标节点特征：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-25-26.png"><br></p><p>注意到，如果节点<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>之间有多种类型的relationships存在，则信息传递过程将会重复多次，使用相应的attention scores。</p></li><li><p>因为是multi-head的attention机制，所以我们最后还需要将多头得到的特征concat一下：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-28-58.png"><br></p><p>注意到，对于两个author节点，如果使用meta-path，他们是直接相连的。但如果使用HetSANN，因为paper和conference的节点也都要考虑到，所以学习到两个author节点间的信息需要更深的网络。这时候建议使用residual的架构：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-32-18.png"><br></p></li></ol><h3 id="模型训练">模型训练</h3><p>我们的任务是一个无监督的任务，但为了能够进行GNNs的学习，这里使用有监督的方式来进行训练。<strong>即进行node classification任务，其中标签就是节点的类别。</strong></p><p>进一步，我们还可以进行以下3种拓展，来提升训练的效果：</p><ul><li><p>如果我们能够得到多种不同类型的节点标签，可以进行multi-task learning，有助于降低过拟合风险和增强representations的robustness【Baxter 1997】。</p></li><li><p>上面我们提到了计算attention coefficient的一种方式——concat product，这种计算方式可能是没有效率的。</p><p>如果一个author和paper存在关系，则author “写了” paper，paper “被” author写。在concat product中，这两个关系将使用不同的两个functions来计算。但实际上两者在语义上是存在关系的（相反的语义）。</p><p>为了能够将这种语义上的相反纳入，可以让计算这两种关系attention coefficients的functions的参数值共享，但互为相反数。所以就有下面的新的计算方式voices-sharing product：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-19-44-57.png"><br></p></li><li><p>Cycle-consistency Loss。</p><p>这个思想来源于NLP的翻译领域的研究（当然，cycleGAN中也用到了）。</p><p>对于两个相邻的节点<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>，我们如公式1所示，会将<span class="math inline">\(i\)</span>进行一次转换以便能够发送到<span class="math inline">\(j\)</span>上更新<span class="math inline">\(j\)</span>的特征（下图b的右上方的实线）（<span class="math inline">\(j\)</span>的第一次更新）。另外，我们还会在<span class="math inline">\(j\)</span>上进行一次自我的更新（下图b左上方的实线）（<span class="math inline">\(j\)</span>的第二次更新）。以<span class="math inline">\(i\)</span>为目标节点，<span class="math inline">\(j\)</span>作为其邻接点会更新、发送一次信息到<span class="math inline">\(i\)</span>上（下图b的左下方的实现）。</p><p><span class="math inline">\(j\)</span>的第一次更新和第二次更新，都是<span class="math inline">\(j\)</span>的更新态，两者应该尽可能的相似，我们只要能够找到一个<span class="math inline">\(i\)</span>的一次“逆更新”，就可以从两条路、同一个起点计算<span class="math inline">\(j\)</span>的更新态，从而构建一个cycle-consistency loss。这个“逆更新”理论上是<span class="math inline">\(i\)</span>到<span class="math inline">\(i\)</span>自更新的权重矩阵的逆，但这里为了计算量的考虑，使用一个可训练的参数来拟合它，从而我们得到了这个loss：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-10-30.png"><br></p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-10-45.png"><br></p></li></ul><h2 id="results">Results</h2><p>比较的模型有：</p><ul><li><p>.M、.R、.V分别表示多任务学习、voice-sharing product和cycle-consistency loss。如果是.M.R.V则表示这3个提升都用上了。</p><p>使用的模型是3-layer的HetSANN，每个layer有8个attention heads，每个head的输出维度都是8。adam（IMDB lr=0.001，其他 lr=0.0005），每一层间的dropout rate是0.6。cycle-consistency loss的系数 <span class="math inline">\(\beta_1=10^{-3},\beta_2=10^{-5}\)</span>。</p></li><li><p>比较的baseline在下面的表格中可以看到。</p></li></ul><p>使用的数据集的信息：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-17-00.png"><br></p><p>评价指标：train：valid：test=0.8:0.1:0.1，使用valid上最好的用来在test上进行验证。使用的指标是micro f1和macro f1。每个重复10次。</p><p>整体结果如下表所示：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-19-05.png"><br></p><ol type="1"><li>这3种提升都对模型有所帮助，.V提供的提升较小。</li><li>HetSANN除了一个任务外，其他任务的表现都是最好的。</li></ol><p>下图表示了使用不同比例的数据作为训练集的效果：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-24-53.png"><br></p><p>进一步，进行了一些超参数的敏感度分析：</p><p><img src="/2020/09/05/paper/dl/paper-hetsann2019/paper-HetSANN2019_2020-09-05-20-25-47.png"><br></p><h2 id="conclusion">Conclusion</h2><hr><h2 id="questions">Questions</h2><blockquote><p>可以看做是GAT的加强版，只是对不同类型的nodes、edges使用不同的参数。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-ASAP-2020</title>
      <link href="/2020/09/02/paper/dl/paper-asap2020/"/>
      <url>/2020/09/02/paper/dl/paper-asap2020/</url>
      
        <content type="html"><![CDATA[<h1 id="asap-adaptive-structure-aware-pooling-for-learning-hierarchical-graph-representations">ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations</h1><ul><li>杂志: AAAI</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>在使用GNNs进行graph classification的时候，学习graph-level representation是重要的。其中以hierarchical的方式来学习representation是非常有实际意义的，其可以捕捉local substructures（比如一个大分子中的分子集团）。</p></li><li><p>为了能够进行层次地学习，众多的graph pooling methods被提出：</p><ul><li>DiffPool，得到的assignment matrix 是dense的，无法扩展到大图。</li><li>TopK，无法学习到足够丰富的graph structure。</li><li>SAGPool，无法有效确定pooled graph的连通性。</li></ul></li><li><p>本研究提出一种新的graph sparse pooling operation，叫做Adaptive Structure Aware Pooling（ASAP），来解决上面的limitations。</p></li></ol><h3 id="相关工作">相关工作</h3><ul><li><p>GNNs</p></li><li><p>Pooling</p><ul><li>早期聚焦于确定性的graph clustering algorithm【Defferrard, Bresson, and Vandergheynst 2016; Fey et al. 2018; Simonovsky and Komodakis 2017】</li><li>pooling方法也可分为spectral【Ma et al. 2019; Dhillon, Guan, and Kulis 2007】和non-spectral的。因为spectral一般需要进行特征值分解，对于大图来说这个计算量太大，所以这里只聚焦于non-spectral的方法。</li><li>pooling方法也可以分为global和hierarchical两种。</li></ul></li></ul><p>global pooling直接将整个graph的信息提取，相关方法有Set2Set【Vinyals, Bengio, and Kudlur 2016】、global-attention【Li et al. 2016】和SortPool【Zhang et al. 2018】。</p><p>hierarchical pooling则层次地进行节点信息的聚合，相关方法有DiffPool、TopK、SAGPool。<strong>这里注意，TopK和SAGPool都是直接将节点丢弃，其没有将节点的信息进行聚合，所以其丢失了大量的信息。</strong></p><p>以下是几种方法的特点的总结：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-02-16-15-26.png"><br></p><h2 id="methods">Methods</h2><blockquote><p>因为这个方法比较复杂，这里对其进行一下总结，叙述一下其总体的思路。</p><p>首先是TopkPool的问题：</p><ul><li>其在计算node score（看自己是不是重要）的时候，只考虑到自己这个节点的特征，既没有看到更大的感受野，也没有考虑到graph的结构信息。</li><li>在进行pooling的时候，是直接将排名靠后的节点去掉，这些排名靠后的节点的信息并没有丝毫的保留，也没有将其储存在其他的节点中。</li><li>（自己的反驳：那我在使用TopKPool之前都先多堆叠基层GNN就好了，这些GNN理论上会解决上面的问题。）</li></ul><p>为了能够克服上面的这些缺点，ASAP进行了这些设计（思想如下图所示）：</p><ol type="1"><li>首先使用self-attention的架构，将每个点的邻域都看到（下图中的b），从而将这些邻域的信息都记录到这个点上去，这样得到的就是后面说所的cluster graph <span class="math inline">\(G^c\)</span>。</li><li>然后根据记录的邻域信息（<span class="math inline">\(G^c\)</span>的features matrix），使用LEConv来计算cluster score（下图中的c），然后根据这个score进行TopKPool类似的pooling操作。</li><li>然后根据cluster的感受野是否有重合、是否有互为邻居的点分别位于两者之中，为这些cluster之间赋予边。此时，得到的graph是<span class="math inline">\(G^p\)</span></li></ol></blockquote><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-02-20-51-32.png"><br></p><h3 id="自注意力">自注意力</h3><p>attention就是计算一个alignment score <span class="math inline">\(\alpha_{ij}\)</span>，来描述candidates <span class="math inline">\(c_j\)</span>在query <span class="math inline">\(q_i\)</span>上的重要性。在self-attention上，query和candidates都是input entities。根据query的选择，self-attention可以进一步分为下面两个类别：</p><ul><li><p>Token2Token（T2T）：candidates和query都是输入特征<span class="math inline">\(\mathbf{h}\)</span>，根据【Bahdanau, Cho, and Bengio 2014】，score的计算方式是：</p><p><span class="math display">\[\alpha_{ij}=softmax(v^T\sigma(Wh_i||Wh_j))\]</span></p></li><li><p>Source2Token(S2T)：不使用query，计算方式：</p><p><span class="math display">\[\alpha_{ij}=softmax(v^T\sigma(Wh_j))\]</span></p></li></ul><h3 id="感受野">感受野</h3><p>这里将感受野的概念从CNNs中推广到GNNs中。</p><p>定义pooling operation的<span class="math inline">\(RF^{node}\)</span>为覆盖影响特点输出节点的neighborhoods所需要的hops。</p><p>定义pooling operation的<span class="math inline">\(RF^{edge}\)</span>为覆盖影响特定输出节点的neighborhoods的edges所需要的hops。</p><h3 id="cluster-assignment">Cluster Assignment</h3><p>每个节点<span class="math inline">\(v_i\)</span>都可以看做是一个cluster <span class="math inline">\(c_h(v_i)\)</span>的medoid，这个cluster是该节点<span class="math inline">\(v_i\)</span>的h hops的neighbors，即<span class="math inline">\(c_h(v_i)=\mathcal{N}_h(v_i)\)</span>。</p><p>令<span class="math inline">\(x^c_i\)</span>是cluster <span class="math inline">\(c_h(v_i)\)</span>的feature representation，这时我们可以定义一个新的graph：<span class="math inline">\(G^c(\mathcal{V},\mathcal{E},X^c)\)</span>，其中的features就是cluster的features，其adjacency matrix还是原来的：<span class="math inline">\(A^c=A\)</span>。</p><p>接下来，我们定义一个cluster assignment matrix <span class="math inline">\(S\in\mathbb{R}^{N\times N}\)</span>，其中每个元素<span class="math inline">\(S_{ij}\)</span>表示<span class="math inline">\(v_i\)</span>属于<span class="math inline">\(c_h(v_j)\)</span>的“资格”。</p><h3 id="cluster-formation-using-master2token">Cluster Formation using Master2Token</h3><p>接下来我们讨论如何通过self-attention来学习该cluster assignment matrix <span class="math inline">\(S\)</span>。</p><blockquote><p>基本思路就是搞一个representation <span class="math inline">\(m_i\)</span>表示整个cluster <span class="math inline">\(c_h(v_i)\)</span>，这个就作为query。而每个cluster内的元素的表示<span class="math inline">\(x_j\in c_h(v_i)\)</span>就是一个个candidates。</p></blockquote><p>T2T和S2T都无法满足我们的要求，所以这里提出了一种新的self-attention的variant，Master2Token（M2T）。</p><ol type="1"><li><p>首先，我们先使用一个单独的GCN对节点特征<span class="math inline">\(x_j\)</span>进行一次变化，得到节点特征<span class="math inline">\(x'_j\)</span>。这些新的节点特征包含了网络的结构信息，这在后面我们将会用到。</p></li><li><p>需要构建master query of cluster，使用下面的方式：</p><p><span class="math display">\[m_i = f_m(\{x'_j|v_j\in c_h(v_i)\})\]</span></p><p>这里的<span class="math inline">\(x'_j\)</span>是将<span class="math inline">\(v_j\)</span>的节点特征。</p><p><span class="math inline">\(f_m\)</span>可以使用<span class="math inline">\(max\)</span>：</p><p><span class="math display">\[m_i = max_{v_j\in c_h(v_i)}(x'j)\]</span></p></li><li><p>然后将master query <span class="math inline">\(m_i\)</span>作为query，构建标准的attention模块即可：</p><p><span class="math display">\[\alpha_{ij}=softmax(w^T\sigma(Wm_i||x'j))\]</span></p><p>这里<span class="math inline">\(s_{ij}=\alpha_{ij}\)</span>，这样我们得到了cluster assignment matrix <span class="math inline">\(S\)</span>。</p><blockquote><p>注意，<span class="math inline">\(S\)</span>并不是dense的。对于指定的节点<span class="math inline">\(v_i\)</span>，只有在其感受野内的节点（和其在<span class="math inline">\(h\)</span> hops之内的节点）才会被赋予score。</p></blockquote></li><li><p>然后计算cluster representation <span class="math inline">\(x_i^c = \sum_{j=1}^{|c_h(v_i)|}(\alpha_{ij}x_j)\)</span>。</p></li></ol><h3 id="cluster-selection-using-leconv">Cluster Selection using LEConv</h3><p>类似TopKpool的思想，这里也是为每一个cluster（这是实际上是将一个感受野的信息都收集到一个节点上去了）计算一个scalar——cluster fitness score <span class="math inline">\(\phi_i\)</span>，然后选择保留前<span class="math inline">\(\lceil kN\rceil\)</span>的cluster作为pooled graph。</p><p>这里，提出了Local Extreme Convolution（LEConv），一个新的graph convolution method可以捕捉局部的极端信息。其计算score的方式为：</p><p><span class="math display">\[\phi_i=\sigma(x^c_iW_i+\sum_{j\in\mathcal{N}(i)}{A^c{ij}(x^c_iW_2-x_j^cW_3)})\]</span></p><p>其中<span class="math inline">\(W_i,i=1,2,3\)</span>是可学习的参数，<span class="math inline">\(\mathcal{N}(i)\)</span>是graph <span class="math inline">\(G^c\)</span>的第<span class="math inline">\(i\)</span>个节点的neighborhood。</p><blockquote><p>在本文的公式中，<span class="math inline">\(\sigma\)</span>表示的是激活函数，而不是sigmoid函数。</p></blockquote><p>Fitness vector <span class="math inline">\(\Phi=[\phi_1,\phi_2,\dots,\phi_N]^T\)</span>，乘上cluster feature matrix，以便上面的LEConv可以学习：</p><p><span class="math display">\[\hat{X}^c=\Phi\odot X^c\]</span></p><p>然后我们根据fitness scores来选择出前面的nodes进行保留，其他删除：</p><p><span class="math display">\[\begin{aligned}    \hat{i} &amp;= TOP_k(\Phi,\lceil kN\rceil) \\    \hat{S} &amp;= S(:,\hat{i})\in\mathbb{R}^{N\times\lceil kN\rceil} \\    \hat{X^p} &amp; = \hat{X}^c(\hat{i},:)\end{aligned}\]</span></p><p>其中<span class="math inline">\(\hat{S}\)</span>是裁剪过后的cluster assignment matrix，之后还会用到。</p><h3 id="maintaining-graph-connectivity">Maintaining Graph Connectivity</h3><p>根据【Ying et al. 2018】，我们可以用下面的方式来计算<span class="math inline">\(G^p\)</span>的adjacency matrix：</p><p><span class="math display">\[A^p=\hat{S}^T\hat{A}^c\hat{S}\]</span></p><p>其中<span class="math inline">\(\hat{A}^c=A^c+I\)</span>，这保证了如何只要两个cluster有共有的节点、存在节点是邻居则就会被相连。</p><p>因为<span class="math inline">\(\hat{S}\)</span>和<span class="math inline">\(\hat{A}^c\)</span>都是sparse，所以这个操作是高效的。</p><h3 id="理论分析">理论分析</h3><p>这里主要由3个定理构成：</p><ul><li><p>GCN无法进行local extremas的学习</p><blockquote><p>这里我们使用世界上的高山进行比喻理解。</p><p>我们的任务是得到一系列的代表，能够代表整个世界的高山的特征。自然的一个想法是选择世界上海拔最高的N个地点作为整个世界上高山的代表。但这里存在的问题在于，很多时候高山是一起存在的，比如青藏高原附近的海拔都明显高，如果我们单纯以海拔来选择的话，青藏高原会把世界上其他地区的高山都给挤掉。这带来了两个问题：青藏高原其实不是高山，它可以看做是喜马拉雅山附件的高地；我们这样得到的代表会只局限于局部，无法窥探整个世界的高山的特征。</p><p>用更加数学的语言来说，我们现在认为极值点可以用来描述整个graph的信息。每个极值点都可以看做是一座山。但有些山（最值点）的山坡位置也比其他极值点高，所以如果单纯进行“高度”的比较来选择，就会选择更多的点在最值点附近，无法更广的涉及到整个graph的极值点。</p><p>当使用GCN进行scores的计算，其将所有邻接点的特征进行一次weighted average的操作，所以score最高的node周围的nodes的scores也会非常高（喜马拉雅山的周围是青藏高原，最值点及其附近）。如果这个时候，我们再按照score的高低选择点的话，则我们只会选择到这个nodes及其周围，无法触及到这个graph的广泛的局部极值点信息。</p><p>而使用LEConv，因为其使用的是neighborhoods和中心节点的差值进行的学习，所以其发现极值点的能力应该是强于GCN，这里的定理就是来论述这个问题。</p></blockquote><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-39-11.png"><br></p></li><li><p>graph的连通性</p><blockquote><p>这里证明了经ASAP pooling后，pooled graph拥有更好的连通性，相比于TopK和SAGPool。</p></blockquote><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-42-06.png"><br></p></li><li><p>ASAP是一个graph permutation equivariant操作</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-42-56.png"><br></p></li></ul><h2 id="results">Results</h2><h3 id="实验设置">实验设置</h3><p><strong>数据集</strong></p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-46-59.png"><br></p><p><strong>基线方法</strong></p><ul><li>hierarchical methods：DiffPool、TopK、SAGPool</li><li>global methods：Set2Set、Global-Attention、SortPool</li></ul><p><strong>模型设置</strong></p><ul><li><p>网络架构来自【Cangea et al.2018; Lee, Lee, and Kang 2019】，在fig1中有展示。</p><ul><li><p>其中的readout是mean和max的concat（SAGPool的文章中使用过）</p></li><li><p>对于global pooling，其只在所有的GCN后使用，并且也不再用readout（global pooling本身就是一个readout）。然后各种方法有一些超参数，这些超参数会进行调整：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-56-48.png"><br></p></li></ul></li><li><p>对于ASAP，使用<span class="math inline">\(k=0.5\)</span>和<span class="math inline">\(h=1\)</span>。</p></li><li><p>使用10-fold CV，然后重复20次，将200次test的结果取平均。</p></li></ul><h3 id="实验结果">实验结果</h3><ol type="1"><li><p>在graph classification tasks上的性能比较：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-10-51-44.png"><br></p><p>ASAP效果更好，而且训练时更加稳定。</p></li><li><p>探索“聚集整个cluster的节点特征”所产生的作用</p><p>ASAP在两个地方用到了这个：计算fitness scores和计算pooled graph的特征时</p><ul><li>FITNESS：表示使用了整个cluster节点的信息，否则只使用medoid的特征。</li><li>CLUSTER：表示使用整个cluster节点的信息来更新特征，否则只是用medoid的特征作为pooled graph的特征。</li></ul><p>则据此，我们设计了3种情形：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-11-07-06.png"><br></p><p>然后其结果如下：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-11-07-23.png"><br></p><p>发现这种聚集cluster节点特征的方式确实对T型能的提升有帮助。</p></li><li><p>探索M2T Attention的效果</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-11-08-42.png"><br></p></li><li><p>探索LEConv的效果</p><p>这里使用GCN和Basic-LEConv（3个参数矩阵都使用同一个）作为对照，效果如下：</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-11-13-35.png"><br></p><p>LEConv带来的提升还是很大的。</p></li><li><p>探索保留edge weights的效果</p><p><img src="/2020/09/02/paper/dl/paper-asap2020/paper-asap2020_2020-09-03-11-16-13.png"><br></p><p>发现保留edge weights带来显著的性能提升，所以保留edge information在pooled graph上是非常必要的。</p></li></ol><h2 id="discussion">Discussion</h2><h3 id="和其他pooling方法的比较">和其他pooling方法的比较</h3><ul><li><p>DiffPool和ASAP都是去试图构建一个cluster，区别在于DiffPool会考虑所有的节点，而ASAP只考虑h-hop的neighborhoods。</p><p>所以DiffPool可能会导致很远的节点（拥有相似的特征）也会被聚集到一起，为了减轻这个趋势，其专门使用了一个辅助的regularization。而ASAP不需要。</p><p>DiffPool计算的cluster assignment matrix是dense的，而ASAP是sparse的。</p><p>DiffPool必须预先确定好pooled graph的节点数，而ASAP需要给出的是比例，所以更加易于操作。</p></li><li><p>TopK没有考虑到structure information，SAGPool考虑到了，但两者都没有使用cluster assignment matrix，而是直接丢弃节点，这可能造成信息的丢失。</p><p>ASAP因为构建cluster来提取cluster的信息，所以其能够捕捉更加丰富的graph structure information。</p><p>相比于TopK和SAGPool，ASAP可以使得pooled graph拥有更好的connectivity，从而更加有利于信息的流动。</p><p>另外，ASAP使用了LEConv，其保留的cluster更加合理。</p></li></ul><h3 id="self-attention变体间的比较">self-attention变体间的比较</h3><p>实际上，GAT用的就可以认为是T2T的attention。</p><p>如果我们从cluster中移除一个非medoid节点，对T2T和S2T并没有什么影响，也就是说两者都没有捕捉到cluster内部的关系。</p><blockquote><p>还有一些细节，需要参考文章的appendix部分。</p></blockquote><hr><h2 id="questions">Questions</h2><ol type="1"><li><span class="math inline">\(RF^{edge}\)</span>和<span class="math inline">\(RF^{node}\)</span>不太懂其具体含义。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-EdgePool-2019</title>
      <link href="/2020/09/01/paper/dl/paper-edgepool-2019/"/>
      <url>/2020/09/01/paper/dl/paper-edgepool-2019/</url>
      
        <content type="html"><![CDATA[<h1 id="towards-graph-pooling-by-edge-contraction">Towards Graph Pooling by Edge Contraction</h1><h1 id="edge-contraction-pooling-for-graph-neural-networks">Edge Contraction Pooling for Graph Neural Networks</h1><blockquote><p>这里搜到两个题目，但其实内容是一样的，其中第一篇较为粗糙，第二篇精细一些。</p></blockquote><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li>使用deep learning来对graphs进行处理是进来的一个热点，其中许多启发自CNNs，关于其中pooling layers的研究却显得欠缺。</li><li>pooling的作用是非常显著的：确定clusters、减少计算复杂度</li><li>本研究提出一种新的基于edge contraction的pooling layer——EdgePool，其不再去选择保留哪些nodes，而是去选择保留哪些edges。</li></ol><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-03-01.png"><br></p><h3 id="相关工作">相关工作</h3><p>这里可以将所有的pooling分为两种：直接进行pooling和学习进行pooling。</p><ul><li>DiffPool，学习进行pooling。</li><li>Graph U-net，学习进行pooling。【Cangea et al.(2018)】使用其去进行graph classification。</li><li>SAGPool，学习进行pooling。</li></ul><h2 id="methods">Methods</h2><h3 id="edge-contraction-pooling">Edge Contraction Pooling</h3><ol type="1"><li><p>首先为每条edge计算一个score。本研究使用的是下面的过程：</p><p><span class="math display">\[r(e_{ij})=W(n_i||n_j)+b\]</span></p><p>其中<span class="math inline">\(n_i\)</span>和<span class="math inline">\(n_j\)</span>是node features，此得到的是raw score。如果存在edge features <span class="math inline">\(f_{ij}\)</span>，则我们可以这样得到raw score： <span class="math display">\[r(e_{ij})=W(n_i||n_j||f_{ij})+b\]</span></p><p>然后有两种不同的construction methods：</p><ul><li><p>tanh：计算edge score为<span class="math inline">\(s_{ij}=tanh(r_{ij})\)</span></p></li><li><p>softmax：即以某个节点为target，将其neighborhoods的raw scores进行softmax-normalize，即<span class="math inline">\(s_{ij}=softmax_{r_{\star j}}(r_{ij})\)</span></p></li><li><p>（在后一个版本的文章里只有这个计算方法）<span class="math inline">\(s_{ij}=0.5+softmax_{r_{\star j}}{r_{ij}}\)</span></p><blockquote><p>按照上面的公式，好像是沿adjacency matrix的列进行的normalization。</p></blockquote></li></ul><p>然后，将edge scores从大到小进行排序，依次将排名靠前的edge连接的nodes放在一起（如下图所示）形成一个新的节点，而该节点连接到和原来的两个节点有链接的所有节点。</p><p>依次重复进行这个操作，直到聚合了graph中50%的节点。</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-09-42.png"><br></p></li><li><p>聚合node features</p><p>本研究发现，使用最简单的sum就可以取得较好的效果。另外，为了能够保证梯度的流动，所以还需要乘以edge score：</p><p><span class="math display">\[\hat{n}_{ij}=s_{ij}(n_i+n_j)\]</span></p></li><li><p>Unpooling EdgePool</p><p>如果进行node classification并使用Graph U-net的架构来完成，则还需要Unpooling EdgePool。</p><p>这里的做的是：首先将graph的结构复原，然后将“聚合点”的特征除以其对应的edge的score作为新的分离点的特征。 <span class="math display">\[\hat{n}_i=\hat{n}_j=n_{ij}/s_{ij}\]</span></p></li></ol><ul><li>优点：整个计算是sparse的，所以计算量和内存占用都比较小；其影响只在需要进行pooling的edges上进行，所以对于大型的graphs或变化的graphs有计算优势。</li><li>缺点：每次都让nodes的数量减半，这无法由用户控制。</li></ul><h2 id="results">Results</h2><p>回答两个问题：</p><ul><li>EdgePool是否要优于TopKPool和DiffPool？</li><li>EdgePool是否可以作为一个即插即用的GNN组件？</li><li>EdgePool是否可以用于node classification？</li></ul><h3 id="评价过程">评价过程</h3><p>使用的graph classification数据集是来自【Kersting et al. (2016)】：PROTEINS、两个reddit-based datasets、COLLAB。</p><p>使用的node classification数据集是5个semi-supervised node classification datasets：CORA、CITESEER、PUBMED是3个citation networks，PHOTO、COMPUTER是2个Amazon co-purchasing graph。每次使用20 nodes per class来训练，30 nodes per class来测试。其他节点是unlabelled。</p><p>训练时，使用Adam，200 epochs，lr是10-3（每50个epochs减半），batch size是128。</p><p>PROTEINS使用的channels是64，其他使用128。【Ying et al. (2018)】所有的模型都有dropout和batch normalization。另外，发现对edge score使用dropout会显著提升EdgePool's的性能，这里设置drop probability是0.2。</p><p>使用10-fold cross-validation，报告mean和std。</p><h3 id="模型架构">模型架构</h3><ul><li><p>对于第一个问题：</p><p>使用3个SAGEConv blocks和3个pooling交替堆叠而成，然后接一个global mean pooling。将3个block的输出和global pooling的输出concat后接两层fc进行分类，base model不适用pooling。SAGEConv blocks和模型的详细情况见下图：</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-14-12-58.png"><br></p><p>DiffPool限制为每个graph最多750个nodes，TopKPool使用rate为0.5使得其和EdgePool一致。</p><p>loss使用cross-entropy loss，为了保证一致，DiffPool训练时没有使用additional auxiliary losses。</p></li><li><p>对于第二个问题：</p><p>我们将使用不同的GNNs layers来配合EdgePool形成model，并查看其效果。使用的GNNs有：GCN、GIN、GIN0、GraphSAGE、GraphSAGE na。</p><p>网络架构如下图所示：</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-14-21-55.png"><br></p></li><li><p>对于第三个问题：</p><p>评价的GNN类型有GCN、GIN、GIN0、GAT，另外还评估了MLPs的效果。</p><p>这里的网络架构类似第二个问题，但有7层conv layers。其中第2、4层后使用pool，第5、7层后使用unpooling，然后在pooling和unpooling间使用shortcuts（U-Net）。然后将concated的features使用2-layers MLP来预测node class。</p></li></ul><h3 id="评价指标">评价指标</h3><p>下面是关于第一个问题的实验结果：</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-33-45.png"><br></p><p>EdgePool在3个数据集上取得最佳效果，而且仅在一个数据集上次于DiffPool。EdgePool“伸缩性”更好，可以在更大的graph上使用。</p><p>下面是关于第二个问题的实验结果：</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-37-00.png"><br></p><p>可以看到，大多数情况下EdgePool都带来了性能的提升（平均2.2个百分点）。其中在GIN和GIN0上提升最小（0.3个百分点），在GraphSAGE上提升最大（5.5个百分点）。</p><p>对于MLP，我们可以发现，EdgePool都有提升。MLP并不能自动地联系各个节点之间的信息，只有插入其中的pooling能够做到，EdgePool能够普遍地带来提升意味着其能够完成这个任务。</p><p>但遗憾的是，引入pooling带来的性能提升与使用的数据集和模型都有关系，所以我们无法做出一个明确的建议。</p><p>下面是关于第三个问题的实验结果：</p><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-42-40.png"><br></p><p>可以看到，使用EdgePool能够普遍地提高node classification的性能。</p><p>MLP仅仅通过添加EdgePool来联系节点间的信息，就可以达到媲美GNNs的效果。</p><h3 id="可视化">可视化</h3><p><img src="/2020/09/01/paper/dl/paper-edgepool-2019/paper-EdgePool-2019_2020-09-02-15-45-23.png"><br></p><p>fig1和fig3都是可视化结果。我们发现经过池化后，蛋白质的线性结构依然被保持。但同时在fig3中，我们也发现EdgePool会导致一些反直觉的node poolings。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-SAGpool-2019</title>
      <link href="/2020/09/01/paper/dl/paper-sagpool-2019/"/>
      <url>/2020/09/01/paper/dl/paper-sagpool-2019/</url>
      
        <content type="html"><![CDATA[<h1 id="self-attention-graph-pooling">Self-Attention Graph Pooling</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/inyeoplee77/SAGPool" target="_blank" rel="noopener">Github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>CNNs在graph领域的推广的兴趣，使得出现了一些关于graph pooling的研究。</p><p>最早是一些仅仅关注于graph topology的方法：【Defferrard et al., 2016; Rhee et al., 2018】</p><p>之后开始将node features的信息考虑进去：【Dai et al., 2016; Duvenaud et al., 2015; Gilmer et al., 2017b; Zhang et al., 2018b】</p><p>最近，【Ying et al.; Gao &amp; Ji; Cangea et al.】分别提出了几种革新的方法，使得使用GNNs来构建hierarchical representation称为可能。</p></li><li><p>然而，以上方法都存在一定的问题，有提高的空间。本研究提出SAGPool方法，其利用self-attention mechanism，并同时考虑了node features和graph topology。</p></li></ol><h3 id="related-work">Related Work</h3><ol type="1"><li><p>Graph Convolution</p></li><li><p>Graph Pooling</p><ul><li><p>Topology based pooling</p><p>其中最常用的是Graclus【Dhillon et al., 2007】，其寻求了eigendecomposition的数学等价，从而降低了计算复杂度。</p></li><li><p>Global pooling</p><p>Set2Set【Vinyals et al., 2015】</p><p>SortPool【Zhang et al., 2018b】</p></li><li><p>Hierarchical pooling</p><p>DiffPool、gPool（更低的storage complexity）</p></li></ul></li></ol><h2 id="methods">Methods</h2><h3 id="self-attention-graph-pooling-1">Self-Attention Graph Pooling</h3><p>这里我们使用GNNs来构建self-attention score<span class="math inline">\(Z\in\mathbb{R}^{N\times1}\)</span>，如果使用的是GCN，则公式如下：</p><p><span class="math display">\[Z=\sigma(\widetilde{D}^{-\frac{1}{2}}\widetilde{A}\widetilde{D}^{-\frac{1}{2}}X\Theta_{att})\]</span></p><p>其中<span class="math inline">\(\Theta_{att}\in\mathbb{R}^{F\times1}\)</span>，其中<span class="math inline">\(F\)</span>是节点特征的维度。这样的scores，是考虑了features和topology的。</p><p>然后，参考gPool【Gao &amp; Ji; Cangea et al.】的做法，设定<span class="math inline">\(k\in(0,1]\)</span>为pooling ratio，则top <span class="math inline">\(\lceil kN\rceil\)</span>的nodes被保留：</p><p><span class="math display">\[idx=toprank(Z, \lceil kN\rceil),\quad Z_{mask}=Z_{idx}\]</span></p><p>然后：</p><p><span class="math display">\[X'=X_{idx,:},\quad X_{out}=X'\odot Z_{mask},\quad A_{out}=A_{idx,idx}\]</span></p><blockquote><p>总体来说做法和gPool一致，这在中进行过仔细介绍。</p></blockquote><p>图示：</p><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-16-38-34.png"><br></p><h3 id="sagpool的变体">SAGpool的变体</h3><p>根据上面的叙述，GCN实际上也可以换成其他的GNNs。</p><p>另外，如果我们希望在计算self-attention scores的时候考虑到2-hop neighborhoods，可以有下面2种策略：</p><ul><li><p>“augmentation”</p><p><span class="math display">\[Z=\sigma(GNN(X, A+A^2))\]</span></p></li><li><p>“serial”</p><p><span class="math display">\[Z=\sigma(GNN_2(\sigma(GNN_1(X, A)), A))\]</span></p></li></ul><p>另外，还可以有效下面的做法（类似multi-head）：</p><ul><li><p>“parallel”</p><p><span class="math display">\[Z=\frac{1}{M}\sum_m\sigma(GNN_m(X,A))\]</span></p></li></ul><h3 id="模型架构">模型架构</h3><p>为了便于进行比较，架构来自【Zhang et al.】和【Cangea et al.】。</p><ul><li><p>convolution layer，使用GCN，激活函数用ReLU</p></li><li><p>readout layer，使用：</p><p><span class="math display">\[s=\frac{1}{N}\sum_{i=1}^N{X_i}||max_{i=1}^NX_i\]</span></p><blockquote><p>也就是addition和max都考虑，并将其结构concatenation到一起。</p></blockquote></li><li><p>global pooling architecture</p><p>继承自【Zhang et al.】，见fig2。</p></li><li><p>hierarchical pooling architecture</p><p>继承自【Cangea et al.】，见fig2。</p></li></ul><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-17-05-55.png"><br></p><h2 id="results">Results</h2><h3 id="数据集">数据集</h3><ul><li>D&amp;D，蛋白质分子是不是酶</li><li>PROTEINS，也是蛋白质分子</li><li>NCI，每张图是一个化合物，预测化合物的抗癌效应</li><li>NCI1和NCI109</li><li>FRANKEN-STEIN，化学分子是否是诱变剂</li></ul><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-17-09-18.png"><br></p><h3 id="评价流程">评价流程</h3><p>进行20次10-fold CV，一共有200个testing results来得到最后的结果。training data中的10%被用来作为validation。使用Adam、early stop（50个epochs的valid loss没有降低），总的epochs是100k。</p><p>进行grid search的hyperparamters有：</p><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-17-12-49.png"><br></p><h3 id="基线方法">基线方法</h3><ul><li>hierarchical pooling：DiffPool、gPool、SAGPool_h</li><li>global pooling：Set2Set、SortPool、SAGPool_g</li></ul><h3 id="sagpool的变体-1">SAGpool的变体</h3><ol type="1"><li>使用了3种不同的GNNs：cheb、sage、gat</li><li>然后是上面提到的3种变体：augmentation、serial、parallel</li></ol><h3 id="结果">结果</h3><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-19-25-32.png"><br></p><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-19-26-29.png"><br></p><h2 id="discussion">Discussion</h2><h3 id="global和hierarchical-pooling的比较">Global和hierarchical pooling的比较</h3><p>global pooling更加适用于节点数较少的graphs；而hierarchical pooling适用于节点数较多的graphs。</p><h3 id="考虑graph-topology的效果">考虑graph topology的效果</h3><p>从tab3中就可以看出，尽管SAGpool和gPool有着相同的参数数量，但效果要好得多。</p><h3 id="稀疏实现">稀疏实现</h3><p>如果使用dense adjacency matrix进行GNNs操作，其时间复杂度和空间复杂度都要比使用sparse adjacency matrix高。SAGPool是使用sparse adjacency matrix进行操作的，而DiffPool是使用dense。</p><h3 id="节点数量">节点数量</h3><p>DiffPool中参数的数量和输出的节点的数量相关，这可能导致参数的量随节点数量的线性增长，而SAGPool中参数的数量和节点的数量无关。</p><p><img src="/2020/09/01/paper/dl/paper-sagpool-2019/paper-SAGpool-2019_2020-09-01-19-38-42.png"><br></p><h3 id="sagpool变体间的比较">SAGPool变体间的比较</h3><ol type="1"><li>增加2-hop的关系到SAGPool中，可以提高效果。（在SAGPool中堆叠更多的GNNs）</li><li>使用parallel策略，选择合适的M，至少可能让结果更加稳定。</li></ol><h3 id="limitations">Limitations</h3><p>无法确定保留节点的数量，这始终作为一个超参数。本研究试图将其变成一个2分类预测问题来自动决定哪些节点被保留，但这没有根本的解决问题。</p><h2 id="conclusion">Conclusion</h2><p>未来，可以探索如何自动决定pooling size以及多个pooling layers间的相互影响。</p><hr><h2 id="questions">Questions</h2><ol type="1"><li>在global architecture中，global pooling不就是一个readout吗？为什么会有一个pooling和一个readout分开？</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-Graph Unet-2019</title>
      <link href="/2020/09/01/paper/dl/paper-graphunet-2019/"/>
      <url>/2020/09/01/paper/dl/paper-graphunet-2019/</url>
      
        <content type="html"><![CDATA[<h1 id="graph-u-nets">Graph U-Nets</h1><ul><li>杂志: Proceedings of Machine Learning Research</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>CNNs在人工智能领域的成功，促成了类似思想在graph领域的进展（GNNs）。</p></li><li><p>CNNs在pixel-wise prediction tasks领域取得了一定的进展，比如U-Net【Ronneberger et al., 2015】使用Encoder-Decoder的架构进行。所以是否可以在graph领域将其进行推广是一个非常有趣的问题。</p><p>要想进行推广，首先需要解决的就是如何实现在graph上的pooling和unpooling。</p></li><li><p>本研究提出了gPool和gUnpool operations，从而依靠这两个operations，构建了Graph U-net architecture。其可以进行high-level feature encoding和decoding，用来进行network embedding。</p></li></ol><h3 id="related-work">Related Work</h3><blockquote><p>这里面介绍了很多方法，如果我比较了解的，就不赘述了。</p></blockquote><ol type="1"><li>GCNs【Kipf &amp; Welling, 2017】</li><li>【Hamilton et al., 2017】采样固定数量的neighborhoods，从而降低计算量。</li><li>【Velickovic et al., 2017】将attention mechanism应用于graph。</li><li>【Schlichtkrull et al., 2018】使用relational GCNs来进行link prediction。</li><li>还有很多工作进行graph classification tasks。【Duvenaud et al., 2015; Dai et al., 2016; Zhang et al., 2018; Henaff et al., 2015; Bruna et al., 2014】</li></ol><p>另外，还有许多研究试图扩展pooling operations到graphs中：</p><ol type="1"><li>【Defferrard et al., 2016】提出使用binary tree来进行graph coarsening。</li><li>【Simonovsky &amp; Komodakis, 2017】使用的是确定性的graph clustering算法进行pooling。</li><li>【Ying et al., 2018】使用assignment matrix来进行pooling，assignment可微，从而可以进行end-to-end的training（DiffPool）。</li></ol><h2 id="methods">Methods</h2><h3 id="graph-pooling-layer">Graph Pooling layer</h3><p>在第<span class="math inline">\(l\)</span>层，graph是<span class="math inline">\(\mathbb{G}\)</span>，有<span class="math inline">\(N\)</span>个节点，每个节点有<span class="math inline">\(C\)</span>个特征。所以邻接矩阵和feature matrix可以分别表示为<span class="math inline">\(A^l\)</span>和<span class="math inline">\(X^l\)</span>，<span class="math inline">\(X^l\)</span>的每一行<span class="math inline">\(x_i^l\)</span>表示一个节点的特征向量。</p><p>主要流程是：</p><ol type="1"><li><p>创建一个可训练参数向量<span class="math inline">\(\mathbf{p}^l\)</span>。</p></li><li><p>为每个节点计算一个scalar分数：<span class="math inline">\(\mathbf{y}=X^l\mathbf{p}^l/||\mathbf{p}^l||\)</span>。</p></li><li><p>选择分数最高的<span class="math inline">\(k\)</span>个节点：<span class="math inline">\(idx=rank(\mathbf{y},k)\)</span>。</p></li><li><p>保留这些节点的特征以及它们的连接关系作为下采样后的图：</p><p><span class="math display">\[A^{l+1}=A^l(idx,idx)\quad\text{and}\quad\widetilde{X}^l=X^l(idx,:)\]</span></p></li><li><p>根据分数对特征的值进行相应的变换，即排名越靠前的节点的特征越“明显”：</p><p><span class="math display">\[\begin{aligned}     \widetilde{\mathbf{y}}=sigmoid(\mathbf{y}(idx)) \\     X^{l+1}=\widetilde{X}^l \odot(\widetilde{\mathbf{y}}\mathbf{1}_C^T) \end{aligned}\]</span></p><p>其中<span class="math inline">\(\mathbf{1}_C\in\mathbb{R}^C\)</span>。</p><p>这个操作，也被称为gate operation。其最重要的作用是，<strong>使得<span class="math inline">\(\mathbf{p}\)</span>加入到了整个模型的end-to-end反向传播的训练中。</strong></p></li></ol><p>整个流程图见下图：</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-12-53-39.png"><br></p><h3 id="graph-unpooling-layer">Graph Unpooling layer</h3><p>这里我们需要进行gPool的时候，把保留的节点的位置记录（这里记录的就是其在<span class="math inline">\(X\)</span>和<span class="math inline">\(A\)</span>的行标和列标）。</p><ol type="1"><li><p>unpooling后得到的<span class="math inline">\(A\)</span>就是pooling之前的<span class="math inline">\(A\)</span>。</p></li><li><p>unpooling之后的<span class="math inline">\(X\)</span>的shape和pooling之前的<span class="math inline">\(X\)</span>shape相同，首先使用0进行填充，然后在我们记录的节点位置上用当前的节点的特征进行填充。</p><blockquote><p>剩下的那些没有填充的节点依然是0。</p></blockquote></li></ol><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-13-08-28.png"><br></p><h3 id="graph-u-nets-1">Graph U-nets</h3><p>类似计算机视觉中的pixel-prediction工作，我们也可以在graph上使用类似的架构来进行node classification的任务。</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-13-16-02.png"><br></p><p>整体的架构可以有上图来描述，其中的skip-connection可以是addition或concatenation。</p><h3 id="graph-connectivity-augmentation-via-graph-power">Graph Connectivity Augmentation via Graph Power</h3><p>在进行gPool的时候，很有可能导致出现很多的isolated nodes，这可能会影响GNNs的性能。</p><p>解决方法是通过一些手段增加一些edges来建立新的联系。这里使用<span class="math inline">\(k^{th}\)</span> graph power <span class="math inline">\(\mathbb{G}^k\)</span>来增加graph connectivity。</p><p>本研究中使用<span class="math inline">\(k=2\)</span>，则我们只需要改变gPool中<span class="math inline">\(A^{l+1}\)</span>的计算方式：</p><p><span class="math display">\[A^2=A^lA^l,\quad A^{l+1}=A^2(idx,idx)\]</span></p><p>其中<span class="math inline">\(A^2\)</span>就是2nd graph power，这样会有比原始graph更好的connectivity。</p><h3 id="improved-gcn">Improved GCN</h3><p>这里对GCN进行一个小小的改进，即将<span class="math inline">\(\hat{A}=A+I\)</span>改为<span class="math inline">\(\hat{A}=A+2I\)</span>。这样在进行feature更新的时候，会更多的考虑节点自身的信息，从而有助于节点分类任务。</p><h2 id="results">Results</h2><p>这里分别使用node classification tasks和graph classification tasks来验证graph U-nets对transductive learning和inductive learning的作用。</p><h3 id="数据集">数据集</h3><p>对于node classification：Cora、Citeseer、Pubmed</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-10-11.png"><br></p><p>这些都是citation networks。20个nodes用于training，500 nodes用于validation，1000 nodes用于testing。</p><p>对于graph classification：D&amp;D、PROTEINS、COLLAB</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-10-26.png"><br></p><h3 id="实验设置">实验设置</h3><p>transductive learning：</p><ol type="1"><li>Encoder：GCN + gPool(2000) + GCN + gPool(1000) + GCN + gPool(500) + GCN + gPool(200) + GCN</li><li>Decoder: (gUnpool + GCN) x 4</li><li>skip connectons: addition</li><li>Predictor: GCN</li><li>Others：identity activaton function【Gao et al., 2018】、L2 regularization（0.001）、Dropout keep rate（for adjacency matrix：0.8，for feature matrix：0.08）</li></ol><p>inductive learning:</p><ol type="1"><li>follow【Zhang et al., 2018】的设置。</li><li>使用graph U-nets作为feature extraction。</li><li>因为graph的大小一直在变，所以这里设置gPool采样的比例为：90%、70%、60%、50%。</li><li>droput keep rate在feature matrix上是0.3。</li></ol><h3 id="performance-study">Performance Study</h3><p>transductive learning：</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-34-10.png"><br></p><p>inductive learning:</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-37-54.png"><br></p><h3 id="消融实验">消融实验</h3><p>这里，我们将gPool和gUnpool移除，然后看结果的变化：</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-48-40.png"><br></p><p>将graph connectivity augmentation移除，结果：</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-49-59.png"><br></p><p>探索深度对结果的影响：</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-51-26.png"><br></p><p>最佳深度是4。</p><p>因为gPool增加了额外的参数，所以这里对其参数增加量和其带来的性能变化进行研究。发现这只带来了参数量0.12%的增加，但带来了2.3%的性能增加，所以这是值得的。</p><p><img src="/2020/09/01/paper/dl/paper-graphunet-2019/paper-GraphUnet-2019_2020-09-01-14-56-27.png"><br></p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文献精读-DiffPool-2018</title>
      <link href="/2020/09/01/paper/dl/paper-diffpool2018/"/>
      <url>/2020/09/01/paper/dl/paper-diffpool2018/</url>
      
        <content type="html"><![CDATA[<h1 id="hierarchical-graph-representation-learning-with-differentiable-pooling">Hierarchical Graph Representation Learning with Differentiable Pooling</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li>当前已经有许多GNN的工作，在社会网络【16,21,36】和分子网络【7,11,15】，其基本思路是将整个graph看做一个计算图，然后通过信息的passing、transform、aggregation等来学习node embedding，之后再使用学习到的node embedding来进行node classification【16】或link prediction【32】；</li><li>但以上的GNN的主流方法只能通过graph的结构传递信息，无法分层的推断或汇总信息，这让进行graph classification任务称为挑战，只能使用简单的global pooling【7,11,15,25】；</li><li>本研究提供出了DiffPool方法（fig1），其可以在更深的网络中学习graph的分层表示。灵感来源于CNNs，但为了避免因空间信息的缺失而带来的挑战，DiffPool使用一个堆叠的GNN来学习nodes间的聚类关系，这个GNN也有参数需要进行训练；</li><li>本研究中实验证明DiffPool的有效性，平均提高了7%的准确性，而且在4（一共5个）个graph classification benchmark上达到了state of the art。</li></ol><h3 id="相关工作">相关工作</h3><ol type="1"><li><p>GNN；</p></li><li><p>GNN的graph classification【7,11,40】：</p><ol type="a"><li>简单的sum或average所有的node embedding【11】；</li><li>使用一个virtual node来连接所有的nodes【25】；</li><li>使用一个deep leanring architecture来学习聚合所有的nodes【15】；</li></ol><p>以上的方法都存在无法学习graph中分层信息的缺点，另外还有一些试图将CNN的架构应用到GNN中【29,40】，但这需要指定nodes的一个排序，这本身是困难的；</p></li><li><p>还有一些工作试图先通过graph cluster方法【8,35,13】来确定性的学习graph层次，然后应用到GNN中；</p></li></ol><h2 id="methods">Methods</h2><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-39-55.png"><br></p><h3 id="问题框架">问题框架</h3><ol type="1"><li>graph被表示为<span class="math inline">\((A,F)\)</span>，其中<span class="math inline">\(A\)</span>表示adjacency matrix，<span class="math inline">\(F\in\mathbb{R}^{n\times d}\)</span>表示nodes features，数据集表示为<span class="math inline">\(\mathcal{D}=\{(G_1,y_1,\dots)\}\)</span>；</li><li>我们的任务是学习一个映射<span class="math inline">\(f:\mathcal{G}\to\mathcal{Y}\)</span>，其中的难点在于如何将一个graph表示为一个确定维度的向量表示；</li></ol><p>以上问题可以使用GNN来解决。假设这个GNN符合下面的message-passing框架： <span class="math display">\[H^{(k)}=M(A,H^{(k-1)};\theta^{(k)})\tag{1}\]</span> 其中<span class="math inline">\(M\)</span>是message propagation function，<span class="math inline">\(H\)</span>表示学习到的node embedding，<span class="math inline">\(\theta\)</span>表示学习的参数。</p><p><span class="math inline">\(M\)</span>的实现有多种方式，比如Kipf的GCNs <span class="math display">\[H^{(k)}=ReLU(\widetilde{D}^{-\frac{1}{2}}\widetilde{A}\widetilde{D}^{-\frac{1}{2}}H^{(k-1)}W^{(k-1)})\tag{2}\]</span> 其中<span class="math inline">\(\widetilde{A}=A+I\)</span>，<span class="math inline">\(\widetilde{D}=\sum_j\widetilde{A}_{ij}\)</span>。一般堆叠2-6层即可。</p><p>在以上研究的基础上：</p><ol type="1"><li><p>本工作的目的在于定义一个通用的、端对端的框架允许hierachical地进行学习，即：</p><p>存在一个pooling，返回一个新的graph，nodes数量<span class="math inline">\(m&lt;n\)</span>，adjacency matrix <span class="math inline">\(A'\in\mathbb{R}^{m\times m}\)</span>，和新的node embedding <span class="math inline">\(Z'\in\mathbb{R}^{m\times d}\)</span>，通过在GNN中多次插入这样的模块使得GNN能够逐渐处理越来越“粗”的graph；</p></li><li><p>关键在于如何学习cluster方式。</p></li></ol><h3 id="diffpool">DiffPool</h3><p><strong>基本思想是：堆叠L层的GNN来学习生成cluster的分配矩阵。</strong></p><p><strong>首先介绍，如果使用分配矩阵进行pooling</strong></p><ol type="1"><li><p>在第<span class="math inline">\(l\)</span>层定义一个分配矩阵<span class="math inline">\(S^l\in \mathbb{R}^{n_{l}\times n_{l+1}}\)</span>，注意是软分布策略（其中的元素是连续的数值）；</p></li><li><p>然后下一层的节点特征和邻接矩阵可以由以下方式计算：</p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-13-21.png"><br></p></li><li><p>注意到，因为使用的是软分配策略，所以得到的<span class="math inline">\(A^(l+1)\)</span>是全连接的edge-weighted graph，其第<span class="math inline">\(ij\)</span>个值表示的cluster <span class="math inline">\(i\)</span>和cluster <span class="math inline">\(j\)</span>的连接强度；</p></li></ol><p><strong>如何得到分配矩阵</strong></p><p>由上面可知，进行pooling需要两个东西：<span class="math inline">\(S\)</span>和<span class="math inline">\(Z\)</span>，这里这两者都通过GNN将原始节点特征转换而来：</p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-16-29.png"><br><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-15-54.png"><br></p><p>其中softmax是row-wise的（每一行加在一起为1，即每个节点分配后，加在一起还是原来的那一个）。</p><p><strong>另外，可以证明，DiffPool操作而是permutation invariant</strong></p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-18-23.png"><br></p><blockquote><p>只要是DiffPool中使用的GNN是permutation invariant，则可以证明整个DiffPool就是permutation invariant</p></blockquote><p><strong>辅助训练</strong></p><p>实际上，直接训练上面的框架是困难的，需要额外加入一些辅助训练loss或者说regularizations：</p><ol type="1"><li><p>应该试图将邻接点合并在一起，即对于每一层，最小化：</p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-20-58.png"><br></p><p>其中对于深层的GNN，<span class="math inline">\(A\)</span>就是上一次进行pooling后得到的网络。</p></li><li><p>另外，式6的<strong>softmax输出应该尽可能的接近one-hot向量使得我们比较清楚地知道nodes应该属于那个cluster，所以还需要最小化每个softmax概率的entropy</strong>：</p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-21-59.png"><br></p></li></ol><h2 id="results">Results</h2><h3 id="目的">目的</h3><ol type="1"><li>DiffPool相比于其他GNN pooling方法（sort pooling【40】和Set2Set【15】）相比，是不是更好？</li><li>DiffPool和GNN结合后，在graph classification任务上和其他方法进行比较？</li><li>DiffPool得到的cluster是否可以进行有效的解释？</li></ol><h3 id="数据集">数据集</h3><ol type="1"><li>Protein data sets：ENZYMES、PROTEINS、D&amp;D；</li><li>Social networks：REDDIT-MULTI-12K、COLLAB；</li></ol><p>相关统计学指标见Appendix A；</p><p>所有的指标使用的10-cv后的平均acc评价。</p><h3 id="模型超参数">模型超参数</h3><ol type="1"><li>使用的是graphSage中的mean variant【16】，并每隔2个graphSage加一层DiffPool，对于小型数据集（ENZYMES、PROTEINS、COLLAB）一层DiffPool也能取得类似性能；</li><li>在进行下一个pooling或readout之前进行3层graph convolution；</li><li>如果是2个DiffPool，则pooling后的nodes数量设为之前的25%，如果是1个DiffPool，则设为10%；</li><li>每个graphSage都应用了BN，并且在每个nodes embedding上加l2正则化会稳定训练；</li><li>训练了3000个epochs，并在验证集随时不再下降的时候使用了early stop；</li><li>另外，为了评价DiffPool中的一些组件的功能，还有两个简单版本的DiffPool：<ol type="a"><li>DiffPool-set，其分配矩阵是通过确定性的graph聚类算法得到的；</li><li>DiffPool-nolp，没有link prediction辅助训练；</li></ol></li></ol><h3 id="基线方法">基线方法</h3><ol type="1"><li>基于GNN的方法：<ol type="a"><li>GraphSage，带有mean-pooling【16】，其他变种没有使用，因为【21】证明了GraphSage在此类任务上效果是最好的；</li><li>Structure2vec【7】，使用的是global mean pooling；</li><li>Edge-conditional filters（ECC）【35】使用图粗化算法来进行pooling，并考虑了edge information到GCN model中；</li><li>PatchySan【29】定义了每个节点的receptive field，并使用规范的节点排序来进行卷积；</li><li>Set2Set【38】；</li><li>SortPool【40】；</li></ol></li></ol><p>执行10-CV来得到最后结果，并联系原作者得到其代码来进行实验，并按照原始作者的思路进行超参数搜索；</p><ol start="2" type="1"><li>基于kernel的算法：GRAPHLET、SHORTEST-PATH、WEISFEILER-LEHMAN（WL）、WL-OA kernel作为baseline，使用的是C-SVM分类器，其中<span class="math inline">\(C\in\{10^(−3),10^(−2),\dots,10^2,10^3\}\)</span>，通过10-CV确定，对于WL和WL-OA，从<span class="math inline">\(\{0,\dots,5\}\)</span>中搜索迭代次数。</li></ol><h3 id="graph分类结果">Graph分类结果</h3><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-30-48.png"><br></p><ol type="1"><li>这个结果回答了问题1和问题2，即DiffPool有更加好的性能，平均来说比graphSage提高了6.27%，并在4个benchmark上有最佳效果。在collab上则是确定性的聚类有更好的效果，这是因为collab的网络有许多社区结构，仅通过聚类算法就已经能够很好的捕获了，所以实现了更好的效果；</li><li>另外，DiffPool算法在经过Link Prediction限制后，有更好的稳定性；</li></ol><p>另外我们将DiffPool应用到了另外的S2V模型上，以证明DiffPool可以应用到不同的GNN模型框架中：</p><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-32-26.png"><br></p><p>发现DiffPool也使S2V模型的效果得到提升，在其他数据集上也有类似的结果。</p><p>至于运行时间，发现DiffPool并不会招致大量的额外时间，因为减小了网络大小。带有DiffPool的GraphSage模型比带有Set2Set的GraphSage要快12倍，而且有更高的准确性。</p><h3 id="聚类分配结果分析">聚类分配结果分析</h3><p><img src="/2020/09/01/paper/dl/paper-diffpool2018/paper-DiffPool2018_2020-09-01-11-35-54.png"><br></p><ol type="1"><li>分层聚类结构：DiffPool得到的分层结构展示在fig2中（COLLAB），其中颜色代表其属于的cluster类别，我们观察到了明显的分层社区结构，尽管其只通过分类来学习的。有辅助训练的分配质量会有所提高；</li><li>DiffPool得到的是密集连接的图，这可能会减少损失的信息；</li><li>有相似表示的nodes会被分配到在一起，比如距离非常远的两个节点，但其与周围邻居的连接模式相似，则两者可能会被分配到相同的cluster中，这和image ConvNets不同；</li><li>结果对cluster的数量敏感。大的cluster数量可能会导致更大的噪声和更低的效率；</li></ol><h2 id="conclusion">Conclusion</h2><p>本研究提出了一种可微分的池化方法，能够提取复杂的层次结构。和现有的GNN模型结合后，在benchmark上取得了非常好的结果。</p><p>未来的一个研究方向是去进行hard cluster assignment，可以降低计算成本，同时还确保了可区分性；另外还需要将其应用于其他的任务上，探索其在分类以外任务的能力。</p><hr><h2 id="questions">Questions</h2><p>针对这个方法，实际上我有自己的思路进行改进，基本的想法和其在结论中提到的一致，即hard cluster assignment：</p><ol type="1"><li>使用gumbel softmax来进行分类采样，这样可以引入一定的随机性，而且还变成了hard cluster assignment，可能会提高效率；</li><li>Gumbel softmax的使用引入了另外的思想，即将分配看做是一个隐变量，使用变分推断的思想来进行训练，但如果存在多个pooling层，我们需要想想如何解决？</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-对graph的深度学习的深度介绍-2020</title>
      <link href="/2020/08/28/paper/dl/gnngentlesurvey2020/"/>
      <url>/2020/08/28/paper/dl/gnngentlesurvey2020/</url>
      
        <content type="html"><![CDATA[<h1 id="a-gentle-introduction-to-deep-learning-for-graphs">A Gentle Introduction to Deep Learning for Graphs</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="介绍">介绍</h2><ol type="1"><li><p>graph数据是广泛存在的。</p></li><li><p>深度学习在graphs数据上的研究，需要克服几个挑战：</p><ul><li>模型需要对不同大小、拓扑结构的graphs可用</li><li>节点的信息可能比较稀缺</li><li>graphs是离散对象，可微性不是很好，而其组合特性又限制了我们使用类似穷举的方法进行求解</li><li>有些graphs存在循环</li></ul></li><li><p>深度学习在graphs上的研究历史：</p><ol type="1"><li>早期就有使用RecNN（递归神经网络）【98,32,9】来对tree structured data进行建模的历史，但其无法处理带有cycles的graphs。</li><li>GNN【89】和NN4G【74】可以处理带有cycles的graphs。两者分别为两类方法打下了基础（recurrent-GNN和feedforward-NN4G），特别是后者，是GCN的基础。</li></ol></li><li><p>本研究希望能够对DL在graphs上的方法进行一个介绍，涉及的前沿的方法可能比较少，更多地作为一个tutorial，来巩固一些经典算法。</p></li></ol><h2 id="概述">概述</h2><h3 id="数学符号">数学符号</h3><p>graph：<span class="math inline">\(g=(\mathcal{V}_g, \mathcal{E}_g, \mathcal{X}_g, \mathcal{A}_g)\)</span></p><p>其中节点集合<span class="math inline">\(\mathcal{V}_g\)</span>，边的集合<span class="math inline">\(\mathcal{E}_g\)</span>，如果是directed edges，则<span class="math inline">\(\mathcal{E}_g=\{(u,v)|u,v\in\mathcal{V}_g\}\)</span>，如果是undirected edgs，则认为<span class="math inline">\((u,v)=(v,u)\)</span>，<span class="math inline">\(\mathcal{E}_g\)</span>同时拥有两个方向的arcs。有时候可以直接使用邻接矩阵<span class="math inline">\(\mathbf{A}\in{0,1}^{|\mathcal{V}_g|\times|\mathcal{V}_g|}\)</span>来表示<span class="math inline">\((\mathcal{V}_g, \mathcal{E}_g)\)</span>。</p><p>节点<span class="math inline">\(v\)</span>上的特征是<span class="math inline">\(\mathbf{x}_v\in\mathcal{X}_g\)</span>，边<span class="math inline">\((u,v)\)</span>上的特征是<span class="math inline">\(\mathbf{a}_{uv}\in\mathcal{A}_g\)</span>。节点、边、整个graph的标签使用<span class="math inline">\(y_v,y_{uv},y_g\)</span>来表示。</p><p>如果graph的节点定义了一个顺序，则称之为是ordered，反之是unordered。如果边的集合和一个自然数的集合存在双射，则称为positional，反之称为non-positional。<strong>我们关注的是unordered和non-positional的graph。</strong></p><p>节点<span class="math inline">\(v\)</span>的邻域（neighborhood）定义为<span class="math inline">\(\mathcal{N}_v=\{u\mathcal{V}_g|(u,v)\in\mathcal{E}_g\}\)</span>。这个也成为了open neighborhood，有时候我们也把<span class="math inline">\(v\)</span>本身也加入其中，这时称为closed neighborhood。进一步，结合边的特征，我们可以定义特征符合条件的neighborhood<span class="math inline">\(\mathcal{N}_v^{c_k}=\{u\in\mathcal{N}_v|\mathbf{a}_{uv}=c_k\}\)</span>。</p><blockquote><p>原始文献PDF这里应该是写错了（第6页第3行，应该是v而不是u）</p><p>在图论中，neighborhood不是点的集合，而是一个subgraph，是邻接点及其与指定点的边组合成的subgraph。</p></blockquote><p><span class="math inline">\(l\)</span>用来表示第<span class="math inline">\(l\)</span>层或第<span class="math inline">\(l\)</span>个迭代步骤，<span class="math inline">\(\mathbf{h}_v^l\)</span>表示节点<span class="math inline">\(v\)</span>在第<span class="math inline">\(l\)</span>层或第<span class="math inline">\(l\)</span>个迭代步骤后得到的特征。</p><p>使用<span class="math inline">\(\Psi\)</span>来表示permutation invariant function。当其输入（一般来说输入是一个集合）的元素数量是可数时，可以大致将其写成下面的形式： <span class="math display">\[\Phi(Z)\approx\phi(\sum_{z\in Z}{\psi(z)})\]</span> 其中<span class="math inline">\(\phi\)</span>和<span class="math inline">\(\psi\)</span>是任意的函数。</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-28-14-06-20.png"><br></p><h3 id="动机">动机</h3><p>自适应地学习到新的特征进行下游的任务。</p><h3 id="概览">概览</h3><p><strong>不管任务是什么，几乎所有的算法首先都生成节点的表示，这称为graph的isomorphic transduction。</strong>然后在此基础上，再根据任务的不同进行后续的操作。</p><p>这里，我们DGN来同一描述这些所有的算法，具体来说，是这些算法中从graph到生成节点特征的部分，如下图所示。</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-28-16-11-29.png"><br></p><p>DGN被进一步分为3类：</p><ul><li>DNGNs（Deep Neural Graph Networks）</li><li>DBGNs（Deep Bayesian Graph Networks）</li><li>DGGNs（Deep Generative Graph Networks）</li></ul><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-28-16-14-12.png"><br></p><h3 id="局部关系和信息的迭代处理">局部关系和信息的迭代处理</h3><p>对于graph的处理面临以下两个基本问题，而且讨论了其普遍的解决方案（<strong>“局部和迭代”方法</strong>）。</p><ul><li><p>graph的拓扑结构是没有什么限制假设的</p><p>这一般通过<strong>在node level局部地而不是在graph level全局地建立模型</strong>来完成【98】，即考虑的是节点和其邻节点间的关系。这称为stationary assumption。</p><p>但stationary assumption并没有完全解决问题，因为每个节点所拥有的邻接点的数量是变化的。所以，一般还需要<strong>使用permutation invariant function来将邻接点集合进行处理</strong>。</p></li><li><p>可能存在cycle</p><p>解决这个问题的方法是<strong>建立迭代机制</strong>，即<span class="math inline">\(\mathbf{h}_v^{l+1}\)</span>是第<span class="math inline">\(l\)</span>次迭代的邻接点特征计算得到，这样就算是有cycle存在，也可以方便被纳入其中（可以看做自我更新）。另外，迭代机制也可以很方便地集成到深度架构中。</p></li></ul><h3 id="context-diffusion的3种机制">context diffusion的3种机制</h3><p>context指的是计算节点特征所使用的信息。<strong>context diffusion描述的是我们如何将单个节点的信息传递到整个网络中</strong>，毕竟我们不希望节点信息被只限制在它的小邻域中。</p><p>之前介绍的“局部和迭代”方法可以实现context diffusion。如下图所示：</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-28-17-09-46.png"><br></p><p>通过两层的迭代，节点<span class="math inline">\(u\)</span>能够接收到更多节点的信息。而如果增加到第3层迭代，则<span class="math inline">\(u\)</span>将接收到所有节点的信息。这也说明了<strong>深度不仅有助于特征的自动化处理，而且还对context diffusion</strong>。</p><p>根据context diffusion实现机制的不同，我们将DGNs的模型分为下面3类：</p><ul><li><p>Recurrent Architectures</p><p>代表是Graph Neural Networks（GNNs）【89】和Graph Echo State Networks（GESNs）【35】，通过在一个操作上进行反复的迭代计算来实现context diffusion。一般需要通过动力学上的限制使得在recurrent iteration的时候收敛。</p></li><li><p>Feedforward Architectures</p><p>没有使用迭代，而是通过堆叠多层来实现。和recurrent architecture相比，每一层（或迭代）使用的是不同参数的layers，而且不需要有收敛的限制。</p><blockquote><p>这也是最常见的，我们接触到的大多数图神经网络都是这个。</p></blockquote></li><li><p>Constructive Architectures</p><p>可以看做是Feedforward architecture的特殊形式，区别在于其训练时是逐层训练的。</p><p>好处在于这可以避免一些梯度消失/爆炸的问题，所以context可以更加有效地传递到其他节点中。并且在逐层训练时，还可以通过某些策略自动确定使用的层数。</p><p>代表有Neural Network for Graphs（NN4G）【74】和Contextual Graph Markov Model（CGMM）【3】。</p></li></ul><h2 id="构建模块">构建模块</h2><p>介绍我们构建模型常使用到的模块，以及如何将这些模块进行组装构成一个模型。</p><h3 id="邻接点聚合neighborhood-aggregation">邻接点聚合（Neighborhood Aggregation）</h3><p>这里我们假设graphs是non-positional，所以我们需要使用permutation invariant function。</p><p>最general的形式，如下：</p><p><span class="math display">\[\mathbf{h}_v^{l+1}=\phi^{l+1}(\mathbf{h}^l_v,\Psi(\{\psi(\mathbf{h}_u^l)|u\in\mathcal{N}_v\})) \tag{1}\]</span></p><ul><li><p>处理graph的edges</p><p>上面的公式并没有考虑到edges的特征。如果edges的属性是离散的（比如边的类型有2种），则我们可以将上面的公式1进行修改： <span class="math display">\[\mathbf{h}_v^{l+1}=\phi^{l+1}(\mathbf{h}^l_v,  \sum_{c_k\in\mathcal{A}}{(\Psi(\{\psi(\mathbf{h}_u^l)|u\in\mathcal{N}_v^{c_k}\})\cdot w_k)}) \tag{2}\]</span></p><p>其中<span class="math inline">\(c_k\)</span>是边的标签，<span class="math inline">\(w_k\)</span>是该边对应的贡献度，是一个可训练的参数。NN4G、R-GCN和CGMM都实现了公式2。</p><p>更general，针对边的特征是连续的： <span class="math display">\[\mathbf{h}_v^{l+1}=\phi^{l+1}(\mathbf{h}^l_v,  \Psi(\{e^{l+1}(\mathbf{a}_{uv})^T\psi(\mathbf{h}_u^l)|u\in\mathcal{N}_v\})) \tag{3}\]</span></p><p>其中<span class="math inline">\(e^{l+1}(.)\)</span>和<span class="math inline">\(\phi\)</span>、<span class="math inline">\(\psi\)</span>一样，可以是任意的函数。</p></li><li><p>注意力机制</p><p>需要给与一个注意力权重，此权重由两点的特征进行计算，可以使用下面的公式描述：</p><p><span class="math display">\[\mathbf{h}_{v}^{l+1}=\phi^{l+1}(\mathbf{h}_v^{l},  \Psi(\{\alpha_{uv}^{l+1}\cdot\psi^{l+1}(\mathbf{h}_u^l)|u\in\mathcal{N}_v\}))\tag{4}\]</span></p><p>其中<span class="math inline">\(\alpha_{uv}\)</span>就是注意力权重，在GAT【102】中，其计算时没有考虑边的特征： <span class="math display">\[\alpha_{uv}^l=\frac{\exp(w_{uv}^l)}{\sum_{u'\in\mathcal{N}_v}{\exp(w_{u'v}^l)}}\]</span> <span class="math display">\[\begin{aligned}      w_{uv}^l&amp;=a(\mathbf{W}^l\mathbf{h}_u^l,\mathbf{W}^l\mathbf{h}_v^l) \\      &amp;=LeakyReLU((\mathbf{b})^T[\mathbf{W}^l\mathbf{h}_u^l,\mathbf{W}^l\mathbf{h}_v^l])  \end{aligned}\]</span> 其中<span class="math inline">\([:,:]\)</span>表示concatenation。另外GAT还使用了multi-head attention，即将多个注意力机制的输出concat或average。</p></li><li><p>采样</p><p>当graphs比较large或dense的时候，邻接点数目太多，就不适合将全部的邻接点进行处理，sampling是自然的解决这个问题的想法。</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-28-18-17-19.png"><br></p><p>采用这种策略的模型有FastGCN【18】和GraphSAGE【42】：</p><ul><li>FastGCN：在每一层，使用importance sampling进行采样（降低方差）。</li><li>GraphSAGE：通过一些策略来选择本次传递信息到目标节点的节点是哪些，这些节点可能不只是目标节点的邻接点，还有可能是目标节点的二阶邻接点、三阶邻接点等。所以GraphSAGE可能不止有locally的能力。</li></ul></li></ul><p>下面的tab1列举了我们常用的进行node aggregation的各种方法，可以参考使用：</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-01-55-33.png"><br></p><h3 id="池化">池化</h3><p>pooling主要有3个作用：</p><ul><li>发现重要的communications。</li><li>将communications的信息注入到学习的features中。</li><li>降低计算复杂度</li></ul><p>pooling可以分为两类：</p><ul><li><p>adaptive，自适应</p><p>参数化的、可学习的决定怎样进行pooling。</p><p>DiffPool【120】，首先使用本层学习到的特征计算一个soft-membership matrix <span class="math display">\[\mathbf{S}^{l+1}=softmax(GNN(\mathbf{A}^l, \mathbf{H}^l))\tag{5}\]</span> 然后再使用这个matrix重新构筑graph <span class="math display">\[\mathbf{H}^{l+1}={\mathbf{S}^{l+1}}^{T}\mathbf{H}^l\quad\text{and}\quad  \mathbf{A}^{l+1}={\mathbf{S}^{l+1}}^T\mathbf{A}^l\mathbf{S}^{l+1}\]</span> 根据你想要的保留多少个节点来设置<span class="math inline">\(\mathbf{S}^{l+1}\)</span>的维度。因为是soft的，所以整个过程可微，同时使得经过其pooling后的graph是全连接的。</p><p>TopKPool【37】，设置了一个可学习的projection vector <span class="math inline">\(p^l\)</span>来计算一个scores， <span class="math display">\[s^{l+1}=\frac{\mathbf{H}^lp^{l+1}}{||p^{l+1}||}\]</span> 保留这个scores排名靠前的节点和他们之间的相互联系。</p><p>SAGPool【62】则在TopKPool的基础上，使用attention score替代了projection vector <span class="math display">\[s^{l+1}=\sigma(GCN(\mathbf{A}^l,\mathbf{H}^l))\]</span></p><p>EdgePool【33】则将目标放在了边上，为边计算一个权重，权重靠前的边连接的两个节点会被融合成一个， <span class="math display">\[s^{l+1}((u,v)\in\mathcal{E}_g)=\sigma(\mathbf{w}^T[\mathbf{h}_v^l,\mathbf{h}_u^l]+\mathbf{b})\]</span></p></li><li><p>topological，基于拓扑学的</p><p>比如GRACLUS【22】使用谱聚类、NMFPool【2】基于非负矩阵分解等。</p></li></ul><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-01-47-44.png"><br></p><h3 id="用于graph-embedding的node-aggregation">用于graph embedding的node aggregation</h3><p>现在的我们的任务是得到一个graph的feature，所以需要将node features进行聚合得到graph feature，同样这个过程必须是permutation-invariant。</p><p>最常用的就是直接使用sum、max、mean等函数。【123】则进行了一些细致的研究，其先对node features进行一次MLP映射，然后进行summation，然后经过一个非线性映射完成。</p><p>至于使用那些特征来计算graph feature：</p><ul><li>最常见的是只使用最后一层的feature</li><li>将所有中间层的feature都concat</li><li>将所有中间层的feature看做是一个feature sequence，使用LSTM来处理【64】</li><li>SortPool【125】</li></ul><h2 id="任务">任务</h2><h3 id="无监督学习">无监督学习</h3><ul><li><p>Link prediction</p><p>试图去建立node representation，使得相邻的node之间是相似的。所以其reconstruction loss【59】可以写成 <span class="math display">\[\mathcal{L}_{reg}(g)=\sum_{(u,v)}{||\mathbf{h}_v-\mathbf{h}_u||^2}\tag{10}\]</span></p><p>另外，也可以把edge看做存在或不存在，从而构建probabilistic的formulation【58】 <span class="math display">\[P((u,v)\in\mathcal{E}_g|\mathbf{h}_v,\mathbf{h}_u)=\sigma(\mathbf{h}_v^T\mathbf{h}_u)\tag{11}\]</span></p><p><strong>使用上面的loss，意味着你认同这样的假设：相邻的节点应该有更大的倾向被分到相同的community/class中，这称为homphily【69】。这也可以在监督学习中作为一个正则化出现。</strong></p></li><li><p>Maximum Likelihood</p><p>当认为neighborhood服从一定的分布时，我们可以使用极大似然法进行训练。一个典型的例子是CGMM【3】，其堆叠了simple Bayesian Networks，每一层有下面的likelihood： <span class="math display">\[\mathcal{L}(\theta|g)=\prod_{u\in\mathcal{V}_g}\sum_{i=1}^CP(y_u|Q_u=i)P(Q_u=i|\mathbf{q}_{\mathcal{N}_u})\]</span> 其中，<span class="math inline">\(Q_u\)</span>是每个节点的隐藏类别，一共有<span class="math inline">\(C\)</span>类别。<span class="math inline">\(\mathbf{q}_{\mathcal{N}_u}\)</span>是节点<span class="math inline">\(u\)</span>的所有邻接点的特征。<span class="math inline">\(y_u\)</span>是节点<span class="math inline">\(u\)</span>的一个特征。</p><blockquote><p>这个有点像节点分类了。</p></blockquote><p>用到类似技术的还有【83,58】的研究。</p></li><li><p>Mutual Information</p><p>最大化两个相似的graphs之间的MI作为无监督学习的loss。比如DGI【103】，其先使用corruption function（就是添加噪声等扰动操作）生成一个<span class="math inline">\(g\)</span>的扰动版本<span class="math inline">\(\widetilde{g}\)</span>，然后训练一个discriminator来识别两个图。</p></li><li><p>Entropy regularization for pooling</p><p>当使用adaptive pooling的时候，模型会趋向于将每个节点分给单个community。【120】使用了entropy loss来解决这个问题： <span class="math display">\[\mathcal{L}_{ent}(g)=\frac{1}{|\mathcal{V}_g|}\sum_{u\in\mathcal{V}_g}H(\mathbf{S}_u)\]</span> 其中<span class="math inline">\(H\)</span>表示计算entropy，<span class="math inline">\(\mathbf{S}\)</span>表示soft-cluster assignment matrix（公式5），<span class="math inline">\(\mathbf{S}_u\)</span>表示其中表示<span class="math inline">\(u\)</span>的那一行。</p></li></ul><h3 id="监督学习">监督学习</h3><ul><li><p>Node Classification</p><p>这里有两种类型的node classification，即：</p><ul><li>inductive node classification，在一张（或多张）graphs上学习得到模型后，在一张新的graphs上进行分类。</li><li>transductive node classification，只有一张graph，其中有一些节点类型未知，对这些节点进行分类。</li></ul><p>我们会发现benchmark上的结果和实验环境的设置息息相关【93】。</p></li><li><p>Graph Classification/Regression</p><p>与node相比，这里就是多了一个node aggregation的过程。</p><p>同样的，也存在着各种实验基准不一样导致的混乱。【25】推荐了一个同一的平台来进行评价。</p></li></ul><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-15-08-46.png"><br></p><h3 id="生成学习">生成学习</h3><ul><li><p>Graph-level decoding</p><p>输入一个graph的embedding，输出一个dense probabilistic的adjacency matrix <span class="math inline">\(\widetilde{\mathbf{A}}\in\mathbb{R}^{k\times k}\)</span>，其中<span class="math inline">\(k\)</span>表示允许最多的节点数目，元素<span class="math inline">\(\widetilde{a}_{ij}\)</span>表示节点<span class="math inline">\(i\)</span>和<span class="math inline">\(j\)</span>间存在连接的概率。然后使用极大似然法进行训练： <span class="math display">\[\mathcal{L}_{decoder}(g)=-\log P(\widetilde{\mathbf{A}}|\widetilde{\mathbf{h}}_g)\tag{14}\]</span> 其中<span class="math inline">\(P(\widetilde{\mathbf{A}}|\widetilde{\mathbf{h}}_g)=MLP(\widetilde{\mathbf{h}}_g)\)</span>。</p><p>得到probabilistic adjacency matrix后，要想得到一个novel graph，有下面的3种方法：</p><ul><li>直接根据概率<span class="math inline">\(\widetilde{a}_{ij}\)</span>进行采样</li><li>在probabilistic和ground truth之间进行approximate graph matching【96,60】</li><li>使用Gumbel-Softmax将采样过程可微【20】</li></ul></li><li><p>Node-level decoding</p><p>即首先我们采样得到的不是graph的representation，而是很多个node的representation。然后根据这些node的representation看是否两个nodes之间有连接： <span class="math display">\[\mathcal{L}_{decoder}(g)=-\frac{1}{|\mathcal{V}_g|}\sum_{v\in\mathcal{V}_g}\sum_{u\in\mathcal{V}_g}\log P(\widetilde{a}_ij|\widetilde{\mathbf{h}}_u,\widetilde{\mathbf{h}}_v)\]</span> 其中的概率可以通过公式11的方式进行计算。这样的生成过程是permutation-invaraint的，但相对来说计算量特别大。</p></li></ul><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-15-56-37.png"><br></p><ul><li><p>Generative Auto-Encoder</p><p>不止可以进行graph generate，还能够得到graph的embedding，原理基于VAEs。公式可以表示为： <span class="math display">\[\mathcal{L}_{AE}(g)=\mathcal{L}_{decoder}(g)+\mathcal{L}_{encoder}(g)\]</span> 其中的<span class="math inline">\(\mathcal{L}_{decoder}(g)\)</span>就是上面使用的loss，而<span class="math inline">\(\mathcal{L}_{encoder}(g)\)</span>是保证latent space的distribution和某个特定的distribution之间的相似的一个“prior” regularization。 <span class="math display">\[\mathcal{L}_{encoder}(g)=-D_{KL}[\mathcal{N}(\mathbf{\mu},\mathbf{\sigma}^2)||\mathcal{N}(\mathbf{0},\mathbf{I}))]\]</span></p><p>【14】建议可以将encoder error改为Wasserstrain loss。</p></li><li><p>Generative Adversarial Networks</p><p>【27】使用graph-level decoder充当G生成adjacency matrix和node label matrix，然后将这些内容送入一个discriminator中进行判断。</p><p>【107】则使用的是node-level的decoder。</p></li></ul><h3 id="总结">总结</h3><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-16-11-56.png"><br></p><h2 id="其他">其他</h2><p>还有一些主题没有被上面的分类覆盖，在这里进行简要介绍。（只关注于DL的方法，且只关注于基于“局部和迭代”策略的。）</p><h3 id="kernel">Kernel</h3><p>kernel被定义为计算一对输入间相似性的正定函数的推广形式。比如【94,84,115,31,104】即使用kernel来对graph进行操作。</p><p>kernel的主要问题在于其不是local和adaptive（自适应的），需要人类进行设计，其对于人类已经了解的性质自然非常好用，但对于其他的大量的未知，则无法触及。</p><p>基于kernel的方法一般和SVM一起来进行graph classification。</p><h3 id="spectral-methods">Spectral methods</h3><p>Laplacian smoothing【86】、graph semi-supervised learning【81,17】、spectral clustering【105】、Graph Fourier Transform【46】、GCN【59】（是对其的一阶近似）</p><h3 id="random-walks">Random-walks</h3><p>【67,104,85,50】</p><p>Node2Vec【40】、DeepWalk【82】</p><p>最近，该技术已经用来进行graph generate【12】和探索context diffusion【114】</p><h3 id="adversarial-training和attacks">Adversarial training和attacks</h3><p>【131,28,117,54】</p><h3 id="sequential-generative-models">Sequential generative models</h3><p>【65,121,5,4】</p><h2 id="挑战">挑战</h2><ol type="1"><li>Time-evolving graphs，即随时间变化的graphs，【63,110,124】等研究讨论过类似的问题。</li><li>Bias-variance trade-offs</li><li>合理使用edges information，将edge informations作为context进行传播是否合理？</li><li>Hypergraph learning，hypergraph指的是node set之间进行连接的对象。已经有一些研究进行了讨论【129,128,29,53】，但类似的于Time-evolving graphs，主要的问题在于缺乏数据集。</li></ol><h2 id="应用">应用</h2><p>这里强调，如果可以有更加通用的方法来解决（比如存在顺序等信息可以使用LSTM或CNN来解决），则使用这些方法可能是更好的选择。</p><h3 id="化学和药物设计">化学和药物设计</h3><ol type="1"><li>Quantitative Structure-Activity Relationship（QSAR）和Quantitative Structure-Property Relationship（QSPR）分析，分别是用化学结构来预测生物活动和化学性质（毒性和溶解性等）【9,76】。</li><li>化学结构相似性【24,52】。</li><li>药物设计，特别是使用生成模型来设计符合特定化学性质的分子。</li></ol><p>以下是【25】中对一组DGNs在该领域的相关评估：</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-19-44-32.png"><br></p><h3 id="社会网络">社会网络</h3><p>节点是人，边表示朋友关系或共事关系，目的是检测人是否有不健康的行为或错误信息。因为隐私保护和伦理的问题，许多数据集是不公开的。</p><p>现在主要使用的节点分类的数据集有3个，【93】使用这3个数据集对常用的几个DGNs进行了评价：</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-19-50-07.png"><br></p><p>而常用的graph分类的数据集有以下5个，在常用DGNs上的结果如下:</p><p><img src="/2020/08/28/paper/dl/gnngentlesurvey2020/GNNgentleSurvey2020_2020-08-29-19-51-16.png"><br></p><h3 id="自然语言处理">自然语言处理</h3><p>将语言根据语法分解为tree，然后进行学习建模。【1,71,70,8】</p><h3 id="安全性">安全性</h3><p>静态代码分析</p><h3 id="时空预测">时空预测</h3><p>道路网络的交通预测【122】、动作识别【109】、供给链任务【56】。</p><p>需要能够学习到随时间改变，graph结构的变化。</p><p>一般需要结合DGNs和RNNs。</p><h3 id="推荐系统">推荐系统</h3><p>这里使用的graph是用户和产品组成的一个bipartite graph。任务可以看做是link prediction，已经有些研究涉猎【78,118】。</p><p>现在主要的困难在于如何处理大型的、可伸缩的graph，一些基于采样的方法因此被提出【119】。</p><h2 id="总结-1">总结</h2><p>本研究的目的不在于跟进那些最先进的研究成果，而在于将已经发表的经典进行梳理归纳。这就涉及到两个问题：</p><ol type="1"><li>为所有的DGNs找到一个框架，【38,32,45,44】做出了自己的贡献。</li><li>为所有的DGNs提供统一的、公平的、可重复的测试平台，【25,93】认为这个工作已经迫在眉睫。</li></ol><p>另外，PyG【30】和DGL【108】提供了DGNs的标准接口，使得我们可能轻松的实现我们的模型。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Review </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-conditional pixelCNN-2016</title>
      <link href="/2020/08/26/paper/dl/condi-pixelcnn2016/"/>
      <url>/2020/08/26/paper/dl/condi-pixelcnn2016/</url>
      
        <content type="html"><![CDATA[<h1 id="conditional-image-generation-with-pixelcnn-decoders">Conditional Image Generation with PixelCNN Decoders</h1><ul><li>杂志: NIPS</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>使用NN进行image modelling的研究众多，并且已经能够产生多样的图片。但实际应用中，我们一般需要conditioned on prior information。</p></li><li><p>本研究通过对PixelRNN【30】进行改进，加入卷积来实现conditional image modelling，使用的是自回归的方法，并且有明确的概率密度估计。</p><p>原始文献【30】中的pixelRNN和pixelCNN有着不同的缺点：pixelRNN更加准确，但很慢；pixelCNN更快，但估计不如RNN准确。</p><p>本研究提出了Gated PixelCNN，既能够有准确的估计，而且速度也有保障。</p></li><li><p>另外，本研究还提出了Gated PixelCNN的conditional版本，能够根据一些条件、标签了生成图像。</p></li></ol><h2 id="methods">Methods</h2><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-01-12-53.png"><br></p><h3 id="pixelcnn">PixelCNN</h3><p>上图展示了pixelCNN的基本原理，基本来说，还是遵循了AR模型的假设，需要逐个对像素点进行条件概率建模，其依赖于其前面的像素点。</p><p>pixelCNN在此基础上使用masked CNN来进行建模，其卷积核如上图middle所示。每个位置上，先建模R、然后是G、最后是B。最后使用256-softmax来输出一个像素值的概率。所以pixelCNN输入<span class="math inline">\(N\times N\times3\)</span>，输出<span class="math inline">\(N\times N\times3\times256\)</span>。</p><p>进行采样时，和传统的AR模型一样，逐个pixel的生成。</p><p>但pixelCNN有下面的缺点：</p><ul><li><p>相比于pixelRNN来说，其效果较差。</p><p>这可能是因为pixelCNN相对于pixelRNN来说，其所能访问的像素点范围是随着NN的深度线性增加的，所以当网络不够深时，其无法向pixelRNN一样访问到之前所有的像素点。</p><p>另外，pixelCNN缺乏multiplicative units（LSTM中的门控单元），这些units将有助于构建更加复杂的关系。</p></li><li><p>盲点。</p><p>如上图右上方所示，当使用3x3卷积的时候，随着卷积的增加，进行某个像素点的概率估计的时候，有一部分内容是看不到的，是blind spot。如果有重要的信息在此，可能会影响模型的训练。</p></li></ul><h3 id="gated-pixelcnn">Gated PixelCNN</h3><p>本研究针对上面两个问题，进行了如下的改进：</p><ul><li><p>每一层将relu替换为gated units，从而增加multiplicative units，增加NN的拟合能力：</p><p><span class="math display">\[\mathbf{y}=tanh(W_{k,f}\star\mathbf{x})\odot\sigma(W_{k,g}\star\mathbf{x})\]</span></p><p>其中，<span class="math inline">\(\odot\)</span>表示element-wise product，<span class="math inline">\(\star\)</span>表示convolution，后面的是gated，使用tanh替代relu。gated units可以形成类似highway networks的效果，从而有助于模型的效能提升。</p></li><li><p>针对blind spot的问题，我们使用两个convolutional network的stacks来解决这个问题：其中一个用来聚合像素点上面的行的信息（vertical stack），另一个用来聚合像素点所在行前面的像素点的信息（horizontal stack）。如果上图右下角所示，而下图展示了单层的设计：</p><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-01-37-33.png"><br></p><p>注意：</p><ul><li><p>每一层接受两个输入，必须输出两个结果，分别是horizontal stack和vertical stack。horizontal stack的输出将作为下一层horizontal stack的输入，vertical stack的输出也将作为下一层vertical stack的输入。</p></li><li><p>实现两个stack，可以使用mask（上图是<span class="math inline">\(n\times n\)</span>和<span class="math inline">\(1\times n\)</span>的卷积核，说明使用了masked），也可以使用正常的长方形卷积进行，然后通过padding、cropping和shifting来进行调整，使其卷积得到的信息是提供给我们想要的pixel。</p><blockquote><p>在我看来，就算是使用mask，也必须配合shift（在最后一层进行）才行。</p></blockquote></li><li><p>horizontal stack的输出可以来自混合了horizontal stack和vertical stack的信息，这并没有破坏AR的conditional rules。</p></li><li><p>但vertical stack的输出不得混合horizontal stack的信息，这将破坏conditional rules。</p></li></ul></li></ul><h3 id="conditional-pixelcnn">Conditional PixelCNN</h3><p>所以现在我们需要建模的分布是：</p><p><span class="math display">\[p(x|\mathbf{h})=\prod_{i=1}^{n^2}{p(x_i|x_1,\dots,x_{i-1},\mathbf{h})}\]</span></p><p>这个通过在每一层都加入<span class="math inline">\(\mathbf{h}\)</span>的信息来实现：</p><p><span class="math display">\[\mathbf{h}=tanh(W_{k,f}\star\mathbf{x}+V_{k,f}^T\mathbf{h})\odot\sigma(W_{k,g}\star\mathbf{x}+V_{k,g}^T\mathbf{h})\]</span></p><p>这里认为<span class="math inline">\(\mathbf{h}\)</span>表示的是图像中有什么物体出现或者出现的内容，但并不指定物体的位置等等，所以其不包含位置信息。</p><p>如果想要进行<span class="math inline">\(\mathbf{h}\)</span>包含位置信息的建模，可以使用下面的模型：</p><p><span class="math display">\[\mathbf{h}=tanh(W_{k,f}\star\mathbf{x}+V_{k,f}\star\mathbf{s})\odot\sigma(W_{k,g}\star\mathbf{x}+V_{k,g}\star\mathbf{s})\]</span></p><p>其中<span class="math inline">\(\mathbf{s}=m(\mathbf{h})\)</span>，<span class="math inline">\(m\)</span>是一个deconvolution，<span class="math inline">\(s\)</span>是一个长宽和<span class="math inline">\(\mathbf{x}\)</span>相同的特征图，<span class="math inline">\(V\)</span>是<span class="math inline">\(1\times1\)</span>卷积。</p><h3 id="pixelcnn-ae">PixelCNN AE</h3><p>对传统的AE进行修改，将decoder部分改变为conditional PixelCNN，其接受的<span class="math inline">\(\mathbf{h}\)</span>是encoder的输出。</p><h2 id="results">Results</h2><h3 id="unconditional-modeling">Unconditional Modeling</h3><p>首先是在CIFAR-10上的结果：</p><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-37-12.png"><br></p><p>之后在Imagenet上的结果（20 layers、每个layers有384个hidden、kernel size是5x5、batch size是128）：</p><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-39-31.png"><br></p><h3 id="conditioning-on-imagenet">Conditioning on ImageNet</h3><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-54-08.png"><br></p><h3 id="conditional-on-portrait-embeddings">Conditional on Portrait Embeddings</h3><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-54-46.png"><br></p><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-54-59.png"><br></p><h3 id="pixelcnn-ae-1">PixelCNN AE</h3><p><img src="/2020/08/26/paper/dl/condi-pixelcnn2016/condi-pixelCNN2016_2020-08-26-14-55-35.png"><br></p><h2 id="conclusion">Conclusion</h2><blockquote><p>其实从上面的结果来看，即使在32x32的图片上，实际效果也着实一般。但总归是有提高的。</p></blockquote><p>未来的一个思路是使用PixelCNN替代VAE的Gaussian，从而提高VAE的性能。</p><blockquote><p>实际上，后来的VQ-VAE就是通过以上的方案实现的。</p></blockquote><hr><h2 id="questions">Questions</h2><ol type="1"><li>现在因为有3个染色通道，怎么序列的进行r、g、b的建模的？</li><li>很多细节需要在代码中才比较好理解...</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Autoregressive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-MADE-2015</title>
      <link href="/2020/07/28/paper/dl/made2015/"/>
      <url>/2020/07/28/paper/dl/made2015/</url>
      
        <content type="html"><![CDATA[<h1 id="made-masked-autoencoder-for-distribution-estimation">MADE: Masked Autoencoder for Distribution Estimation</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/mgermain/MADE" target="_blank" rel="noopener">source code</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>一个general的问题是如何从一组数据中得到其概率密度估计，一个好的概率密度估计器可以用于许多下游任务。“维数灾难”是该任务的主要困难之一。</p></li><li><p>最近，在深度学习领域，该问题得到了长足的进步，显示出了巨大的潜力。</p></li><li><p>本研究专注于autoregressive model，之前对此的研究一直没有解决computational cost的问题，本研究通过一种简单的方法来加快估计的速度——使用masking的方法，将一个autoencoder改造成一个autogregressive model，称为MADE。</p><p>早期的单层版本是【Bengio &amp; Bengio (2000)】，本研究中将试着将其加深，并在一个binary datasets with hundreds of dimensions上进行测试。</p></li></ol><h3 id="related-works">Related Works</h3><ul><li>NADE【Larochelle &amp; Murray, 2011】</li><li>NADE的深度扩展【Uria et al., 2014】，表现不错，但时间花费较多</li><li>DARN【Gregor et al., 2014】</li></ul><p>另外，可以将MADE看做是结构化的dropout【Srivastava et al., 2014，Wan et al., 2013】。</p><p>以下是几种方法的时间复杂度：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-27-21.png"><br></p><h2 id="methods">Methods</h2><p>本研究关注于每个变量是binary code的数据的概率密度估计。</p><h3 id="autoencoders">Autoencoders</h3><p>略</p><h3 id="autoregression">Autoregression</h3><p>我们首先将整个概率密度进行分解：</p><p><span class="math display">\[p(X)=\prod_{d=1}^Dp(x_d|X_{\lt d})\]</span></p><p>其中<span class="math inline">\(X_{\lt d}=(x_1, \dots, d_{d-1})^T\)</span>。则negative log-likelihood是：</p><p><span class="math display">\[\begin{aligned}    -\log p(X)&amp;=\sum_{d=1}^D -\log p(x_d|X_{\lt d}) \\        &amp;=\sum_{d=1}^D [-x_d\log p(x_d=1|X_{\lt d})]\cdot            [-(1-x_d)\log p(x_d=0|X_{\lt d})] \\        &amp;=l(X)\end{aligned}\]</span></p><p>我们可以看到，<strong>只需要我们让AEs的输出中的每个神经元，其只依赖于其前面的神经元，则AEs自然形成一个Autoregressive model。这称为autoregressive property。</strong></p><h3 id="masked-autoencoders">Masked Autoencoders</h3><p>实现的一个方式是给fc中的weight乘上一个masked matrix，使得我们不希望存在的依赖关系为0。</p><p>考虑一个只有bottle neck layer（维度是<span class="math inline">\(K\)</span>）的AE：</p><p><span class="math display">\[h(X) = g(B+X(W\odot M^W)) \\\hat{X} = \sigma(C+h(X)(V\odot M^V))\]</span> 其中<span class="math inline">\(M^W\)</span>和<span class="math inline">\(M^V\)</span>表示masked matrices，维度分别是<span class="math inline">\(D\times K\)</span>和<span class="math inline">\(K\times D\)</span>。</p><p>设<span class="math inline">\(m(k)\)</span>表示第<span class="math inline">\(k\)</span>个瓶颈层神经元连接的输入的个数（其取值是<span class="math inline">\(\{1,\cdots,D-1\}\)</span>），则两个masked matrices的设置为：</p><p><span class="math display">\[M^W_{k,d} = \mathbf{1}_{m(k)\ge d} =\begin{cases}    1 \quad if\ m(k)\ge d \\    0 \quad otherwise\end{cases}\]</span></p><blockquote><p>以下是一个<span class="math inline">\(4\times 5\)</span>的例子，我们假设瓶颈层的神经元分别连接1、2、3、4个神经元：</p><p><span class="math display">\[M^W =\begin{pmatrix}   1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\   1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\   1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\   1 &amp; 1 &amp; 1 &amp; 1 &amp; 0\end{pmatrix}\]</span> 这时候，注意，最后一个个输入神经元<span class="math inline">\(x_D\)</span>是不会连接的。这是合理的，因为分解后的分量中并不存在以最后一个分量<span class="math inline">\(x_D\)</span>为条件的条件概率。</p></blockquote><p><span class="math display">\[M^V_{d,k} = \mathbf{1}_{m(k)\lt d} =\begin{cases}    1 \quad if\ m(k)\lt d \\    0 \quad otherwise\end{cases}\]</span></p><p>继续上面的例子：</p><blockquote><p><span class="math display">\[M^V =\begin{pmatrix}   0 &amp; 0 &amp; 0 &amp; 0 \\   1 &amp; 0 &amp; 0 &amp; 0 \\   1 &amp; 1 &amp; 0 &amp; 0 \\   1 &amp; 1 &amp; 1 &amp; 0 \\   1 &amp; 1 &amp; 1 &amp; 1\end{pmatrix}\]</span> 这时候，第一个输出神经元<span class="math inline">\(\hat{x}_1\)</span>不会有连接。这也是合理的，因为分解后的分量中不会有<span class="math inline">\(p(x_1|...)\)</span>的分量，其是<span class="math inline">\(p(x_1)\)</span>是自己先验生成的。</p></blockquote><blockquote><p>进一步我们可以看到，有<span class="math inline">\(K\ge D-1\)</span>，不然将没有足够的链接构筑所有的条件分量。<span class="math inline">\(K\)</span>大一点则没有关系，只是会出现一些重叠作用的神经元而已。</p><p>以上的依赖关系从矩阵上看不太直观，自己在纸上画一些连接关系就一目了然了。</p></blockquote><blockquote><p>另外，我们没有必要像上面的例子一样来设置<span class="math inline">\(m(k)\)</span>（<span class="math inline">\(m(k)=k\)</span>，实际上本研究后续的实验中是随机的分配这个<span class="math inline">\(m(k)\)</span>的，只要保证其包含所有的<span class="math inline">\(\{1,\cdots,D-1\}\)</span>。</p></blockquote><p>我们将两个矩阵相乘，得到：</p><p><span class="math display">\[M^{V,W}_{d',d}=\sum_{k=1}^K{M^V_{d',k}M^W_{k,d}}=\sum_{k=1}^K{\mathbf{1}_{d\le m(k)}\mathbf{1}_{m(k)\lt d'}}\]</span></p><p>这个元素表示的是<span class="math inline">\(d'\)</span>是否对<span class="math inline">\(d\)</span>有依赖。如果<span class="math inline">\(d'\gt d\)</span>，我们发现是存在<span class="math inline">\(m(k)\)</span>满足上面的条件的，所以上面是1，不然则上面的值为0。如果<span class="math inline">\(d'\le d\)</span>，则满足上面条件的<span class="math inline">\(m(k)\)</span>不会存在，所以这样的依赖关系也不会存在。满足了autoregressive property。</p><blockquote><p>以上的公式也佐证了<span class="math inline">\(m(k)\)</span>必须遍历所有的<span class="math inline">\(\{1,\cdots,D-1\}\)</span>，不然，比如说<span class="math inline">\(\forall k,m(k)\ne 3\)</span>，则当<span class="math inline">\(d'=4,d=3\)</span>时，以上的值为<span class="math inline">\(0\)</span>，也就是说<span class="math inline">\(x_4\)</span>的生成将无法依赖于<span class="math inline">\(x_3\)</span>，这对于自回归模型当然是错的。</p></blockquote><p>在【Bengio &amp; Bengio, 2000】中进一步进行了改进：</p><p><span class="math display">\[\hat{X}=\sigma(C+h(X)(V\odot M^V)+X(A\odot M^A))\]</span></p><p>即加了一个skip connect，这将有助于训练。</p><h3 id="deep-made">Deep MADE</h3><p>类似上面的想法，我们为每个神经元都分配一个最大连接数，则可以类似的在更深的网络上构建自回归模型。</p><p>假设第<span class="math inline">\(l\)</span>层的weight matrix为<span class="math inline">\(W^l\)</span>，这一层的神经元个数为<span class="math inline">\(K^l\)</span>，则<span class="math inline">\(W^l\)</span>的维度是<span class="math inline">\(K^{l-1}\times K^l\)</span>，<span class="math inline">\(K^0\)</span>是输入维度。第<span class="math inline">\(l\)</span>层的第<span class="math inline">\(k\)</span>个神经元接受的连接数为<span class="math inline">\(m^l(k)\)</span>。我们进行下面的分配：</p><p><span class="math display">\[M^{W^l}_{k',k} = \mathbf{1}_{m^l(k')\ge m^{l-1}(k)}=\begin{cases}    1 \quad if\ m^l(k')\ge m^{l-1}(k) \\    0 \quad otherwise\end{cases}\]</span></p><p>在最后一层，则使用输入维度<span class="math inline">\(D\)</span>作为输出维度：</p><p><span class="math display">\[M^{V}_{d,k} = \mathbf{1}_{d\gt m^L(k)}=\begin{cases}    1 \quad if\ d\gt m^L(k) \\    0 \quad otherwise\end{cases}\]</span></p><p>将以上这些矩阵连乘，得到输入和输出的连接模式（<span class="math inline">\(L\)</span>个隐层，还有一个输出层）：</p><p><span class="math display">\[\begin{aligned}M^{V,W^L,\dots,W^1}_{d',d}&amp;=\sum_{k^1,k^2,\dots,k^L}{M^{W^1}_{d,k^1}M^{W^2}_{k^1,k^2}\cdots M^{W_L}_{k^{L-1},k^l}M^V_{k^L,d}} \\&amp;=\sum_{k^1,k^2,\dots,k^L}{\mathbf{1}_{d\le m^1(k^1)}\mathbf{1}_{m^1(k^1)\le m^2(k^2)}\cdots\mathbf{1}_{m^{L-1}(k^{L-1})\le m^L(k^L)}\mathbf{1}_{m^L(k^{L})\lt d'}} \tag{1}\end{aligned}\]</span></p><p>有上面的式子可以知道，为了避免漏掉可能的依赖关系，则<span class="math inline">\(m^l(k)\ge \min_{k'}{m^{l-1}(k')}\)</span>。只有这样，才能保证中间的所有不等式在<span class="math inline">\(d'\gt d\)</span>时有成立的可能，从而算出来值为1。</p><p>同样的我们可以知道，其中的<span class="math inline">\(m^l(k^l)\)</span>的取值必须使得<span class="math inline">\(d'\gt d\)</span>时有成立的可能。因为多层的缘故，我们现在有很多种mask的方式，比如下面的fig1是其中的一种。</p><blockquote><p>类似上一节中对单层网络的讨论，我们知道，只要使得masks满足上面的要求，所以我们希望出现的依赖关系（前面分量对后面分量的依赖，<span class="math inline">\(d\ge d'\)</span>），是不会出现的。</p></blockquote><blockquote><dl><dt>进一步，我们来说明，实际上<span class="math inline">\(m^l(k^l)\)</span>必须能够将<span class="math inline">\(\{1,\dots,D-1\}\)</span>的所有值都取遍，不然将遗漏必要的依赖性</dt><dd><p>autoregressive property 保证了第<span class="math inline">\(h\)</span>个变量对第<span class="math inline">\(h-1\)</span>个变量一定有依赖，所以当<span class="math inline">\(d=h-1\)</span>，<span class="math inline">\(d'=h\)</span>时，上式中必须存在一项是等于1的。也就是说，必须在每一层中存在一个神经元<span class="math inline">\(\{k^1,\dots,k^L\}\)</span>，使得其分配的连接数<span class="math inline">\(\{m^1(k^1),\dots,m^L(k^L)\}\)</span>使得上面的所有不等式成立。这时我们发现，这个连接数必须是 <span class="math display">\[m^1(k^1)=\cdots=m^L(k^L)=h-1\]</span> 显然，<span class="math inline">\(h\)</span>可以从<span class="math inline">\(2\)</span>一直取到<span class="math inline">\(D-1\)</span>，所以每一层都必须有神经元拥有这些连接数<span class="math inline">\(\{1,\dots,D-1\}\)</span>。</p></dd></dl><p>这也进一步证明了，每一个隐层的神经元个数必须<span class="math inline">\(\ge D-1\)</span>。</p></blockquote><blockquote><dl><dt>最后我们来证明，只要每一层都保证了取遍<span class="math inline">\(\{1,\dots,D-1\}\)</span>，则所有我们需要的依赖关系都是可以满足的</dt><dd><p>要让<span class="math inline">\(d\lt d'\)</span>之间存在依赖关系，需要存在<span class="math inline">\(\{m^1(k^1),\dots,m^L(k^L)\}\)</span>，使得其是一个递增的数列，并且正好在<span class="math inline">\([d,d')\)</span>之间。显然因为每一层都有<span class="math inline">\(\{1,\dots,D-1\}\)</span>，所以我们这只需要取这个数列是<span class="math inline">\(\{d,d,\dots,d\}\)</span>即可。</p></dd></dl></blockquote><blockquote><p>注意到，如果我们设置更多的隐层神经元，则单个依赖关系会有更多的重复路径，则会增强网络的表达能力。</p></blockquote><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-16-24-59.png"><br></p><h3 id="order-agnostic-training">Order-agnostic training</h3><p>【Uria et al. (2014)】已经证明，在<span class="math inline">\(X\)</span>向量的全排序上训练autoregressive model是有益的。</p><p>而且这也有实际的意义：</p><ul><li>如果我们当前拥有一个样本的一部分变量，想要将剩下的变量生成，我们可以将这些存在的变量排在前面，然后递归的生成下面的变量，这必须在乱序的model中进行。</li><li>我们可以快速的构建一个model的ensemble：即以不同的顺序去进行estimate，然后将得到的结果平均。</li></ul><p>实现的方法是非常简单的，即在每个minibatch上都使用一种新的ordering进行训练即可（对输入permutate即可）。</p><h3 id="connectivity-agnostic-training">Connectivity-agnostic training</h3><p>类似order-agnostic training，我们也可以在连接模式（masked）上“动手脚”。</p><p>即在每个minibatch training之前都重新将每个layer的masked matrices进行重新修改。</p><p>但这样训练时有个问题：即输入是0的神经元和被掩盖掉的神经元是无法区分的，这可能会造成训练的困难。【Uria et al. (2014)】提出一个解决方案是在训练的时候另外加上一个被同样掩模处理得到神经元，但这个神经元的输入都是1，这样进行区分，公式为：</p><p><span class="math display">\[\mathbf{h}^{l}(\mathbf{x})=\mathbf{g}\left(\mathbf{b}^{l}+\left(\mathbf{W}^{l} \odot \mathbf{M}^{\mathbf{W}^{l}}\right) \mathbf{h}^{l-1}(\mathbf{x})+\left(\mathbf{U}^{l} \odot \mathbf{M}^{\mathbf{W}^{l}}\right) \mathbf{1}\right)\]</span></p><p>另外，只使用有限种mask可以避免欠拟合。然后在test时对所有的mask都试一遍，然后将输出进行平均。</p><p>以下的算法详细介绍了整个算法：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-16-54-52.png"><br></p><h2 id="results">Results</h2><p>使用的数据集：</p><ul><li>a suite of UCI binary datasets</li><li>the binarized MNIST dataset</li></ul><p>评价指标是test上的负对数似然，minibatch size是100，使用earlystop（向前看30步）。</p><h3 id="uci-evaluation-suite">UCI evaluation suite</h3><p>由7个小型数据集组成，其详细信息如下：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-36-14.png"><br></p><p>model信息：</p><ul><li>hidden units 500</li><li>decay 0.95</li><li>valid和test时使用的masked的数量是300和1000</li><li>其他如下表所示</li></ul><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-42-31.png"><br></p><p>结果如下所示：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-44-35.png"><br></p><p>可以看到，MADE相对于其他模型是非常有竞争力的。</p><h3 id="minist数据集">MINIST数据集</h3><p>28x28的pixels，training=50000、valid=10000、test=10000。</p><p>model信息：</p><ul><li>hidden units的数量从500试到8000，发现越多越好，所以使用的是8000。</li><li>其他超参数设置如下</li></ul><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-48-20.png"><br></p><p>结果如下所示：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-49-00.png"><br></p><p>结果显示</p><ul><li><p>MADE是有竞争力的，并且在单层情况下要优于NADE（这是之前单层最好的方法）。</p></li><li><p>如果使用了太多的masks，将导致明显的欠拟合线性：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-17-51-37.png"><br></p></li></ul><p>从表现最好的model中生成了100个数字，进行了可视化：</p><p><img src="/2020/07/28/paper/dl/made2015/MADE2015_2020-07-28-18-18-03.png"><br></p><h2 id="conclusion">Conclusion</h2><p>MADE可以进行非常高效的概率密度估计，和标准的AEs类似，可以非常方便地利用GPU的算力。</p><hr><h2 id="questions">Questions</h2><ol type="1"><li><p>在上面，我们证明了，如果想要能够让每个条件分量都存在，我们需要让隐层的神经元数量至少为<span class="math inline">\(D-1\)</span>。但不管在paper中还是github的各种实现中，都没有这个隐层神经元数量的限制？难道是我错了？</p></li><li><p>在进行实验的时候，我发现order-agnostic的策略并不成功，这是为什么？？</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Autoregressive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-DeepBind预测DNA/RNA蛋白结合位点-2015</title>
      <link href="/2020/07/27/paper/omics/deepbind2015/"/>
      <url>/2020/07/27/paper/omics/deepbind2015/</url>
      
        <content type="html"><![CDATA[<h1 id="predicting-the-sequence-specificities-of-dna--and-rna-binding-proteins-by-deep-learning">Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</h1><ul><li>杂志: Nature Biotechnology</li><li>IF:</li><li>分区:</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li>DNA，比如控制转录或可变剪切，而其功能和其特异性的序列相关。</li><li>position weight matrices（PWMs）可以用来描述这种序列特异性，并且易于解释。</li><li>一些新的、更加复杂的技术能够更加准确的来描绘序列特异性，本研究提出了一种基于Deep Learning的技术，称为DeepBind，能够发现新的patterns。</li></ol><p>使用高通量数据来进行序列特异性的建模有下面几个问题：</p><ul><li>来自不同技术的数据有着不同的形式。</li><li>高通量数据一般比较多，有10000-100000条序列。</li><li>不同类别的数据有着不同的偏移和限制。</li></ul><p>而DeepBind依次解决了上述问题：</p><ul><li>其可以应用于微阵列数据或序列数据</li><li>使用GPU来加快训练</li><li>在这个数据间泛化良好，甚至没有进行校正</li><li>可以允许一定的噪声</li><li>可以自动化的进行训练，减少了手动调参的工作</li><li>最后，可以类似PWMs一样进行可视化，从而提供一定的可解释性</li></ul><p><img src="/2020/07/27/paper/omics/deepbind2015/DeepBind2015_2020-07-27-16-42-06.png"><br></p><h2 id="methods">Methods</h2><h3 id="数据">数据</h3><p>序列长度14-101nt不等，每条序列有一个binding score，可以是real-value或binary class labels。</p><h3 id="模型">模型</h3><p><img src="/2020/07/27/paper/omics/deepbind2015/DeepBind2015_2020-07-27-17-00-41.png"><br></p><ol type="1"><li><p>首先经过一层CNN，然后进行global max pooling，这样每个序列得到一个相同长度的表示向量。</p></li><li><p>将此向量送入MLP进行预测，然后和binding score计算loss，反向传播进行训练。loss为：</p><p><img src="/2020/07/27/paper/omics/deepbind2015/DeepBind2015_2020-07-27-17-12-00.png"><br></p></li></ol><p>为了能够进行自动化地训练，这里：</p><ol type="1"><li>对于每个需要训练的模型，随机采样30组参数；</li><li>3-CV训练并计算测试集误差，选择最好的那组参数。</li></ol><blockquote><p>完整的参数列表在supplementary notes中</p></blockquote><p>整个模型的训练使用了12 terabases的序列数据，<a href="http://tools.genes.toronto.edu/deepbind/" target="_blank" rel="noopener">源代码</a>，其中包括了927个DeepBind模型，对应538个确定的转录因子和194个RBPs。</p><h3 id="评价">评价</h3><p>DNA模型使用revised DREAM5 TF-DNA Motif Recognition Challenge的PBM数据进行验证。</p><h2 id="results">Results</h2><h2 id="discussion">Discussion</h2><h2 id="conclusion">Conclusion</h2><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-CMPNN-2020</title>
      <link href="/2020/07/26/paper/dl/cmpnn2020/"/>
      <url>/2020/07/26/paper/dl/cmpnn2020/</url>
      
        <content type="html"><![CDATA[<h1 id="communicative-representation-learning-on-attributed-molecular-graphs">Communicative Representation Learning on Attributed Molecular Graphs</h1><ul><li>杂志: IJCAI-20</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/SY575/CMPNN" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>准确预测分子性质是药物研究中一个重要的课题，这可以为下游药物开发节省大量的资源和时间【Cherkasov et al.2014】。</p></li><li><p>性质预测的主要思路：先将药物分子embed为一个dense feature vector，然后再对这个feature进行预测。</p></li><li><p>早期定量进行embed，主要通过特征工程的手段（QSPR），如：</p><ul><li>expert-crafted physicochemical descriptors 【Nettles et al.2007】</li><li>molecular fingerprints 【Rogers and Hahn2010】</li></ul><p>然而这些方法认为我们进行预测所需的信息都包括在这些特征中，这可能无法满足。</p></li><li><p>最近随着分子实验数据的增加，基于机器学习和深度学习的方法显示出明显的优势，其可以直接输入原始的、完整的分子表示（SMILES string或topological graph），从而学习到更加全面的信息。</p><ul><li>本质上，任何一个分子都可以描述为一个hydrogen-depleted topological graphs，其中节点是原子（atoms）、边是化学键（bonds）。</li><li>【Duvenaud et al.2015】最早尝试使用GCN学习fingerprint。</li><li>【Gilmer et al.2017】总结了众多可用的架构，称为message passing neural networks（MPNNs），其在化学性质预测上都有较好的表现，即：<ul><li>message passing module：将每个节点的信息进行转换，并传送到它的邻接点上</li><li>updating module：对于每个节点，基于其接受的信息，更新该节点的特征</li></ul></li></ul><p>但MPNNs类的方法没有考虑到edge上的信息。</p></li><li><p>为了解决上述edges的问题，【Yang et al.2019】提出了D-MPNN，其使用的是有向图</p><p>主要贡献是避免了不必要的信息循环，从而得到没有冗余的信息。</p><p>但其没有考虑到从bonds到atoms的消息传递，从而无法有效的捕获到更加全面的特征。</p></li><li><p>本研究提出了directed graph-based Communicative Message Passing Neural Networks（CMPNN）：</p><ul><li>其可以同时更新node和edge的特征；</li><li>为了避免冗余信息，精心设计了node interaction procedure；</li><li>提出了messager booster来丰富message生成；</li></ul></li></ol><h3 id="related-works">Related Works</h3><ol type="1"><li><p>Descriptor-based Representation</p><p>最常用的descriptor就是分子指纹（chemical fingerprint），比如ECFP【Rogers and Hahn2010】。</p><blockquote><p>我的理解，类似one-hot向量，每个变量表示是否存在某种结构。</p></blockquote><p>一些基于fingerprint的DL方法，如【Dahl et al.2014】，表现出比传统ML方法更好的结果。</p><p>但其带来了以下两个问题：</p><ul><li>数据过于稀疏，变量太多。</li><li>解释性不好。</li></ul></li><li><p>Linear Notation-based Representation</p><p>此类中最常见的是SMILES notation，其基于共同的chemical bonding rules将topological graph进行编码。</p><p>一般处理这一类数据的NN都较为复杂：【[Zheng et al.2019b] [Jastrzebski et al.2016] [Zheng et al.2020] [Zheng et al.2019a]】</p><p>但序列表示的可扩展性差、空间信息的丢失是无法解决的问题。</p></li><li><p>Graph Structure-based Representation</p><ul><li>【Duvenaud et al.2015】最早，将molecular映射为neural fingerprint，并逐渐有一批改进，这些共同构成了MPNN类的方法，但这类方法只考虑到了atoms information。</li><li>【Kearnes et al.2016】、【Gilmer et al.2017】和【Coley et al.2017】逐渐发展了将atoms和bonds都考虑其中的方法，这些方法因为是基于MPNN直接发展而来，所以在迭代过程中存在information redundancy。</li><li>DMPNN【Yang et al.2019】将graph看做是一个edge-oriented directed structure，从而避免了unnecessary loops，减轻了information redundancy。</li><li>本研究基于DMPNN，将node-edge interaction module融入，从而充分利用atoms和bonds的信息。</li></ul></li></ol><h2 id="methods">Methods</h2><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-11-51-53.png"><br></p><h3 id="communicative-message-passing">Communicative Message Passing</h3><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-12-02-32.png"><br></p><p>以上是MPNN、DMPNN、CMPNN在消息传递中的不同，可以看到：</p><ul><li>MPNN仅仅更新node特征；</li><li>DMPNN只更新edge特征；</li><li>CMPNN将node和edge特征都进行更新，并使用一个特殊的module进行操作。</li></ul><p>算法如下所示：</p><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-12-07-08.png"><br></p><p>可以看到：</p><ul><li><p>先更新node特征：node message <span class="math inline">\(\mathbf{m}^{k}(v)\)</span>来自指向它的edge features <span class="math inline">\(\mathbf{h}^{k-1}(e_{u,v})\)</span>的聚合（这是最主要的和MPNN的不同），然后使用communicate func聚合message和原始特征更新node特征。</p></li><li><p>edge特征：原始edge <span class="math inline">\(\mathbf{h}^0(e_{v,w})\)</span>和传递过来的edge message <span class="math inline">\(\mathbf{m}^k(e_{v,w})\)</span>的计算</p><ul><li>考虑原始edge特征<span class="math inline">\(\mathbf{h}^0(e_{v,w})\)</span>，相当于提供了一个skip connect【Yang et al.2019】</li><li>非线性函数<span class="math inline">\(\sigma\)</span>是relu。</li></ul><p>如果是DMPNN，这里的edge message是基于所有邻接边的特征<span class="math inline">\(\{\mathbf{h}^{k-1}(e_{u,v}),\forall u\in N(v)/w \}\)</span>计算的。其没有考虑到其反向边特征<span class="math inline">\(\mathbf{h}^{k-1}(e_{w,v})\)</span>。</p><blockquote><p>也就是只考虑和目标edge有相同终点的edges。</p></blockquote><p>在CMPNN中，因为node features中已经编码上述邻接边的特征，所以我们可以直接利用它，然后再减去目标edge的反向特征<span class="math inline">\(\mathbf{h}^{k-1}(e_{w,v})\)</span>来作为edge message。</p></li></ul><p>经过<span class="math inline">\(K\)</span>层的特征特征更新后，再利用edge feature得到node message，然后使用communicate func将node message、node feature和原始node feature进行整合，得到最终的node features。</p><p>最后，使用一个readout函数（这里是GRU【Cho et al. (2014)】），将所有node features变换为一个向量<span class="math inline">\(\mathbf{z}\)</span>。之后再接fc进行分类即可。</p><h3 id="message-booster">Message Booster</h3><p>这里介绍上面的aggregate func。</p><ul><li>【Hamilton et al.2017】提到了两种常用的aggregate func，即LSTM和max pooling。</li><li>【Xu et al.2018】则认为sum aggregattion要优于max/mean pooling。</li><li>【Yang et al.2019】也使用到了加和的方式来聚合邻接点特征形成message。</li></ul><p>但以上的方式都没有考虑到edges间的关系，所以本研究提出了message booster的方式来进行aggregate得到message，如下图所示：</p><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-16-17-08.png"><br></p><p>公式为：</p><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-16-24-50.png"><br></p><blockquote><p>这个公式可能写错了，实际上就是将所有node features，做了一次sum和max，然后乘起来即可。下面的公式可能更加正确： <span class="math display">\[[\sum_{u\in N(v)}{\mathbf{h}^{k-1}(e_{u,v})}]\odot [\max_{u\in N(v)}{\mathbf{h}^{k-1}(e_{u,v})}]\]</span></p></blockquote><blockquote><p>实际上就是sum和max的结合。mean pooling是不可取的，max可能是最好的，但会丢失一些信息，sum可以进行一定的弥补。</p></blockquote><h3 id="node-edge-message-communication">Node-Edge Message Communication</h3><p>这里介绍communicate func，在MPNN和DMPNN中称为updating step。</p><p>这里有3种备选方案：</p><ol type="1"><li><p>Inner product kernel：</p><p><span class="math display">\[\mathbf{h}^k(v)=\mathbf{m}^k(v)\odot\mathbf{h}^{k-1}(v)\]</span></p></li><li><p>Gated graph kernel【Li et al.2015】:</p><p><span class="math display">\[\mathbf{h}^k(v)=GRU(\mathbf{h}^{k-1}(v), \mathbf{m}^k(v))\]</span></p><p>GRU有更强的拟合能力，但其不是symmetric的，这和graph的性质略有不符。</p></li><li><p>Multilayer Perception：</p><p><span class="math display">\[\mathbf{h}^k(v)=\sigma(W \cdot Concat(\mathbf{h}^{k-1}(v), \mathbf{m}^k(v)))\]</span></p></li></ol><h2 id="results">Results</h2><h3 id="实验设置">实验设置</h3><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-16-56-04.png"><br></p><p>一共有6个benchmark datasets：</p><ul><li>BBBP，血脑屏障穿透数据集，记录的是化合物的穿透性。</li><li>Tox21，预测12个和药物毒性有关的靶点。</li><li>Sider，已上市药物的27个器官的毒性反应。</li><li>ClinTox，包括了FDA审批通过的药物和因为药物毒性没有通过的药物。</li><li>ESOL，化合物的水溶性。</li><li>FreeSolv，水化自由能。</li></ul><p>其中Tox21、Sider、ClinTox是多任务学习。</p><p>比较的方法有9种（+CMPNN）：</p><ul><li>binary Morgan fingerprints + RF</li><li>binary Morgan fingerprints + FNN（MLP）</li><li>GCN【Kipf and Welling2016】</li><li>Weave【Kearnes et al.2016】</li><li>N-Gram【Liu et al.2019】（unsupervised）</li><li>RGAT【Ryu et al.2018】</li><li>MPNN</li><li>DMPNN</li></ul><p>使用5-CV，分割策略有random和scaffold-based两种。评价指标是AUC和RMSE。使用的节点特征使用开源库RDKit计算得到。超参数使用Bayesian Optimization搜索得到。</p><blockquote><p>scaffold-based split是一种更加接近现实、更加有挑战性的数据集分割方式，可以通过python module RDKit实现。</p></blockquote><h3 id="实验结果">实验结果</h3><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-17-10-16.png"><br></p><p>可以看到，CMPNN取得了非常好的结果。</p><p>因为Tox21的不平衡性，这里使用scaffold-based split进行进一步的验证：</p><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-17-14-07.png"><br></p><h3 id="消融实验">消融实验</h3><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-17-15-23.png"><br></p><p>证明了message booster和communicate func的重要性，也和attention-based booster进行了比较。</p><h3 id="特征可视化">特征可视化</h3><p><img src="/2020/07/26/paper/dl/cmpnn2020/cmpnn2020_2020-07-26-17-17-30.png"><br></p><p>分子特性通常和其结构密切相关，为了证明CMPNN能够学习到更好的特征，这里对学习到的特征进行可视化。</p><ul><li>匹配PAINS database（包含有400个毒性子结构），从Tox21中选择出100个毒性分子，然后对应的选择出100个非毒性分子。</li><li>将每个分子（graph）中的atoms（node）对应的标记成toxic和non-toxic。</li><li>利用上述方法学习这些atoms的特征，然后使用t-SNE进行可视化。</li></ul><p>从上图可以看出，CMPNN有更好的效果。</p><h2 id="conclusion">Conclusion</h2><p>本研究通过增强bonds和atoms间的信息交互，从而提高了预测性能。</p><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Graph Neural Networks </tag>
            
            <tag> Molecular Graphs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-pointNet++-2017</title>
      <link href="/2020/07/12/paper/dl/pointnet-plus/"/>
      <url>/2020/07/12/paper/dl/pointnet-plus/</url>
      
        <content type="html"><![CDATA[<h1 id="pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</h1><ul><li><p>杂志: NIPS2017</p></li><li><p>IF: None</p></li><li><p>分区: None</p></li><li><p><a href="https://github.com/erikwijmans/Pointnet2_PyTorch" target="_blank" rel="noopener">github</a></p><blockquote><p>作者提供的源码是tensorflow的，包括它的实现，为了提高速度，使用了一些C++代码。这里提供的代码是纯正pytorch的，更加利于学习，但可以效率低一些。</p></blockquote></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>之前PointNet算是在DL领域对point sets的一个探索，其基本思想是先学习每个点的encoding，然后将所有点的信息进行融合得到global point cloud signature。</p><p>但这样的设计使得模型无法捕捉到点云的局部结构，而在CNN的实践中我们知道这是非常重要的，低级别的特征有较小的感受野，高级别的特征有较大的感受野。</p></li><li><p>所以本研究介绍一个分层的NN框架——PointNet++，</p><p>思想是：</p><ul><li>先将点集分割成可重叠的local regions，通过某些距离度量；</li><li>类似CNN，从这些local regions中提取特征；</li><li>将这些特征组合成新的点集，然后继续学习更高级别的特征。</li></ul><p>这样，PointNet++的实现面临两个问题：</p><ul><li><p>怎样进行分割？</p><p>在欧式空间中，使用最远点采样（FPS）选择centroids，然后使用centroids为中心的球形邻域作为一个local regions。</p></li><li><p>如何提取点集或local regions的特征？</p><p>使用PointNet。</p></li></ul></li><li><p>实验显示PointNet++能够有效地、稳健地学习点集的特征，结构也显著优于state-of-the-art。</p></li></ol><h2 id="methods">Methods</h2><p><span class="math inline">\((M, d)\)</span>是一个metric space，其中<span class="math inline">\(M\in \mathbb{R}^n\)</span>是n维欧式空间的一个子集，<span class="math inline">\(d\)</span>是其上的一个metric。使用<span class="math inline">\(\mathcal{X}\)</span>来表示将<span class="math inline">\(M\)</span>的位置信息、点特征组合在一起的特征点集，则我们的任务是学习一个<span class="math inline">\(f\)</span>能够得到<span class="math inline">\(\mathcal{X}\)</span>的富含语义的表示，用于分类或分割。</p><h3 id="pointnet-review">1. PointNet Review</h3><p>详见</p><h3 id="分层点集特征提取">2. 分层点集特征提取</h3><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-10-50-57.png"><br></p><p>如图所示，整个网络有多个set abstraction layer组成，其将输入的点集（<span class="math inline">\(N\)</span>个点，每个点的坐标数量<span class="math inline">\(d\)</span>、特征数量<span class="math inline">\(C\)</span>）进行一系列操作，生成一个有着更少的点、每个点特征更新了的新的点集（<span class="math inline">\(N'\)</span>个点，每个点坐标数量<span class="math inline">\(d\)</span>、特征数量<span class="math inline">\(C'\)</span>），其包含以下3个部分：</p><ul><li><p>Sampling layer</p><p>从输入点集中选择一部分点，作为centroids。</p><p>方法：使用FPS采集指定数量的centroids，FPS使用到了数据的坐标信息来进行采样，这使得其相比于完全随机采样有更好的覆盖率。</p></li><li><p>Grouping layer</p><p>以centroids为中心，选择其neighborhoods构成local region sets。</p><p>方法：使用ball query的方法，即找到在以centroid为中心、一定距离为半径的ball中的所有点作为local region sets，这样每个region sets中的点的数量可能不一样。</p><p>相对应的还有一种方案，即kNN，即寻找距离centroid最近的k个点。ball query的方法相对于它，产生的local region features在空间上更加有意义，这对于分割任务可能是有益的。</p></li><li><p>PointNet layer</p><p>使用一个mini-PointNet将local region sets编码成feature vectors。</p><p>方法：对于每个local region set，先以centoid为原点转换点集的点的坐标，然后使用PointNet进行学习，在一个PointNet layer中，所有的local region sets使用的PointNet是权值共享的。</p></li></ul><h3 id="非均匀的点云密度">3. 非均匀的点云密度</h3><p>现在有一个问题：很多时候点云并不是均匀分布在空间中的，这种非均匀的分布会导致我们的feature leanring不稳定，在稀疏点集上学习到的特征并不能推广到密集的点集，反之亦然。</p><p>为了解决这个问题，本研究提出了一个density adaptive PointNet layer来提到上面的PointNet，此时组合成的整个网络称为PointNet++。</p><p>其基本思想是，在每个set abstraction layer中，会进行多个尺度的grouping和PointNet特征提取，然后将这多个尺度的特征根据其points density进行组合，有以下2种方式：</p><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-11-36-20.png"><br></p><ul><li><p>Multi-scale Groupiing（MSG）</p><p>如上图a所示，最简单的，即进行多个尺度的grouping和PointNet，然后将特征concat在一起即可。</p><p>random input dropout：为每一个样本（点云）随机一个<span class="math inline">\(\theta\sim \mathcal{U}(0, p)\)</span>，然后<span class="math inline">\(\theta\)</span>为丢弃率将输入的点丢掉。这样，网络会接收到不同程度的输入稀疏性，从而面对非均匀点集也是稳健的。</p><blockquote><p>使用<span class="math inline">\(p=0.95\)</span>而不是<span class="math inline">\(1\)</span>是为了防止出现空集合的现象。<br>以上的操作是面对local region sets做的。</p></blockquote></li><li><p>Multi-resolution Grouping（MRG）</p><p>MSG运行起来效率非常低，因为其需要为每个local sets都执行，而local sets的数量在底层时通常非常大。</p><p>MRG的思想是将提取两个层次的特征，然后将其concat到一起。如果点的密度较大，则右边的特征提供了更加细粒度的描述；如果点的密度较小，则左边的特征提取的信息较比较少，主要由右边来负责。</p></li></ul><h3 id="点特征传播">4. 点特征传播</h3><p>前面的set abstraction layer将点集的信息进行了聚合，但如果我们要进行分割任务，则必须得到每个点的特征。</p><p>这里使用差值方法将前面的set abstraction layers逐层反转（见fig2），我们在进行set abstraction的时候就把input points的坐标记录，然后在此处使用插值法、利用较少的output points来把input points得到。</p><p>使用的插值法是inverse distance weighted average based on kNN：</p><p><span class="math display">\[f^{(j)}(x)=\frac{\sum_{i=1}^k{w_i(x)f_i(x)}}{\sum_{i=1}^k{w_i(x)}}\quad \text{where}\quad w_i(x)=\frac{1}{d(x, x_i)^p},j=1,\cdots,C\]</span></p><p>其中<span class="math inline">\(p=2, k=3\)</span>。在经过了插值后，再将每个点的特征过一次fc和relu，之后和对应的set abstraction layers的输入concat的一起，然后继续。</p><h2 id="results">Results</h2><p>使用的数据集有：</p><ul><li>MINST</li><li>ModelNet40</li><li>SHREC15：使用5-CV来进行研究</li><li>ScanNet：1201来train、312来test</li></ul><p>classification的evaluation使用acc，semantic scene labeling的evaluation使用average voxel classification acc。</p><h3 id="在欧式空间中的分类效果">1. 在欧式空间中的分类效果</h3><p>使用MNIST和ModelNet40来进行评价，训练时分别从中采样512和1024个点，所有点zero mean和unit ball normalization，使用的网络是3层set abstraction layer和3层fc。</p><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-12-34-10.png"><br></p><blockquote><p>PointNet(vanilla)没有使用transformation network，即其等价于单层的PointNet++。<br>(with normal)表示使用了face normals作为额外的point features，另外使用更多的点（N=5000）来提高性能。</p></blockquote><p>以上结果显示：</p><ul><li>相比于PointNet，proposed model的性能确实提高了；</li><li>在2D image上的性能甚至可以媲美CNN；而在3D ModelNet40中，其超越了state-of-the-art（MVCNN）。</li></ul><p>然后是测试了一下模型对于点的稀疏性的稳健性，结果在fig4中。</p><h3 id="点云分割">2. 点云分割</h3><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-13-01-16.png"><br></p><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-13-03-05.png"><br></p><p>这里是和【5】进行的比较，【5】中没有使用RGB信息，所以这里也没有使用RGB信息。</p><h3 id="在非欧空间中的分类效果">3. 在非欧空间中的分类效果</h3><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-13-05-02.png"><br></p><p>在这样的任务中，a和c的点集表现完全不同，但也需要被分为相同的类型。</p><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-13-06-31.png"><br></p><p>这里使用的metric是测地线距离，使用的特征也不是XYZ的特征（使用XYZ特征效果非常不好）。</p><h3 id="特征可视化">4. 特征可视化</h3><p>这里将第一层set abstraction layer得到的特征点集进行可视化，发现其确实学到了一些点、面、角等特征，用来描述ModelNet4中的对象（其中大多数是家具）。</p><p><img src="/2020/07/12/paper/dl/pointnet-plus/pointNet-plus_2020-07-12-13-12-06.png"><br></p><h2 id="conclusion">Conclusion</h2><p>在未来，如何进一步提高MSG和MRG的运算速度，是一个需要考虑的问题。</p><hr><h2 id="questions">Questions</h2><blockquote><p>文章中使用的网络架构在文章的附录中有介绍，这里加不去介绍这些细枝末节的东西了。这里需要注意一下，随着网络的加深，radius是逐渐增加的（因为点在变得稀疏嘛）。</p></blockquote><blockquote><p>其实它这个的实现和我之前读过的、更晚一些的一篇文章（）已经非常像了。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Point Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-pointNet-2017</title>
      <link href="/2020/06/20/paper/dl/pointnet/"/>
      <url>/2020/06/20/paper/dl/pointnet/</url>
      
        <content type="html"><![CDATA[<h1 id="pointnet-deep-learning-on-point-sets-for-3d-classification-and-segmentation">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</h1><ul><li>杂志: CVPR</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/luyiyun/PointNet-pytorch" target="_blank" rel="noopener">github(我的实现)</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>CNN需要输入regular data formats才能完成权重共享等性质，而point clouds等数据格式并不满足。通常的做法是将其转换成3D voxel grids或不同视角的images，这会使得数据量急剧增加而且带来一些没有必要的变异性。</p></li><li><p>本研究提出一种新的框架--PointNet，</p><ul><li>将point cloud data看做真正的点集，即保持了其中成员的排列不变性（invariant to permutations）、刚性运动不变性（invariant to rigid motions）等。</li><li>unified architecture，end-to-end，直接将point clouds作为输入（xyz坐标），输出为整个point cloud的label或每个point的label。</li><li>结构简单，关键在于使用了一个single symmetric function —— max pooling。首先将每个点映射为各自的features，然后再进行summaries或concat上其他的global features。</li><li>因为输入的时候，对于每个point是独立的，所以可以进行一定的数据预处理，比如进行空间的缩放变化来让数据更加规范，从而提高训练的效果。</li></ul></li><li><p>本研究还对该框架进行了理论上的分析。显示了该networks可以拟合points set上的任意连续函数，而且还提供了一定的可解释性（可视化、为什么PointNet可以对输入点的扰动鲁邦）。</p></li><li><p>在一系列的benchmark datasets上展示了PointNet有最好的效果。</p></li></ol><h3 id="相关工作">相关工作</h3><ul><li><p>点云特征：</p><p>当前大多数的point cloud features是根据任务手动提取的。一般来说需要满足一定的统计特性，而且并分为内在的特征【2,21,3】和外在的特征【18,17,13,10,5】、local和global features。一般来说，如何组合这些features来对特定任务实现最优，这是很难的。</p></li><li><p>在3D数据上的深度学习</p><ul><li>Volumetric CNNs：【25,15,16】。但其存在一些问题：数据稀疏性（FPNN【12】和Vote3D【23】），计算复杂性。</li><li>CNNs：【20,16】，并在shape classification和retrieval tasks上得到了非常好的效果。但这并不能推广到所有的3D data上，特别是point classification或shape completion。</li><li>Spectral CNNs：【4,14】。</li><li>Feature-based DNNs：【6,8】，先提特征再使用fc layers进行分类，这可能会受限于其提取特征的能力。</li></ul></li><li><p>在非排序集合上的深度学习</p><p>【22】使用了一个带有注意力机制的read-process-write network来解决这个问题，并证明了其有排序数字的能力。但这个工作是在NLP上的，所以其没有考虑到sets上的几何关系。</p></li></ul><h2 id="methods">Methods</h2><h3 id="问题">1. 问题</h3><p>数据集为3D点集：<span class="math inline">\(\{P_i|i=1,\ldots,n\}\)</span>，其中每个point是它的坐标<span class="math inline">\((x,y,z)\)</span>和其他的特征向量。本研究中只有其坐标。</p><ul><li>对于object classification task，其输入一个已经分割好的、有形状的点云，然后进行分类与预测。</li><li>对于semantic segmentation，则输入一块区域的点云，然后为每个点预测其分类。</li></ul><p>数据特征：</p><ul><li>unordered。所以这个点云如果有<span class="math inline">\(N\)</span>个点，则这<span class="math inline">\(N\)</span>个点的permutation都是一样的。</li><li>interaction among points。能够捕捉点间的local structures，计算local structures内的interactions。</li><li>invariance under transformations。比如旋转、平移points并不会影响结果。</li></ul><h3 id="pointnet结果">2. PointNet结果</h3><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-14-41-03.png" alt="Network Architecture"><br></p><p>以上的结构中有3个关键模块：</p><ul><li>max pooling layers，symmetric operation，用来得到global features</li><li>local and global features的combination structure</li><li>two join alignment network将输入和输出对齐</li></ul><h4 id="对称函数">2.1 对称函数</h4><p>为了保证model有invariant to input permutation，有以下3种策略：</p><ul><li><p>每次输入时都将输入排列成一个排法。</p><p>但实际上在高维空间中并不存在一个对点扰动稳定的排列。在高维空间中，只要有小小的扰动，则其排列就可能发生了较大的变化。</p></li><li><p>将输入的所有排列都输入训练一次。</p><p>如果使用RNN，其对于比较长的点集序列是很难学习到的，而且permutation得到的数据量太大了。后面也用实验证明了基于此策略的RNN效果是不如PointNet的。</p></li><li><p>使用一个symmetric function来提取信息，symmetric function在不同的排列下降输出相同的值。</p><p>这是本研究的策略。整个模型可以表示为下面的格式：</p><p><span class="math display">\[f(\{x_1,\ldots,x_n\})\approx g(h(x_1),\ldots,h(x_n))\]</span></p><p>在本文中，<span class="math inline">\(h(x)\)</span>就是一个mlp，<span class="math inline">\(g()\)</span>就是一个max pooling。结构简单，但效果很好。</p></li></ul><h4 id="局部和全局信息融合">2.2 局部和全局信息融合</h4><p>这在semantic segmentation任务上是需要的。解决方案也是简单的，就是将pooling后的特征重新和每个点的特征进行concat，然后重新为每个点提取特征。</p><h4 id="联合对齐网络">2.3 联合对齐网络</h4><p>point cloud在经过一些刚性变换后应该是不变的，若学习到的representation应该是保留这种不变性的。</p><p>解决策略是：point cloud在进入model前先进行一个变换，使得其先变成标准的形状。则对于不同的样本，可能需要不同的变换。</p><p>本研究的思想是简单的，直接设计一个mini-network，其输入point cloud，输出一个<span class="math inline">\(3\times 3\)</span>矩阵，这个矩阵代表的就是适用于这个样本的变换。这个mini-network（T-net）的结构和上面是一致的。</p><p>进一步，我们可以为feature space也应用这样的结构，来对其feature space。因为feature space拥有较高的维度，为了防止得到的变换矩阵会降低输出后的秩（损失信息），所以需要在loss上加入一定的regularization：</p><p><span class="math display">\[L_{reg}=||I-AA^T||^2_F\]</span></p><p>其中<span class="math inline">\(A\)</span>是变换矩阵。这个regularization使得变换矩阵尽量靠近一个正交矩阵，从而避免信息的丢失。</p><h3 id="理论分析">3. 理论分析</h3><ul><li><p>通用逼近性（universal approximation）</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-15-24-59.png"><br></p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-15-25-18.png"><br></p><blockquote><p>其中Hausdorff distance的定义<a href="https://en.wikipedia.org/wiki/Hausdorff_distance" target="_blank" rel="noopener">wiki</a>：</p><p><span class="math display">\[d_H(X,Y)=\max\{\sup\limits_{x\in X}{\inf\limits_{y\in Y}{d(x,y)}},\sup\limits_{y\in Y}{\inf\limits_{x\in X}{d(x,y)}}\}\]</span> 就是</p><ul><li>先为每个<span class="math inline">\(x\)</span>点找到<span class="math inline">\(Y\)</span>上的对应点，这个对应点就是在<span class="math inline">\(Y\)</span>上和<span class="math inline">\(x\)</span>距离最近的点。然后计算<span class="math inline">\(x\)</span>到对应点间的距离。</li><li>计算这个对应距离的最大值。</li><li>反过来再算一遍，然后取两个距离的最大值。</li></ul></blockquote><p>证明在附录中。</p></li><li><p>瓶颈层的维度和稳定性</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-17-48-31.png"><br></p><ul><li>a的意思是，只要<span class="math inline">\(\mathcal{C}_S\)</span>中的点保留了，那么去掉一些其他的点，并不会改变函数的输出；同样的，可以加一些额外的噪声点，但只要不超过<span class="math inline">\(\mathcal{N}_S\)</span>，则也不会改变函数的输出。</li><li>b的意思是，作为"关键点"存在的<span class="math inline">\(\mathcal{C}_S\)</span>，其中点的数量被max pooling后得到的特征的维度控制。</li></ul><p>称<span class="math inline">\(\mathcal{C}_S\)</span>为<span class="math inline">\(S\)</span>的<strong>critical point</strong>，称<span class="math inline">\(K\)</span>是<span class="math inline">\(f\)</span>的<strong>bottleneck dimension</strong>。</p><blockquote><p>其实这个结果细想一下也是合理的。因为使用的max pooling，所以一些点的信息是被舍弃的，那么只要保证增加或减少的扰动只会影响到这些舍弃的点，则函数的值就不会变。</p></blockquote></li></ul><p>上面的两个理论分析告诉我们，PointNets通过发现point cloud中的一组稀疏的关键点来工作，这保证了结果的robustness。后面会发现，这组关键点构成了对象的骨架。</p><h2 id="results">Results</h2><h3 id="应用">1. 应用</h3><ul><li><p>3D对象分类</p><ul><li>数据集：ModelNet40【25】，40类，12311个CAD models（9843 for train，2468 for testing）</li><li>训练时从每个model随机抽取1024个点进行训练，并进行了单位圆标准化。</li><li>使用的数据增强：然后绕up-axis进行旋转。每个点的坐标增加了<span class="math inline">\(\mathcal{N}(0, 0.02^2)\)</span>的噪声。</li><li>baseline使用提取的传统特征+MLP。</li></ul><p>结果：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-28-07.png"><br></p><p>MVCNN的效果略好的原因可能是：图像进行渲染的时候会增加一些细节，这些在点云中没有被保留。</p></li><li><p>3D对象部分分割</p><ul><li>数据集：ShapeNet part data set【26】，16881 shapes被分为16类，一共被标记了50个parts。</li><li>评价指标：mIoU。</li><li>比较方法：【24】和【26】。</li></ul><p>结果：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-33-51.png"><br></p><p>另外，使用Blensor Kinect Simulator【7】来从6个视角生成不正确的点集，然后进行训练，发现PointNets只损失了5.3%的mIoU。</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-36-12.png"><br></p></li><li><p>场景语义分割</p><ul><li>数据集：Stanford 3D semantic parsing data【1】，一共271个rooms。从这些rooms的1x1m的区域内随机取点得到一个point cloud（4096个点for train，all for test）。每个点是一个9-d的向量，即xyz、rgb和normalized location as to room。</li><li>评价，使用【1】的k-fold策略进行评价。</li><li>baseline：使用的特征除了上面说到的9个，还有local point density、local curvature（曲率）and normal，然后使用MLP进行分类。</li></ul><p>结果如下表和图所示：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-43-57.png"><br></p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-44-20.png"><br></p><p>基于上述的语义分割网络，本研究建议了一个3d对象检测系统，并和之前的state-ot-the-art方法进行了比较，结果如下表所示：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-20-18-47-13.png"><br></p></li></ul><h3 id="架构设计">2. 架构设计</h3><p>这里对PointNets中设计的一些架构的作用进行验证。</p><ul><li><p>order-invariant方法</p><p>使用的数据集是ModelNet40，除了上面提到的方法，还测试不同的symmetric function的效果，其中attention的做法类似【22】，结果如下：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-21-00-51-46.png"><br></p></li><li><p>输入输出转换</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-21-01-13-07.png"><br></p><p>没有T-Net的时候就已经有不错的效果了，将T-Net、regularization都加上后能够得到最好的效果。</p></li><li><p>鲁棒性测试</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-21-01-13-34.png"><br></p><p>当丢失50%的points时，acc仅仅降低了2.4%（furthest sampling）和3.8%（random sampling）。</p><p>当outliers占据20%的点的时候，acc也能够到达80%以上。</p></li></ul><h3 id="可视化">3. 可视化</h3><p>这里将<span class="math inline">\(\mathcal{C}_S\)</span>和<span class="math inline">\(\mathcal{N}_S\)</span>可视化了一下：</p><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-21-01-13-57.png"><br></p><blockquote><p>两者可以理解为，PointNet可以理解物体所需要的最少和最多的点的集合。</p></blockquote><h3 id="时间和空间复杂度">4. 时间和空间复杂度</h3><p><img src="/2020/06/20/paper/dl/pointnet/pointNet_2020-06-21-01-14-54.png"><br></p><p>上表总结了其空间和时间花费。在tensorflow上（1080X GPU），PointNet可以每秒处理超过100万个点。</p><h2 id="conclusion">Conclusion</h2><hr><h2 id="questions">Questions</h2>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Point Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CCG以及癌症基因组学简介</title>
      <link href="/2020/06/17/tools/tcga/ccg-introduction/"/>
      <url>/2020/06/17/tools/tcga/ccg-introduction/</url>
      
        <content type="html"><![CDATA[<p>NCI，全称为The National Cancer Institute，是美国联邦政府进行癌症研究、培训的政府部门，主要任务是领导、组织、支持国家范围的癌症研究，增进科学知识，任何人们获得更久、更健康。关于NCI的更多内容可以去参考其<a href="https://www.cancer.gov/about-nci/overview" target="_blank" rel="noopener">官网的介绍</a>。</p><blockquote><p>NCI的团队属于NIH（美国国立卫生院，the National Institute of Health）的一部分，而NIH是HHS（卫生与公共服务部，the Department of Health and Human Services）的一个11个下属部门之一。<br>HHS可以看做是美国的卫生部（当然职权更大），FDA就是其下属部门之一。</p></blockquote><p>CCG（Center for Cancer Genomics，癌症基因组学中心）是NCI的一个机构，致力于综合不同领域的癌症基因组学研究（structural、functional、computational）来提高病人的治疗效果。CCG的项目和合作者提供了一系列癌症基因组学数据和临床数据，供全世界的癌症研究者进行研究（包括耳熟能详的TCGA）。</p><p>以下内容是对<a href="https://www.cancer.gov/about-nci/organization/ccg" target="_blank" rel="noopener">CCG官方介绍</a>的整理，主要内容是癌症基因组学的介绍和CCG如何组织进行癌症基因组学研究。希望能够加深对癌症基因组学的理解，并且可以利用到CCG组织的一系列公共资源。</p><h1 id="癌症基因组学综述">1. 癌症基因组学综述</h1><p>cancer是一类疾病，主要原因来自于<strong>DNA的改变导致的细胞行为发生变化，一般是不可控的生长和增值（malignancy）</strong>。</p><blockquote><p>malignancy，是一种疾病状态，一些异常细胞不受控制的分裂并侵入到临近的组织中。malignant cells还可以通过血液或淋巴系统扩散到身体的其他部分，更常用的叫法就是癌症（cancer）。有以下几种主要的类型：</p><ul><li>carcinoma（癌）：始于皮肤或覆盖器官的组织（上皮性）。</li><li>Sarcoma（肉瘤）：始于骨骼、软骨、脂肪、肌肉、血管或其他结缔组织或支持组织。</li><li>leukemia（白血病）：来自于造血系统，导致不正常的血细胞的产生。</li><li>lymphoma and multiple myeloma（淋巴瘤和多发性骨髓瘤）：源自免疫系统。</li><li>central nervous system cancers（中央神经系统癌症）：源自大脑和脊髓。</li></ul></blockquote><p><img src="/2020/06/17/tools/tcga/ccg-introduction/ccg-introduction_2020-06-17-20-29-26.png" alt="关于转移"><br></p><p>DNA的改变有多种类型：</p><ul><li><p>mutations</p><blockquote><p>DNA序列的任意形式的改变都被称为mutation或variant。其一般发生在细胞分裂或暴露DNA-damaging agents时，可能是有害、有益或无影响的。当mutation发生在生殖细胞中，则该突变可以遗传；当发生在其他细胞中则不可遗传。特定的突变可能会导致癌症或其他的疾病。</p></blockquote></li><li><p>rearrangements</p></li><li><p>deletions</p></li><li><p>amplifications</p></li><li><p>addition or removal of chemical marks</p></li></ul><p><img src="/2020/06/17/tools/tcga/ccg-introduction/ccg-introduction_2020-06-17-20-30-29.png" alt="DNA图示"><br></p><p>这些改变一般会导致产生异常数量的蛋白质或错误的蛋白质。通常来说，多种DNA改变一起导致了cancer的发生。<strong>人在一生中累计的基因变化成为获得性或体细胞改变（acquired or somatic changes），约占癌症所有病例的90%-95%</strong>。</p><p><strong>genomics</strong>，指的是对人类的整个DNA set的研究。</p><ul><li><p>通过对比癌症细胞和正常组织细胞的DNA或RNA序列，来研究那些genetic differences可能引起cancer。</p><blockquote><p>tissue的定义：一系列的细胞的组合，用来完成一个特定的功能。</p></blockquote></li><li><p>通过统计DNA编码的genes在正常细胞和癌症细胞间活跃性的差异，来理解到底那些蛋白质的异常或失活导致了癌症的发生。</p></li></ul><p>一旦癌症的发生机制被确定，科学家们就可以针对性的开发新的治疗、干预策略来治疗疾病，延长病人的寿命。其中最重要的一种手段是precision medicine。</p><blockquote><p>precision medicine，利用癌症细胞的genetic changes来决定患者的治疗方案。</p></blockquote><p>药物被设计以下面的这些方式来发挥作用：</p><ul><li>抑制引发癌细胞异常生长的酶的活性</li><li>阻断基因表达特性</li><li>阻断癌细胞中超速运转的分子信号通路</li></ul><blockquote><p>gene expression的定义：是gene在cell中被转换成RNA或protein的过程，可以通过测量RNA、protein或protein的功能来进行定量。</p></blockquote><p>以上这些靶向治疗只作用于癌细胞和正常细胞的不同特性，所以其相对于传统疗法（放疗和化疗）拥有更低的毒性。以下是已经在临床应用的例子：</p><ul><li>Imatinib（伊马替尼，Gleevec，格列卫，就是《我不是药神》里的药），是一种用于治疗白血病的药物，对其他癌症比如皮肤癌也有一定效果。其通过抑制白血病病人体内的Bcr-Abl络氨酸激酶的过度表达来达到治疗目的，而这通常源于一段特定染色体的rearrangement。</li><li>Trastuzumab（曲妥珠单抗，Herceptin，赫赛汀）控制一种过度活跃的信号通路（HER2酪氨酸激酶），由一种乳腺癌亚型中HER2基因的多个拷贝引起的。</li><li>Erlotinib（埃洛替尼，Tarceva，特罗凯）和gefitinib（吉非替尼，Iressa，易瑞沙）都限制了一种蛋白（表皮生长因子，EGFR）的激活，这种蛋白在肺癌亚群中由于蛋白突变而异常活跃。</li></ul><p>另外，genomics research还通过定义更加精确的癌症亚型来为precision medicine做出贡献。更加精细的molecular substyle代表癌症的更加精确分类，有助于更加个体化的治疗。当前已经在临床发挥效果的癌症亚型分类有：</p><ul><li>乳腺癌根据分子特征被分为不同的亚组（Luminal A, Luminal B, Triple-negative/basal-like, HER2），它们的侵袭性和对治疗的反应不同。</li><li>弥漫性大B细胞淋巴瘤可细分为ABC和GCB亚型，不同的患者对化疗方案和分子靶向治疗有着不同的反应。</li><li>2013年，TCGA计划确定了子宫内膜癌的四种亚型（POLE ultramutated, microsatellite instability (MSI) hypermutated, copy-number (CN) low, CN high），不同亚型的患者生存率不同。这项研究已经引发了新的临床试验，研究这些亚型如何改善子宫内膜癌的临床治疗。</li><li>含有ROS1基因融合的肺癌患者通常对一种名为克里佐替尼（crizotinib）的靶向治疗反应良好。</li></ul><blockquote><p>microsatellite instability (MSI)，微卫星不稳定，一种发生在某些细胞（如癌细胞）中的变化，microsatellite（一段短而重复的DNA序列）中的重复DNA碱基的数量与遗传时的不同，这可能意味着DNA在复制的时候出现了错误。这在结直肠癌、胃癌和子宫内膜癌中最为常见，其他癌症也有。了解MSI可能有助于我们指定最佳的治疗方案。</p></blockquote><h1 id="ccg的研究">2. CCG的研究</h1><h2 id="结构基因组学研究">2.1 结构基因组学研究</h2><p>结构基因组学（structural genomics）旨在了解<strong>癌症细胞相对于正常细胞，DNA、RNA发生了怎样的变化</strong>，这里的“结构”指的就是DNA和RNA。其典型的项目就是TCGA。</p><ul><li><p>关键问题</p><ol type="1"><li>哪些genes负责肿瘤的生长、转移和药物抵抗？</li><li>哪些分子特征导致了某些癌症类型要比其他类型更有侵袭性？</li><li>未来癌症的分子诊断应该是什么样子的？</li></ol></li><li><p>工具和方法</p><ol type="1"><li>Next-generation DNA exome sequencing</li><li>Next-generation DNA whole genome sequencing</li><li>Total RNA sequencing</li><li>Reverse phase protein array（RPPA）protein analysis</li><li>Epigenomic analysis</li></ol></li><li><p>项目和合作</p><ol type="1"><li><p>ALCHEMIST（辅助肺癌富集标记物鉴定及测序试验）</p><p>这是一项precision medicine clinical trial，关于lung cancer，接受的病人满足下面的两种genomic特征：</p><ul><li><p>EGFR改变</p><blockquote><p>epidermal growth factor receptor（表皮生长因子受体），是在一些细胞中存在的蛋白质，其和一种称为表皮生长因子（epidermal growth factor）的物质结合，参与控制细胞分裂和生存的信号通路。<br>其对应gene的突变会导致某些细胞产生更多的EGFR，这可能是导致癌细胞分裂更加迅速的一个原因。<br>阻断表达EGFR的药物被用来治疗某些癌症。<br>EGFR是一种受体酪氨酸激酶，也叫做ErbB1、HER1。</p></blockquote></li><li><p>ALK改变</p><blockquote><p>间变性淋巴瘤激酶（anaplastic lymphoma kinase），在间变性大细胞淋巴瘤、神经母细胞瘤和非小细胞肺癌中常常发生变化。<br>ALK的改变可能会导致癌症细胞生长和扩算。<br>ALK是一种受体酪氨酸激酶。</p></blockquote></li></ul><p>分别接受erlotinib和crizotinib治疗。</p><p>这是CCG和NCI的Division of Cancer Treatment and Diagnosis（NCI下属的另一个组织）合作的项目。</p></li><li><p>CDDP（Cancer Driver Discovery Program）</p><p>CDDP旨在识别患者的驱动突变（占总突变的2%）。通过对大量病例进行测序，CDDP将具有足够的统计效能发现基因中可能驱动致癌过程的复发突变。涉及到的癌症类型有：肺癌、结肠癌和卵巢癌。</p></li><li><p>CGCI（Cancer Genome Characterization Initiative）</p></li><li><p>Cancer of Unknown Primary (CUP) Consortium</p></li><li><p>Clinical Trial Sequencing Project (CTSP)</p></li><li><p>Early Onset Malignancies Initiative (EOMI)</p></li><li><p>Exceptional Responders (ER) Initiative</p><p>收集了100例有对药物治疗有特殊应答（疗效特别好）的患者的基因图谱。</p></li><li><p>Refractory Cancers</p></li><li><p>Therapeutically Applicable Research to Generate Effective Treatments (TARGET)</p></li><li><p>The Cancer Genome Atlas (TCGA)</p><p>TCGA是NCI和NHGRI（美国国家人类基因组研究所）的合作项目，已经生成了33种癌症关键基因组变化的全面、多视角图谱。TCGA数据集包含超过2pb的基因组数据，可以公开获取，并帮助癌症研究社区改善癌症的预防、诊断和治疗。</p><p>2018年4月，TCGA research networks发表了<a href="http://www.cell.com/consortium/pancanceratlas" target="_blank" rel="noopener">Pan-Cancer Atlas</a>，一个cross-cancer analyses研究，标志着TCGA项目的结束。</p><p>关于TCGA更多的内容请参见<a href="https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga" target="_blank" rel="noopener">链接</a>和</p></li></ol></li></ul><h2 id="功能基因组学">2.2 功能基因组学</h2><p>Functional genomics research研究检查genome在癌症中的作用。通过测试从结构基因组学研究中得出的假设，或者从对癌细胞的实验中产生新的想法，功能基因组学研究揭示了癌症生物学的模式。这些模式有时可以直接转化为精确的治疗方案，比如CTD2网络的研究。</p><blockquote><p>简单来说，结构基因组学类似探索性研究，而功能基因组学类似机制研究。</p></blockquote><ul><li><p>关键问题</p><ol type="1"><li>癌症中改变的gene是如何导致癌细胞的的快速增殖和生存的？</li><li>药物和新的化合物是否可以有效影响癌症异常的分子通路？</li><li>病人活检产生的肿瘤模型能否用于了解治疗效果或耐药性的机制？</li></ol></li><li><p>工具和方法</p><p>CCG的功能基因组学研究使用癌症模型进行高通量药物筛选，使用RNA干扰和CRISPR-Cas9技术进行基因干扰实验，以及许多其他全基因组技术。目前，CCG的研究人员使用癌细胞系、生长在培养皿中的肿瘤类器官培养物，或携带人类肿瘤移植物的小鼠来确定特定基因改变的影响。认识到产生癌症模型的新方法的力量，CCG正在支持发展尖端的有机体和条件重编程细胞模型，以促进安全和有效的转换功能癌症基因组学发现到临床护理。</p></li><li><p>项目和合作</p><ol type="1"><li>Cancer Target Discovery and Development (CTD2) Network</li><li>Human Cancer Models Initiative (HCMI)</li></ol></li></ul><h2 id="计算基因组学">2.3 计算基因组学</h2><ul><li><p>关键问题</p><ol type="1"><li>分析从大量患者中收集的癌症基因组数据集，能增强我们发现新的癌症驱动突变的能力吗?</li><li>展示癌症基因组数据的最佳方式是什么？为了让癌症研究人员能够探索和可视化大型复杂的数据集?</li><li>研究者如何有效地将来自多种模式的基因组数据整合成一个关于致癌通路的统一的观点?</li><li>哪些新技术提供了关于癌症机制的新观点？如单细胞DNA和RNA测序?</li></ol></li><li><p>工具和方法</p><p>computational genomics将算法和统计模型应用到big datasets。CCG使用Genome Characterization Pipeline来生成genomic、clinical数据集，然后通过GDC（Genomic Data Commons）分享数据，并且和NCI Cloud Resources积极合作。</p></li><li><p>项目和合作</p><ol type="1"><li><p>Genomic Data Commons</p><p>是CCG建立的统一的数据整合平台，其将各个研究团队提交的robust genomic data整合在一起，便于复用，并提供了一系列的可视化和分析工具。</p><p>详情可见<a href="https://gdc.cancer.gov/about-gdc" target="_blank" rel="noopener">官网介绍</a>和</p></li><li><p>NCI Cloud Resources</p></li></ol></li></ul><h2 id="基因组描述管道">2.4 基因组描述管道</h2><p>CCG协调美国和加拿大的研究团队，为癌症研究社区提供丰富的癌症基因组和临床数据集。其通过一个称为Genome Characterization Pipeline的高效和标准化的工作流程来实现这种协作。</p><p><img src="/2020/06/17/tools/tcga/ccg-introduction/ccg-introduction_2020-06-18-00-06-58.png" alt="流程图"><br></p><ol type="1"><li><p>组织收集和预处理</p><ul><li>Tissue Source Sites从每个病人收集癌症组织和正常组织（大多是血液），大多数组织使用FFPE（福尔马林石蜡包埋），还有一些使用快速冷冻技术。</li></ul><p>CCG的Biospecimen Core Resource（BCR）有两个单位组成：</p><ul><li>Biospecimen Processing Center at Nationwide Children’s Hospital负责对所有的组织进行处理，分离出DNA、RNA、蛋白质和其他分析物，然后送入CCG的Genome Characterization Centers（GCC）。</li><li>Clinical Data Center at Information Management Services掌管知情同意，并进行审查，保证患者的隐私安全。</li></ul></li><li><p>基因组特征</p><ul><li><p>GCC接受BCR的DNA、RNA和proteins分析物，并产生数据。不同类型的物质将在不同的单位进行测序：</p><ul><li>The Broad Institute负责DNA，执行全基因组测序和全外显子组测序。</li><li>The University of North Carolina负责RNA，执行全RNA组测序。</li><li>MD Anderson Cancer Center负责proteins，得到RPPA。</li></ul></li><li><p>GCC将得到的raw sequence data、相关的metadat、其他characterization data一起发送给GDC，以便于Genomic Data Analysis Network（GDAN）和癌症研究社区使用。</p></li></ul></li><li><p>基因组数据分析</p><ul><li><p>GDAN是一个CCG牵头成立由大量的研究团队（来自美国和加拿大）组成的研究范式。这些组织会收到GDC的数据并按照设计好的研究流程对GDC上的数据进行分析并发布结论。每个团队会负责其擅长的部分，比如数据预处理、癌症驱动、可视化等子课题。</p><blockquote><p>UCSC的Jingchun Zhu领导的团队就是其中一员，负责GDC数据的可视化展示。</p></blockquote></li><li><p>全球其他癌症研究团队可以从GDC中获取GDAN的分析数据来开展新颖的研究，以促进癌症基因组学的发展。</p></li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
          <category> CCG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Omics </tag>
            
            <tag> Websites </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-深度连续卷积神经网络-2018</title>
      <link href="/2020/06/16/paper/dl/paper-conticnn/"/>
      <url>/2020/06/16/paper/dl/paper-conticnn/</url>
      
        <content type="html"><![CDATA[<h1 id="deep-parametric-continuous-convolutional-neural-networks">Deep Parametric Continuous Convolutional Neural Networks</h1><ul><li>杂志: CVPR</li><li>IF: None</li><li>分区: None</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>discrete CNN作为基础的深度学习模块，在效率和表现上都无话可说，但其只适用于dense grid structure。但对于其他结构的的数据，比如3D点云数据、mesh registration、non-rigid shape数据，discrete CNN无法处理。</p></li><li><p>对于这些数据的解决方法有：</p><ul><li>Voxelize the space to form a grid，然后使用discrete CNN【29,24】，但这样会导致tensor中大多数元素都是0，从而浪费内存。</li><li>Geometric deep learning【3,15】和GNN【25,16】使用处理graph的方式来处理这些这些数据，但这样的处理方法有两个缺陷：<ul><li>难以推广；</li><li>需要极好的feature representations才能表现不错；</li></ul></li></ul></li><li><p>本文提出一种新的思路，称为parametric continuous convolution。思想是使用一个参数化的核函数，来spans整个连续向量空间。</p><ul><li>这种新的神经网络架构可以很自然地适用于在空间内分布不均的3D点云数据。</li><li>在semantic labeling和motion estimation任务上验证了continuous CNN的有效性，使用end-to-end的网络架构。</li><li>证明了本方法在very large scale dataset上的有效性（223 billion points）。</li></ul></li></ol><h3 id="相关研究">相关研究</h3><ul><li><p>Deep Learning for 3D Geometry：</p><ol type="1"><li><p>最好的方法是将3D数据变成2-d RGB的image，然后使用传统的CNN进行学习【17,10】，但这不能捕捉到真实的几何关系，相邻的像素点可能相距很远的。</p><blockquote><p>我猜测，是将3D的一个维度转换成image的channel</p></blockquote></li><li><p>另一种方式是使用3d CNN，但需要将数据变成volumetric representations【29,21,24,9,18】：</p><ul><li>其中将数据填补成3d grid结构的过程，称为voxelization。</li><li>这在medical imaging、indoor scene understanding中应用好比较多，因为volume比较小。</li></ul><p>但此方法的问题在于：</p><ul><li>典型的voxelization牺牲了精确度。</li><li>3d volumetric representations是非常耗内存的。</li></ul><p>进一步的改进是使用sparse CNN【9】或新的数据结果（oct-trees【24】）</p></li><li><p>最新的想法是PointNet【20】和PointNet++【22】，其直接使用MLP来学习单个点，然后使用pooling来总结global information。</p></li></ol></li><li><p>Graph Neural Networks：</p><p>GNN的早期应用主要在于进行node representation的学习，【23】使用GGNNs进行point cloud segmentation，得到了state-of-the-art。</p><p>但GNN模型的问题在于，其图中节点信息的传播是同步的，这样对于millions节点的图，就因为图太大无法实现。</p></li><li><p>Graph Convolution Networks：</p><ol type="1"><li>对于spectral methods【4,2,30】，GCN方法，问题是无法扩展到large scale的data。</li><li>spatial approachs【6,15,7,19,2,27,30,26】则要灵活一些，<strong>本文的方法可以看做是spatial GCN的推广。</strong></li></ol></li><li><p>Other Approaches：</p><ol type="1"><li>Edge-conditioned filter networks【27】使用参数化的network来联系graph中的邻接点，相对于它，本文的方法不需要限制在fixed graph structure上。</li><li>【26】使用了本文方法类似的结构，但其使用的是shallow isotropic gaussian kernels，但本文使用的是更加expressive deep networks。</li></ol></li></ul><h2 id="methods">Methods</h2><h3 id="parametric-continuous-convolutions">1. Parametric Continuous Convolutions</h3><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-00-35-24.png" alt="discrete and continuous CNNs"><br></p><p>传统的discrete CNN有如下的运算：</p><p><span class="math display">\[h[n]=(f * g)[n]=\sum_{m=-M}^{M} f[n-m] g[m]\]</span></p><p>其中<span class="math inline">\(f: \mathcal{G} \rightarrow \mathbb{R}\)</span>、<span class="math inline">\(g: \mathcal{S} \rightarrow \mathbb{R}\)</span>，其中<span class="math inline">\(\mathcal{G}=\mathcal{Z}^{D}\)</span>、<span class="math inline">\(\mathcal{S}=\{-M,-M+1, \ldots, M-1, M\}^{D}\)</span>。</p><blockquote><p>这个公式确实是discrete CNN，其中g是kernel，f[n-m]就是以n为中心，两边半径为m的邻域。</p></blockquote><p>continuous CNN的形式应该是：</p><p><span class="math display">\[h(\mathbf{x})=(f * g)(\mathbf{x})=\int_{-\infty}^{\infty} f(\mathbf{y}) g(\mathbf{x}-\mathbf{y}) d \mathbf{y}\]</span></p><p>其中<span class="math inline">\(\mathcal{G}=\mathbb{R}^{D}\)</span> and <span class="math inline">\(\mathcal{S}=\mathbb{R}^{D}\)</span>。</p><p>这个形式有两个问题需要解决：</p><ul><li>显然积分是无法计算的。</li><li>卷积核<span class="math inline">\(g\)</span>是什么</li></ul><ol type="1"><li><p>受到monte-carlo积分【5】的启发，可以得到下面的形式：</p><p><span class="math display">\[h(\mathbf{x})=\int_{-\infty}^{\infty} f(\mathbf{y}) g(\mathbf{x}-\mathbf{y}) d \mathbf{y} \approx \sum_{i}^{N} \frac{1}{N} f\left(\mathbf{y}_{i}\right) g\left(\mathbf{x}-\mathbf{y}_{i}\right) \tag{1}\]</span></p><p>这样就解决了积分的问题</p></li><li><p>至于<span class="math inline">\(g\)</span>（卷积核）的形式，在discrete CNN中，是为每个离散的位置都赋予一个单独的参数，但这不可能在continuous上实现。</p><p>解决方案也是简单的，直接使用一个MLP来实现</p><blockquote><p>根据universal approximation theorem【12】，MLPs有足够的能力来拟合<span class="math inline">\(\mathbb{R}^n\)</span>上的任意连续函数。</p></blockquote><p>即：</p><p><span class="math display">\[g(\mathbf{z} ; \theta)=M L P(\mathbf{z} ; \theta)\]</span></p><blockquote><p>实际上多项式也是可以的，但问题在于low-order的多项式没有足够的能力，而high-order的多项式数值计算不稳定</p></blockquote></li></ol><p>注意到continuous CNN有个特点：<strong>其输入的点的位置可以和输出的点的位置不一样，这是因为式1中的<span class="math inline">\(y\)</span>是可以取任意的连续值的。</strong>这实际上隐式的提供了一种pooling的方式。</p><h3 id="构建deep-networks">2. 构建Deep Networks</h3><p>continuous CNN的输入有3个部分：</p><ul><li>输入特征：<span class="math inline">\(\mathcal{F}=\left\{\mathbf{f}_{\mathrm{in}, j} \in \mathbb{R}^{F}\right\}\)</span>；</li><li>相应的位置坐标：<span class="math inline">\(\mathcal{S}=\left\{\mathbf{y}_{j}\right\}\)</span>；</li><li>输出的位置坐标：<span class="math inline">\(\mathcal{O}=\left\{\mathbf{x}_{i}\right\}\)</span>；</li></ul><p>所以每一层的计算公式为：</p><p><span class="math display">\[h_{k, i}=\sum_{d}^{F} \sum_{j}^{N} g_{d, k}\left(\mathbf{y}_{j}-\mathbf{x}_{i}\right) f_{d, j}\]</span></p><p>其中<span class="math inline">\(N\)</span>是输入点的个数，<span class="math inline">\(i\)</span>是输出点的index，<span class="math inline">\(d\)</span>是位置信息的维度index，<span class="math inline">\(k\)</span>是kernel的index。</p><p>显然，可以类似discrete CNN那样来搭建Continuous CNN的block，比如加入BN、非线性激活等等。注意，<strong>residual connection是非常必要的，因为可以帮助快速收敛</strong>。</p><p>下图是一个block的搭建：</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-01-35-46.png"><br></p><p>下图是本文进行实验时整个网络的结构：</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-01-37-07.png"><br></p><h3 id="讨论">3. 讨论</h3><ol type="1"><li><p>locality enforcing continuous convolution：</p><p>传统的discrete CNN因为kernel是有限大小的，所以能够有局部性（locality），而continuous CNN也可以通过一些操作来具有局部性：</p><p><span class="math display">\[g(\mathbf{z})=M L P(\mathbf{z}) w(\mathbf{z})\]</span></p><p>有两种思路来实现：</p><ul><li><span class="math inline">\(w(\mathbf{z})\)</span>是一个characteristic function，对应的set是对应点的knn，其中邻居的数量假设为<span class="math inline">\(|\mathbf{S}|\)</span>，称为cardinality of the support domain。</li><li><span class="math inline">\(w(\mathbf{z})\)</span>是一个characteristic function，对应的set是对应点为圆心形成的半径固定的邻域。</li></ul></li><li><p>efficient continuous convolution：</p><p>在每一层conv layer中，kernel function（MLP）的执行次数是<span class="math inline">\(N\times |\mathbf{S}|\times F\times O\)</span>，其中<span class="math inline">\(N\)</span>是点的数量、<span class="math inline">\(|\mathbf{S}|\)</span>是cardinality of the support domain的大小，<span class="math inline">\(F\)</span>和<span class="math inline">\(O\)</span>分别表示输入和输出的特征的维度。运算和内存是非常expensive的，因为我们需要储存一个以上维度的weighted matrix（由MLPs计算得到的），来和features进行weighted sum。</p><blockquote><p>首先我们分析一下discrete CNN的一层layer中的kernel tensor的维度，是一个4d tensor。首先是kernel本身的size（<span class="math inline">\(h,w\)</span>），然后是输入的channel，这3个维度聚合只能得到一张feature map，为了能够提取更多的信息，就需要设置多个kernels，每个kernel形成一张2d的feature map，多张2d feature map形成一个新的有channel的“图片“。所以就有了第4个维度，其大小等于输出的channel的大小。<br>另外，我们需要对每个点都进行一次以此点为中心的weighted sum操作。假设我们针对的图片是<span class="math inline">\(H\times W\)</span>大小的，对于这样的一张图片（一个样本），一共做了乘法的次数是<span class="math inline">\(hw\times i\times o\times HW\)</span>。<br>continuous CNN是类似的。上面的公式中，<span class="math inline">\(N\)</span>相等于<span class="math inline">\(HW\)</span>，<span class="math inline">\(|\mathbf{S}|\)</span>相当于<span class="math inline">\(hw\)</span>，<span class="math inline">\(F\)</span>相当于<span class="math inline">\(i\)</span>，<span class="math inline">\(O\)</span>相等于<span class="math inline">\(o\)</span>。</p></blockquote><p>为了能够提高效率，方法是将上面那个我们需要MLP生成的<span class="math inline">\(N\times |\mathbf{S}|\times F\times O\)</span>维度tensor，拆分成两个tensor的叉乘：</p><p><span class="math display">\[ \begin{aligned} W_{N\times |\mathbf{S}|\times F\times O} &amp;= W_1 \times W_2 \\ &amp;=W_{F\times O} \times W_{N\times|\mathbf{S}|\times O} \end{aligned} \]</span> 其中<span class="math inline">\(W_2\)</span>是通过MLP生成的（MLP输出维度是<span class="math inline">\(O\)</span>，运行<span class="math inline">\(N\times|\mathbf{S}|\)</span>次），<span class="math inline">\(W_1\)</span>是一个单独的参数矩阵。</p><blockquote><p>这相当于认为input channels进行了一定的参数共享，使用线性空间的角度来看：input channels间的参数是有一个相同的基向量（<span class="math inline">\(W_1\)</span>）生成的空间，坐标是MLP的输出。</p></blockquote><p>配合BN，可以提高执行效率3倍，而且降低了内存占用。</p></li><li><p>special cases：</p><p>实际上上面介绍的是continuous CNN框架的一种特殊情况而已，continuous CNN框架是非常general的。比如其可以通过特殊的设计，变成gaussian kernel、first-order spatial graph convolution【15】等。</p></li></ol><h2 id="results">Results</h2><blockquote><p>以下的结果来自点云分割任务，而对于此任务，我不是非常了解，所以可能会有一些错误的理解。我进行只进行结果的简单记录，目的是对continuous CNN的性能有一个初步的印象。</p></blockquote><p>基于3D点云的实验任务有两个：</p><ul><li>Semantic labeling<ul><li>outdoor lidar（激光雷达）semantic segmentation dataset，137 billion points</li><li>indoor semantic labeling dataset，629 million points【1】</li></ul></li><li>motion estimation</li></ul><h3 id="semantic-segmentation-of-indoor-scenes">1. Semantic Segmentation of Indoor Scenes</h3><ul><li><p>train和test流程来自【28】，输入是6个维度（x、y、z、r、g、b），类别数是13类。</p></li><li><p>比较算法：PointNet【20】和SegCloud【28】</p></li><li><p>参数设置：一共有8个continuous CNNs，前7个的channels是32，最后一个是128，然后将最后一层的数据在所有点上进行global pooling，然后将这个feature concat到每个点的特征上，得到256的特征，然后为每一个点使用一个fc-softmax进行分类。loss是cross entropy loss，optimizer是Adam。</p></li><li><p>结果：下面的图和表分别显示了指标的结果和分类的质量：</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-11-14-02.png"><br></p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-11-14-31.png"><br></p><p>结果显示，PCCN效果还是非常好的。</p></li></ul><h3 id="semantic-segmentation-of-driving-scenes">2. Semantic Segmentation of Driving Scenes</h3><ul><li><p>该数据集由snippets组成，每个snippets有300 frames（帧）：</p><ul><li>training and validation set 11337 snippets</li><li>test set 1644 snippets，每个snippets随机采样10个frames用来避免一些静态场景（等待红绿灯）所带来的影响</li></ul><p>类别数是7类，指标是meanIOU和pointACC。</p></li><li><p>比较算法：</p><ul><li>PointNet【20】，移除了point rotation layer</li><li>3D-FCN，ResNet-50作为backbone并将最后的pooling和fc替换为FC layers和trilinear upsampling layer来进行分割，loss是class-reweighted cross-entropy loss，adam optimizer</li></ul></li><li><p>参数设置：使用了两个版本</p><ul><li>直接输入xyz lidar points（PCCN），16个continuous CNNs，有residual connections、BN和ReLU，pointwise cross-entropy loss，adam optimizer</li><li>3D-FCN+PCCN，即前面先使用3D-FCN进行特征的预处理，然后连接7个continuous CNNs，设置和上面相同</li></ul></li><li><p>结果：</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-11-47-44.png"><br></p><p>我们可以看到，PCCN模型的参数量也是非常小的。</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-17-11-49-03.png"><br></p></li><li><p>运行速度：</p><p>使用GTX 1080Ti和Xeon E5-2687W CPU、32G内存，8-layers PCNN的forward pass是33ms、KD-Treeneighbour search是28ms，整体的end-to-end的计算是61ms，每一层的计算量是1.32 GFLOPs。</p><blockquote><p>1 GFLOPs大约是<span class="math inline">\(10^9\)</span>次运算。</p></blockquote></li></ul><h3 id="lidar-flow">3. Lidar Flow</h3><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-20-11-11-09.png"><br></p><ul><li><p>training set和validation set有11337 snippets（110k frame pairs），test set有1644 snippets（16440 frame pairs）。</p></li><li><p>比较算法：3D-FCN</p></li><li><p>参数设置：移除了ReLU、使用MSE loss</p></li><li><p>结果：</p><p>如下面的表格和图片所示：</p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-20-11-14-33.png"><br></p><p><img src="/2020/06/16/paper/dl/paper-conticnn/paper-contiCNN_2020-06-20-11-14-52.png"><br></p></li></ul><h2 id="conclusion">Conclusion</h2><p>提出了一种新的深度学习框架，可以应用于non-grid的data。并在点云分割和运动估计中验证了该方法的有效性。</p><hr><h2 id="questions">Questions</h2><p><em>其实思想是非常简单的，但在点云分割中竟然能够work而且效果这么好是令我惊讶的。更令我惊讶的是其在GTX 1080Ti上还能够有比较快的速度。</em></p>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Point Cloud </tag>
            
            <tag> Convolutional Neural Networks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5学习</title>
      <link href="/2020/06/08/pylearning/pyqt5/pyqt5-index/"/>
      <url>/2020/06/08/pylearning/pyqt5/pyqt5-index/</url>
      
        <content type="html"><![CDATA[<p>PyQt5作为一个非常成熟的GUI制作Python模块，是非常值得学习的，最重要的是我正好有这方面的需求，希望制作一个不错的博客文件管理系统。之前是使用tkinter来制作的，tkinter也很不错，非常容易上手，适合简单的应用，但问题在于对于其中一些组件的控制实在不容易，而且可用的组件也比较少。</p><p>这里PyQt5的学习主要依赖于<a href="https://www.learnpyqt.com/" target="_blank" rel="noopener">Martin Fitzpatrick的网站</a>，另外，<a href="https://build-system.fman.io/pyqt5-tutorial" target="_blank" rel="noopener">Michael的网站</a>提供了另外一个选择，但我们并没有找到其书籍的下载地址。</p><p><a href="https://doc.qt.io/" target="_blank" rel="noopener">Qt5的官方文档</a>是非常必要的，其中已经加入了<a href="https://doc.qt.io/qtforpython/" target="_blank" rel="noopener">Python的部分</a>。</p><blockquote><p>不过现在官方再推PySide2，所以官方都是文档都是PySide2的，但实际上其API和PyQt5基本是一致的。</p></blockquote><p>以下是我的学习历程：</p><ol type="1"><li></li><li></li><li></li><li></li><li></li></ol><p><em>未完待续</em></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5教程-Martin ModelView架构</title>
      <link href="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch5/"/>
      <url>/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch5/</url>
      
        <content type="html"><![CDATA[<p>我们在构建复杂的应用的时候往往会遇到ui界面和外部数据间如何交互的问题。有以下几种方式：</p><ol type="1"><li>将所有的数据都储存在widgets中，但这带来的问题是：当我们想要得到其中的数据并进行更改的时候会非常麻烦，因为在qt中数据不是以python自己的格式储存的。</li><li>将数据始终保存在外部，每次数据变动时都将其送入widgets或者直接将widgets重新加载。这可能导致我们大部分时间都在摆弄我们的数据，而且无法很好的控制我们的widgets。</li></ol><p>Qt提供了ModelViews架构，来解决上面的问题。</p><h1 id="model-view-controller">Model View Controller</h1><p>MVC是在构建应用时常用的架构安排，其将应用分为3个部分：</p><ul><li>Model，app内部使用的数据格式</li><li>View，最终显示给用户的数据样式，可以有多个</li><li>Controller，其接受用户的输入，并将其转换到Model或View</li></ul><p>Qt认为View和Controller之间的界定有点模糊，索性就将其两者合并，称为了Model/ViewController架构，或者叫做Model View架构。</p><h1 id="model-view">Model View</h1><ul><li>Model：储存数据，可以返回单个或多个records，以及相关的元数据。</li><li>View：从model中请求数据并将其展示在widgets中。</li></ul><h1 id="示例a-todo-list">示例：a Todo List</h1><p><em>未完待续</em></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5教程-Martin 自定义组件</title>
      <link href="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/"/>
      <url>/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/</url>
      
        <content type="html"><![CDATA[<p>自定义组件的第一步，需要理解PyQt5中的bitmap（pixel-based）graphic operations，因为所有的组件其实都是利用这个东西画出来的。</p><h1 id="qpainter和bitmap-graphics">QPainter和Bitmap Graphics</h1><blockquote><p>bitmap是pixels的正方形区域，也就是我们常说的位图。</p></blockquote><h2 id="qpainter和bitmap">1. QPainter和Bitmap</h2><p><code>QPainter</code>用来实现Qt中的bitmap drawing operations。其接受一个<code>QPixmap</code>对象作为参数，可以在这个<code>QPixmap</code>进行绘制。</p><p>代码示例：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example1.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5 <span class="token keyword">import</span> QtCore<span class="token punctuation">,</span> QtGui<span class="token punctuation">,</span> QtWidgets<span class="token punctuation">,</span> uic<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> Qt<span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QtWidgets<span class="token punctuation">.</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 创建一个label，并将其放到整个窗口中</span>        self<span class="token punctuation">.</span>label <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 创建一个画布，并将这个画布放到label上</span>        canvas <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPixmap<span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 原教程中没有介绍，新创建的Pixmap对象是null的，需要先给底色，可以使用fill(QColor(.))来完成，其默认是白色</span>        canvas<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>setPixmap<span class="token punctuation">(</span>canvas<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 在画布上画一些东西</span>        self<span class="token punctuation">.</span>draw_something<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 对一个QPixmap对象操作，需要使用QPainter</span>        painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        painter<span class="token punctuation">.</span>drawLine<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>        painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span>app <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-11-55-17.png"><br></p><h3 id="绘制用的方法">1.1 绘制用的方法</h3><p><code>QPainter</code>提供大量的方法来对bitmap进行操作，但幸运的是这些方法大多数是一些overloaded methods（即相同方法，适用于不同的输入）。</p><p>比如下面的5种绘制线条的方法：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-11-57-37.png"><br></p><blockquote><p><code>QLine</code>和<code>QLineF</code>使用<code>QLine(x1, y1, x2, y2)</code>或<code>QLine(p1, p2)</code>的方式定义，<code>QPoint</code>对象使用<code>QPoint(x1, y1)</code>的方式来定义，所以实际上这些是相同的方法。</p><p><code>QLineF</code>是指坐标可以有float来指定。</p></blockquote><p>去除这些重复的方法，则绘制方法可以简单的总结为下面的几个：</p><blockquote><p>drawArc , drawChord, drawConvexPolygon, drawEllipse,drawLine, drawPath, drawPie, drawPoint, drawPolygon, drawPolyline, drawRect, drawRects drawRoundedRect.</p></blockquote><h3 id="drawpoint">1.2 drawPoint</h3><p>我们改变<code>drawsomething</code>方法：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawPoint<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>得到下面的结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-04-25.png"><br></p><p>可能当中的点不太容易看出来。</p><p>我们可以来更改绘制点的形状、颜色和大小，方法是使用<code>QPen</code>对象。</p><blockquote><p>将这个过程想成你正在用ipad的手写笔。一次只能用一支笔来写。</p></blockquote><p>我们进行如下修改：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawPoint<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-09-33.png"><br></p><p>现在，我们将相当于使用程序控制一个电子笔进行绘制，比如：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    <span class="token keyword">for</span> n <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        painter<span class="token punctuation">.</span>drawPoint<span class="token punctuation">(</span>            <span class="token number">200</span><span class="token operator">+</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># x</span>            <span class="token number">150</span><span class="token operator">+</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># y</span>            <span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-13-35.png"><br></p><p>当然，也可以在绘制的图中更换“笔”的状态：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint<span class="token punctuation">,</span> choice    colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'#FFD141'</span><span class="token punctuation">,</span> <span class="token string">'#376F9F'</span><span class="token punctuation">,</span> <span class="token string">'#0D1F2D'</span><span class="token punctuation">,</span> <span class="token string">'#E9EBEF'</span><span class="token punctuation">,</span> <span class="token string">'#EB5160'</span><span class="token punctuation">]</span>    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    <span class="token keyword">for</span> n <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># pen = painter.pen() you could get the active pen here</span>        pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span>choice<span class="token punctuation">(</span>colors<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>        painter<span class="token punctuation">.</span>drawPoint<span class="token punctuation">(</span>            <span class="token number">200</span><span class="token operator">+</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># x</span>            <span class="token number">150</span><span class="token operator">+</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># y</span>            <span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-16-26.png"><br></p><h3 id="drawline">1.3 drawLine</h3><p>和上面的一样，只是换成了线段而已</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">'blue'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawLine<span class="token punctuation">(</span>        QtCore<span class="token punctuation">.</span>QPoint<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        QtCore<span class="token punctuation">.</span>QPoint<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-21-55.png"><br></p><h3 id="drawrectdrawrectsdrawroundedrect">1.4 drawRect、drawRects、drawRoundedRect</h3><p>分别是绘制一个矩形，多个矩形和圆角矩形。</p><blockquote><p>和线段类似，使用4个坐标点或者使用<code>QRect</code>、<code>QRectF</code>都可以。</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">"#EB5160"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRect<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRect<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRect<span class="token punctuation">(</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRect<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRect<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果:</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-24-33.png"><br></p><p>也可以使用<code>drawRects</code>完成：</p><pre class="line-numbers language-python"><code class="language-python">painter<span class="token punctuation">.</span>drawRects<span class="token punctuation">(</span>    QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然，对于几何图形来说，现在就有一个另一个问题，即填充的问题。这个需要使用另一种“画笔”--<code>QBrush</code>。指定此刷子后，通过赋予粉刷的范围（这里就是我们指定的<code>QRect</code>对象），其在其上赋予指定的<code>style</code>效果。</p><p>比如使用下面的代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">"#376F9F"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    brush <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QBrush<span class="token punctuation">(</span><span class="token punctuation">)</span>    brush<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">"#FFD141"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    brush<span class="token punctuation">.</span>setStyle<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>DenselPattern<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setBrush<span class="token punctuation">(</span>brush<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRects<span class="token punctuation">(</span>        QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">70</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-29-36.png"><br></p><p>另外关于圆角矩形：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">"#376F9F"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRoundedRect<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRoundedRect<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRoundedRect<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawRoundedRect<span class="token punctuation">(</span><span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其和矩形基本一致，主要就是需要提供额外的2个参数，指定角上的（长短）半径。</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-31-36.png"><br></p><h3 id="绘制椭圆">1.5 绘制椭圆</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token number">204</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># r, g, b</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawEllipse<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawEllipse<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawEllipse<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-32-14.png"><br></p><h3 id="文本">1.6 文本</h3><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">draw_something</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">from</span> random <span class="token keyword">import</span> randint    painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    pen <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPen<span class="token punctuation">(</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    pen<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">'green'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>pen<span class="token punctuation">)</span>    font <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QFont<span class="token punctuation">(</span><span class="token punctuation">)</span>    font<span class="token punctuation">.</span>setFamily<span class="token punctuation">(</span><span class="token string">'Times'</span><span class="token punctuation">)</span>    font<span class="token punctuation">.</span>setBold<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>    font<span class="token punctuation">.</span>setPointSize<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>setFont<span class="token punctuation">(</span>font<span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>drawText<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">'Hello, world!'</span><span class="token punctuation">)</span>    painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-33-45.png"><br></p><p>还可以指定显示文本的框的大小，实现截断的效果：</p><pre class="line-numbers language-python"><code class="language-python">painter<span class="token punctuation">.</span>drawText<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> Qt<span class="token punctuation">.</span>AlignHCenter<span class="token punctuation">,</span> <span class="token string">'Hello, world!'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/pyqt5-tutorial-Martin-ch4_2020-06-08-12-34-33.png"><br></p><h2 id="自己的画板软件">2. 自己的画板软件</h2><p>根据上面的知识，我们就可以指定自己的画板软件了：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example2.py</span><span class="token keyword">import</span> sys<span class="token keyword">import</span> random<span class="token keyword">from</span> PyQt5 <span class="token keyword">import</span> QtCore<span class="token punctuation">,</span> QtGui<span class="token punctuation">,</span> QtWidgets<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> QtCOLORS <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token comment" spellcheck="true"># 17 undertones https://lospec.com/palette-list/17undertones</span>    <span class="token string">'#000000'</span><span class="token punctuation">,</span> <span class="token string">'#141923'</span><span class="token punctuation">,</span> <span class="token string">'#414168'</span><span class="token punctuation">,</span> <span class="token string">'#3a7fa7'</span><span class="token punctuation">,</span> <span class="token string">'#35e3e3'</span><span class="token punctuation">,</span> <span class="token string">'#8fd970'</span><span class="token punctuation">,</span>    <span class="token string">'#5ebb49'</span><span class="token punctuation">,</span> <span class="token string">'#458352'</span><span class="token punctuation">,</span> <span class="token string">'#dcd37b'</span><span class="token punctuation">,</span> <span class="token string">'#fffee5'</span><span class="token punctuation">,</span> <span class="token string">'#ffd035'</span><span class="token punctuation">,</span> <span class="token string">'#cc9245'</span><span class="token punctuation">,</span>    <span class="token string">'#a15c3e'</span><span class="token punctuation">,</span> <span class="token string">'#a42f3b'</span><span class="token punctuation">,</span> <span class="token string">'#f45b7a'</span><span class="token punctuation">,</span> <span class="token string">'#c24998'</span><span class="token punctuation">,</span> <span class="token string">'#81588d'</span><span class="token punctuation">,</span> <span class="token string">'#bcb0c2'</span><span class="token punctuation">,</span>    <span class="token string">'#ffffff'</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token keyword">class</span> <span class="token class-name">QPaletteButton</span><span class="token punctuation">(</span>QtWidgets<span class="token punctuation">.</span>QPushButton<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义按钮，背景颜色代表其储存的颜色类别，    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setFixedSize<span class="token punctuation">(</span>QtCore<span class="token punctuation">.</span>QSize<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>color <span class="token operator">=</span> color        self<span class="token punctuation">.</span>setStyleSheet<span class="token punctuation">(</span><span class="token string">"background-color: %s"</span> <span class="token operator">%</span> color<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># self.setCheckable(True)  # 有按下的效果</span><span class="token keyword">class</span> <span class="token class-name">Canvas</span><span class="token punctuation">(</span>QtWidgets<span class="token punctuation">.</span>QLabel<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    自定义画布，实际上就是一个带有pixmap的label。    可以侦测鼠标的移动从而进行绘制    储存有当前画笔的颜色，改变当前画笔的颜色使用set_pen_color方法    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        pixmap <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPixmap<span class="token punctuation">(</span><span class="token number">600</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">)</span>        pixmap<span class="token punctuation">.</span>fill<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setPixmap<span class="token punctuation">(</span>pixmap<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>last_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>last_y <span class="token operator">=</span> None<span class="token punctuation">,</span> None        self<span class="token punctuation">.</span>pen_color <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span><span class="token string">"#000000"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pen_type <span class="token operator">=</span> <span class="token string">'pen'</span>    <span class="token keyword">def</span> <span class="token function">set_pen_color</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>pen_color <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QColor<span class="token punctuation">(</span>c<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">mouseMoveEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">:</span>        painter <span class="token operator">=</span> QtGui<span class="token punctuation">.</span>QPainter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        p <span class="token operator">=</span> painter<span class="token punctuation">.</span>pen<span class="token punctuation">(</span><span class="token punctuation">)</span>        p<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pen_color<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pen_type <span class="token operator">==</span> <span class="token string">"pen"</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> self<span class="token punctuation">.</span>last_x <span class="token keyword">is</span> None<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true"># First event.</span>                <span class="token comment" spellcheck="true"># 当我们按下鼠标的一刻，会触发该方法，此时last_x和last_y都是None</span>                <span class="token comment" spellcheck="true">#   所以先记录一下当前的鼠标位置</span>                self<span class="token punctuation">.</span>last_x <span class="token operator">=</span> e<span class="token punctuation">.</span>x<span class="token punctuation">(</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>last_y <span class="token operator">=</span> e<span class="token punctuation">.</span>y<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">return</span>  <span class="token comment" spellcheck="true"># Ignore the first time.</span>            <span class="token comment" spellcheck="true"># 当我们继续移动鼠标，技术触发该方法，此时，会执行下面的内容绘制线条并</span>            <span class="token comment" spellcheck="true">#   更新last_x和last_y</span>            p<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>            painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>p<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 这里使用line，因为如果是point的话，绘制的速度会跟不上鼠标移动的速度，</span>            <span class="token comment" spellcheck="true">#   从而出现断开的状态。如果是line的话就没有这个问题，但线条会比较毛糙。</span>            painter<span class="token punctuation">.</span>drawLine<span class="token punctuation">(</span>self<span class="token punctuation">.</span>last_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>last_y<span class="token punctuation">,</span> e<span class="token punctuation">.</span>x<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> e<span class="token punctuation">.</span>y<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            painter<span class="token punctuation">.</span>end<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 绘制图像的过程发生在show之后，所以如果想要把绘制的内容打印到屏幕上，</span>            <span class="token comment" spellcheck="true">#   需要使用update方法</span>            self<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># Update the origin for next time.</span>            self<span class="token punctuation">.</span>last_x <span class="token operator">=</span> e<span class="token punctuation">.</span>x<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>last_y <span class="token operator">=</span> e<span class="token punctuation">.</span>y<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>pen_type <span class="token operator">==</span> <span class="token string">"spray"</span><span class="token punctuation">:</span>            p<span class="token punctuation">.</span>setWidth<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            painter<span class="token punctuation">.</span>setPen<span class="token punctuation">(</span>p<span class="token punctuation">)</span>            <span class="token keyword">for</span> n <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                xo <span class="token operator">=</span> random<span class="token punctuation">.</span>gauss<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>                yo <span class="token operator">=</span> random<span class="token punctuation">.</span>gauss<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>                painter<span class="token punctuation">.</span>drawPoint<span class="token punctuation">(</span>e<span class="token punctuation">.</span>x<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> xo<span class="token punctuation">,</span> e<span class="token punctuation">.</span>y<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> yo<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">mouseReleaseEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 当我们松开鼠标的时候，将last_x和last_y抹除</span>        self<span class="token punctuation">.</span>last_x <span class="token operator">=</span> None        self<span class="token punctuation">.</span>last_y <span class="token operator">=</span> None<span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QtWidgets<span class="token punctuation">.</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>canvas <span class="token operator">=</span> Canvas<span class="token punctuation">(</span><span class="token punctuation">)</span>        w <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        l <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        w<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>l<span class="token punctuation">)</span>        l<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>canvas<span class="token punctuation">)</span>        palette <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_palette_buttons<span class="token punctuation">(</span>palette<span class="token punctuation">)</span>        l<span class="token punctuation">.</span>addLayout<span class="token punctuation">(</span>palette<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>w<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">add_palette_buttons</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> layout<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 为每个颜色创建一个按钮，并设置当按下按钮的时候，更改画布中的画笔颜色</span>        <span class="token comment" spellcheck="true">#   然后把所有的按钮防止到布局中</span>        <span class="token keyword">for</span> c <span class="token keyword">in</span> COLORS<span class="token punctuation">:</span>            b <span class="token operator">=</span> QPaletteButton<span class="token punctuation">(</span>c<span class="token punctuation">)</span>            b<span class="token punctuation">.</span>pressed<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token keyword">lambda</span> c<span class="token operator">=</span>c<span class="token punctuation">:</span> self<span class="token punctuation">.</span>canvas<span class="token punctuation">.</span>set_pen_color<span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">)</span>            layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>b<span class="token punctuation">)</span>app <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以通过改变<code>pen_type</code>来实现不同的画笔效果：</p><p>铅笔画：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/example2-2.gif"><br></p><p>油画：</p><p><img src="/2020/06/08/pylearning/pyqt5/pyqt5-tutorial-martin-ch4/example2-1.gif"><br></p><h1 id="自定义gui组件">自定义GUI组件</h1><p>未完待续...</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5教程-Martin 扩展Signals</title>
      <link href="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch3/"/>
      <url>/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch3/</url>
      
        <content type="html"><![CDATA[<p>本章将试图通过python来对signal的行为进行更改，或者创建自定义的signals。</p><h1 id="改变signal的data">改变Signal的data</h1><p>Signals传给Slots的值是固定的，理论上我们无法更改。但现在我们可以通过python的一些语言特性来完成。</p><h2 id="取消数据">1. 取消数据</h2><p>目的：Signals会传送数据给Slots，但现在Slots不需要这个数据。</p><p>方案：使用另一个function来wrap：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> fn<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 现在x不会被传递到fn中</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="增加数据">2. 增加数据</h2><p>目的：除了signals发送的数据，Slots还需要其他的数据</p><p>方案：还是wrap一个函数</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> some_more_data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在loop时使用此方法，一定要注意variables的行为，这时候最后的值可能会覆盖前方的值。</p><blockquote><p>这在中碰到过。</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">lambda</span><span class="token punctuation">:</span> fn<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>每次迭代的时候，<code>i</code>都会指向新的值，如果我们的函数<code>fn</code>立即执行了<code>i</code>，则这没有问题。但关键在于，我们在进行布局的时候，我们并没有立即从<code>i</code>中取出我们想要的值，则<code>fn</code>只是暂时保存了<code>i</code>的引用。当我们在event loop中触发<code>fn</code>执行的时候，其先找到<code>i</code>，然后去看它指向的数据，这个时候loop已经执行完，这个值永远是<code>n</code>。</p><p>解决方案：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">lambda</span> i<span class="token operator">=</span>i<span class="token punctuation">:</span> fn<span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>解决方案也很简单，也是利用python的特性。python函数创建的时候，如果参数有默认值，为了效率考虑，其会先把默认值执行一遍，取到值和函数的定义存放在一起备用。所以如果将<code>i</code>指定成默认值，其会在每个循环的时候都运行一般和相关的函数定义保存到一起，这就解决了上面的问题。</p><h1 id="自定义signals">自定义Signals</h1><p>实际上，signals就是QObject的<strong>类属性</strong>（几乎所有能碰到的Qt类都是它的子类），创建时使用函数<code>pyqtSignal</code>创建。</p><p>以下使用找到的博客中的例子来进行说明：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example1.py</span><span class="token comment" spellcheck="true"># 来源：https://blog.csdn.net/zhulove86/article/details/52563131</span><span class="token comment" spellcheck="true"># author：Tony Zhu</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> pyqtSignal<span class="token punctuation">,</span> Qt<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token punctuation">(</span>    QWidget<span class="token punctuation">,</span> QApplication<span class="token punctuation">,</span> QGroupBox<span class="token punctuation">,</span> QPushButton<span class="token punctuation">,</span> QLabel<span class="token punctuation">,</span>    QCheckBox<span class="token punctuation">,</span> QSpinBox<span class="token punctuation">,</span> QHBoxLayout<span class="token punctuation">,</span> QComboBox<span class="token punctuation">,</span> QGridLayout<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">SignalEmit</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    helpSignal <span class="token operator">=</span> pyqtSignal<span class="token punctuation">(</span>str<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># str表示这个signal发送的信息将是str</span>    printSignal <span class="token operator">=</span> pyqtSignal<span class="token punctuation">(</span>list<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 这里是复合信号，第一个会带有两个值，第二个将带有1个值，可以使用Signal[int, str]和Signal[str]</span>    <span class="token comment" spellcheck="true">#   得到每个部分</span>    previewSignal <span class="token operator">=</span> pyqtSignal<span class="token punctuation">(</span><span class="token punctuation">[</span>int<span class="token punctuation">,</span> str<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>initUI<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">initUI</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>creatControls<span class="token punctuation">(</span><span class="token string">"打印控制："</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>creatResult<span class="token punctuation">(</span><span class="token string">"操作结果："</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>controlsGroup<span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>resultGroup<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 设置自定义Signals的slots</span>        self<span class="token punctuation">.</span>helpSignal<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>showHelpMesage<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>printSignal<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>printPaper<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>previewSignal<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>previewPaper<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>previewSignal<span class="token punctuation">[</span>int<span class="token punctuation">,</span> str<span class="token punctuation">]</span><span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>previewPaperWithArgs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这里将自定义signals的发送信息作为slots链接到存在的signals上</span>        self<span class="token punctuation">.</span>printButton<span class="token punctuation">.</span>clicked<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>emitPrintSignal<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>previewButton<span class="token punctuation">.</span>clicked<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>emitPreviewSignal<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setGeometry<span class="token punctuation">(</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">290</span><span class="token punctuation">,</span> <span class="token number">150</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"defined signal"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">creatControls</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> title<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 一个带有标题的盒子，用来作为容器承载更多的widgets，主要用来划分区域</span>        self<span class="token punctuation">.</span>controlsGroup <span class="token operator">=</span> QGroupBox<span class="token punctuation">(</span>title<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>printButton <span class="token operator">=</span> QPushButton<span class="token punctuation">(</span><span class="token string">"打印"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>previewButton <span class="token operator">=</span> QPushButton<span class="token punctuation">(</span><span class="token string">"预览"</span><span class="token punctuation">)</span>        numberLabel <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"打印份数："</span><span class="token punctuation">)</span>        paperLabel <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"纸张类型："</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 原来checkBox可以直接给文本来当做label。。</span>        self<span class="token punctuation">.</span>previewStatus <span class="token operator">=</span> QCheckBox<span class="token punctuation">(</span><span class="token string">"全屏预览"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># spin box就是一个数字轮盘</span>        self<span class="token punctuation">.</span>numberSpinBox <span class="token operator">=</span> QSpinBox<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>numberSpinBox<span class="token punctuation">.</span>setRange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>styleCombo <span class="token operator">=</span> QComboBox<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>styleCombo<span class="token punctuation">.</span>addItem<span class="token punctuation">(</span><span class="token string">"A4"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>styleCombo<span class="token punctuation">.</span>addItem<span class="token punctuation">(</span><span class="token string">"A5"</span><span class="token punctuation">)</span>        controlsLayout <span class="token operator">=</span> QGridLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>numberLabel<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>numberSpinBox<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>paperLabel<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>styleCombo<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>printButton<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>previewStatus<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        controlsLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>previewButton<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>controlsGroup<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>controlsLayout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">creatResult</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> title<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>resultGroup <span class="token operator">=</span> QGroupBox<span class="token punctuation">(</span>title<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>resultLabel <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>resultLabel<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>resultGroup<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">emitPreviewSignal</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>previewStatus<span class="token punctuation">.</span>isChecked<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>previewSignal<span class="token punctuation">[</span>int<span class="token punctuation">,</span> str<span class="token punctuation">]</span><span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token number">1080</span><span class="token punctuation">,</span> <span class="token string">"Full Screen"</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>previewStatus<span class="token punctuation">.</span>isChecked<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token boolean">False</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>previewSignal<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token string">"Preview"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">emitPrintSignal</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        pList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        pList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>numberSpinBox<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        pList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>styleCombo<span class="token punctuation">.</span>currentText<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>printSignal<span class="token punctuation">.</span>emit<span class="token punctuation">(</span>pList<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">printPaper</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> list<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>resultLabel<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>            <span class="token string">"Print: "</span> <span class="token operator">+</span> <span class="token string">"份数："</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span>            <span class="token string">"纸张："</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">previewPaperWithArgs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>resultLabel<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>str<span class="token punctuation">(</span>style<span class="token punctuation">)</span> <span class="token operator">+</span> text<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">previewPaper</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>resultLabel<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">keyPressEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> event<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># QWidget自带的方法（event handler），用于在继承时进行改写，</span>        <span class="token comment" spellcheck="true">#   接受的event是关于键盘的事件</span>        <span class="token comment" spellcheck="true"># 在event loop中被时刻监听</span>        <span class="token keyword">if</span> event<span class="token punctuation">.</span>key<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> Qt<span class="token punctuation">.</span>Key_F1<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 如果按下了F1，则helpsignal信号将发送，其发送的消息是字符串</span>            self<span class="token punctuation">.</span>helpSignal<span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token string">"Help Message"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">showHelpMesage</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> message<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 是helpSignal信号的slot，接受的是上面方法中的Help Message字符串，</span>        <span class="token comment" spellcheck="true">#   其行为是将此字符串打印到resultLabel上</span>        self<span class="token punctuation">.</span>resultLabel<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>message<span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>    dispatch <span class="token operator">=</span> SignalEmit<span class="token punctuation">(</span><span class="token punctuation">)</span>    sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch3/example1.gif"><br></p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5教程-Martin Qt Creator</title>
      <link href="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch2/"/>
      <url>/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch2/</url>
      
        <content type="html"><![CDATA[<p>Qt creator实际上是一个用于UI编程的IDE，也就是说其和PyCharm是一个东西，其支持C++、Python，可以直接使用它来编写GUI。但我们这里只考虑它的图形化界面搭建UI界面的部分。</p><h1 id="创建.ui文件">创建.ui文件</h1><blockquote><p>整个过程使用下面的gif文件说明：</p></blockquote><p><img src="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch2/creat_ui.gif"><br></p><h1 id="创建widgets并进行布局">创建widgets并进行布局</h1><p><img src="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch2/layout.gif"><br></p><p>得到的ui文件的格式是这样的（实际上就是一个xml文件）：</p><pre class="line-numbers language-xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ui</span> <span class="token attr-name">version</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>4.0<span class="token punctuation">"</span></span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>class</span><span class="token punctuation">></span></span>MainWindow<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>class</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QMainWindow<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>MainWindow<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>geometry<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>rect</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>x</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>x</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>y</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>y</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>width</span><span class="token punctuation">></span></span>800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>width</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>height</span><span class="token punctuation">></span></span>600<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>height</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>rect</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>windowTitle<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>string</span><span class="token punctuation">></span></span>MainWindow<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>string</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QWidget<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>centralwidget<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>layout</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QVBoxLayout<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>verticalLayout<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QPushButton<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>pushButton<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>text<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>string</span><span class="token punctuation">></span></span>PushButton<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>string</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>widget</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>item</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>item</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QLabel<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>label<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>text<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>       <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>string</span><span class="token punctuation">></span></span>TextLabel<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>string</span><span class="token punctuation">></span></span>      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>widget</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>item</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>layout</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>widget</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QMenuBar<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>menubar<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>geometry<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>rect</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>x</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>x</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>y</span><span class="token punctuation">></span></span>0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>y</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>width</span><span class="token punctuation">></span></span>800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>width</span><span class="token punctuation">></span></span>     <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>height</span><span class="token punctuation">></span></span>26<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>height</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>rect</span><span class="token punctuation">></span></span>   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>widget</span><span class="token punctuation">></span></span>  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>widget</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>QStatusBar<span class="token punctuation">"</span></span> <span class="token attr-name">name</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>statusbar<span class="token punctuation">"</span></span><span class="token punctuation">/></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>widget</span><span class="token punctuation">></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>resources</span><span class="token punctuation">/></span></span> <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>connections</span><span class="token punctuation">/></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>ui</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="将ui文件导入python">将ui文件导入python</h1><p>第一种方式使用<code>uic.loadUi</code>函数，得到的是一个full functional的对象。我们无法去继承它，在<code>__init__</code>中进行设置。只能使用直接使用它的方法。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example1.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5 <span class="token keyword">import</span> QtWidgets<span class="token punctuation">,</span> uic<span class="token keyword">def</span> <span class="token function">mainwindow_setup</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>    w<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"MainWindow Title"</span><span class="token punctuation">)</span>app <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> uic<span class="token punctuation">.</span>loadUi<span class="token punctuation">(</span><span class="token string">"example1.ui"</span><span class="token punctuation">)</span>mainwindow_setup<span class="token punctuation">(</span>window<span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/07/pylearning/pyqt5/pyqt5-tutorial-martin-ch2/pyqt5-tutorial-Martin-ch2_2020-06-07-23-12-49.png"><br></p><p>第二种方式是使用命令行工具<code>pyuic5</code>将ui文件转换成py文件。</p><pre class="line-numbers language-shell"><code class="language-shell">pyuic5 example1.ui -o example1-py.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>转换得到的python文件：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example1-py.py</span><span class="token comment" spellcheck="true"># -*- coding: utf-8 -*-</span><span class="token comment" spellcheck="true"># Form implementation generated from reading ui file 'example1.ui'</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># Created by: PyQt5 UI code generator 5.15.0</span><span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true"># WARNING: Any manual changes made to this file will be lost when pyuic5 is</span><span class="token comment" spellcheck="true"># run again.  Do not edit this file unless you know what you are doing.</span><span class="token keyword">from</span> PyQt5 <span class="token keyword">import</span> QtCore<span class="token punctuation">,</span> QtGui<span class="token punctuation">,</span> QtWidgets<span class="token keyword">class</span> <span class="token class-name">Ui_MainWindow</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">setupUi</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> MainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>        MainWindow<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"MainWindow"</span><span class="token punctuation">)</span>        MainWindow<span class="token punctuation">.</span>resize<span class="token punctuation">(</span><span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">600</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>centralwidget <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QWidget<span class="token punctuation">(</span>MainWindow<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>centralwidget<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"centralwidget"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>verticalLayout <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QVBoxLayout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>centralwidget<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>verticalLayout<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"verticalLayout"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pushButton <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QPushButton<span class="token punctuation">(</span>self<span class="token punctuation">.</span>centralwidget<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pushButton<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"pushButton"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>verticalLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pushButton<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span>self<span class="token punctuation">.</span>centralwidget<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"label"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>verticalLayout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>label<span class="token punctuation">)</span>        MainWindow<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>centralwidget<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>menubar <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QMenuBar<span class="token punctuation">(</span>MainWindow<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>menubar<span class="token punctuation">.</span>setGeometry<span class="token punctuation">(</span>QtCore<span class="token punctuation">.</span>QRect<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>menubar<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"menubar"</span><span class="token punctuation">)</span>        MainWindow<span class="token punctuation">.</span>setMenuBar<span class="token punctuation">(</span>self<span class="token punctuation">.</span>menubar<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>statusbar <span class="token operator">=</span> QtWidgets<span class="token punctuation">.</span>QStatusBar<span class="token punctuation">(</span>MainWindow<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>statusbar<span class="token punctuation">.</span>setObjectName<span class="token punctuation">(</span><span class="token string">"statusbar"</span><span class="token punctuation">)</span>        MainWindow<span class="token punctuation">.</span>setStatusBar<span class="token punctuation">(</span>self<span class="token punctuation">.</span>statusbar<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>retranslateUi<span class="token punctuation">(</span>MainWindow<span class="token punctuation">)</span>        QtCore<span class="token punctuation">.</span>QMetaObject<span class="token punctuation">.</span>connectSlotsByName<span class="token punctuation">(</span>MainWindow<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">retranslateUi</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> MainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>        _translate <span class="token operator">=</span> QtCore<span class="token punctuation">.</span>QCoreApplication<span class="token punctuation">.</span>translate        MainWindow<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span>_translate<span class="token punctuation">(</span><span class="token string">"MainWindow"</span><span class="token punctuation">,</span> <span class="token string">"MainWindow"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pushButton<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>_translate<span class="token punctuation">(</span><span class="token string">"MainWindow"</span><span class="token punctuation">,</span> <span class="token string">"PushButton"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>label<span class="token punctuation">.</span>setText<span class="token punctuation">(</span>_translate<span class="token punctuation">(</span><span class="token string">"MainWindow"</span><span class="token punctuation">,</span> <span class="token string">"TextLabel"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>实际上我们甚至直接可以在它的基础上进行编写。</p></blockquote><p>我们也可以在其基础上进一步继承和改动。</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PyQt5教程-Martin Qt的basic features</title>
      <link href="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/"/>
      <url>/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/</url>
      
        <content type="html"><![CDATA[<p>PyQt5是一个python库，用来调用Qt。Qt本身是一个C++的GUI framework。使用PyQt5，可以使得我们在不怎么损失C++的速度优势的情况下，利用Python创建一个gui应用。</p><h1 id="基础">基础</h1><h2 id="创建一个application">创建一个application</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example1.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token comment" spellcheck="true"># 每个app都需要且只需要一个QApplication实例，可以将命令行参数传入其中。</span><span class="token comment" spellcheck="true"># 如果确定不需要命令行参数，则传入[]即可</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 开启主事件循环</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># application不会运行到这个地方，直到你退出，并且主事件循环结束</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上是一个最简单的PyQt5应用，当然，运行它不会出现任何东西（不止如此，还无法正常关闭它），但它实际上确实work了，通过查看任务管理器可以知道。</p><p>每个application都需要且只需要一个QApplication示例，其管理着event loop。</p><blockquote><p><strong>event loop</strong>是GUI界面运行的标准模式。每次我们和图形界面的交互（按下按钮、点击鼠标）都会产生一个<strong>event</strong>对象，放入<strong>event queue</strong>中进行等待。<strong>event loop</strong>是一个无限循环的loop，其在每次迭代的时候都会进行检查，并找到在<strong>event queue</strong>等待的evnet，并将<strong>event</strong>和控制权移交给其对应的<strong>event handler</strong>，当<strong>event handler</strong>处理完事件后，将控制权返回给<strong>event loop</strong>，然后再去寻找下一个等待中的<strong>event</strong>。每个application中只会有一个event loop。</p></blockquote><blockquote><p>时刻注意查看任务管理器，很可能有许多程序我们没有正常关闭。</p></blockquote><h2 id="创建一个窗口">创建一个窗口</h2><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example2.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QWidgetapp <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># important! 窗口默认是隐藏的</span><span class="token comment" spellcheck="true"># sys.exit(app.exec_())</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-firstapp_2020-06-06-23-08-23.png"><br></p><blockquote><p>进入event loop后，Ctrl-C不会使其退出</p><p>如果怕无法有效的退出，可以使用下面的语句：</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example2-2.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QWidget<span class="token keyword">try</span><span class="token punctuation">:</span>    app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>    window <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>    window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># important! 窗口默认是隐藏的</span>    sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">finally</span><span class="token punctuation">:</span>    <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实际上，我们在PyQt5中看到的所有组件，都是一个<code>QWidget</code>，如果其没有parent，则其成为一个main window。但我们有一个更加好的创建主窗口的方式，即一个子类<code>QMainWidget</code>，其可以轻松的添加toolbars、statusbars和dockable等组件，所以我们还是用<code>QMainWidget</code>吧：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example2-3.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QMainWindowapp <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> QMainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-firstapp_2020-06-06-23-18-16.png"><br></p><blockquote><p>这个相比上面的那个比较小。。。</p></blockquote><p>实际上我们可以创建多个<code>QMainWidget</code>实例，程序会在最后一个实例关闭后退出。</p><h2 id="添加一个组件">添加一个组件</h2><p>这里我们只添加一个widget <code>QLabel</code>。如果我们想要添加更多的组件的话，需要使用Qt layouts，但只添加一个暂时不需要。</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example3.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QLabel<span class="token punctuation">,</span> QMainWindow<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> Qt<span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Qt namespace中有大量的特征用于自定义widget的行为，类似常量</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将widget放入window的中央，默认widget将填满整个window</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-firstapp_2020-06-06-23-25-05.png"><br></p><blockquote><p>可能是因为字体的问题，还有下面的错误信息：</p><pre class="line-numbers language-shell"><code class="language-shell">qt.qpa.fonts: Unable to open default EUDC font: "C:\\Users\\hasee\\AppData\\LocalLow\\SogouPY\\EUDC\\SGPYEUDC_2.TTE"qt.qpa.fonts: Unable to enumerate family ' "Droid Sans Mono Dotted for Powerline" 'qt.qpa.fonts: Unable to enumerate family ' "Droid Sans Mono Slashed for Powerline" 'qt.qpa.fonts: Unable to enumerate family ' "Roboto Mono Medium for Powerline" 'qt.qpa.fonts: Unable to enumerate family ' "Ubuntu Mono derivative Powerline" '<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></blockquote><h1 id="signals-slots-and-events">Signals, Slots and Events</h1><h2 id="signal的必要性">signal的必要性</h2><p>就像前面所讲的，整个application是事件驱动的。event有多种类型，比如mouse events或者keyboard events。</p><p>点击一个widget会触发<code>QMouseEvent</code>，并送入widget中的<code>.mousePressEvent</code> event handler（这实际上是这个widget的方法），这个handler会处理这个event并得到information（什么触发了这个事件、在哪个位置触发的）。</p><p>所以，如果我们想要对某个操作进行自定义，就可以通过继承widget并重写其对应的event handler方法即可。比如我们可以用一下代码来更改<code>Qbutton</code>的<code>.KeyPressEvent</code> handler：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CustomButton</span><span class="token punctuation">(</span>Qbutton<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">keyPressEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>CustomButton<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>keyPressEvent<span class="token punctuation">(</span>e<span class="token punctuation">)</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上的方法是好的，但如果我们现在需要捕获作用在20个buttons上的一个event，则我们需要重新继承20个buttons。。。显然，我们不会这个做。</p><h2 id="什么是signals和slots">什么是signals和slots</h2><p>Qt提供了一个更加整洁的方式，即<strong>Signals</strong>。</p><ul><li>Signals类似event，当application发生变化时其会发送一个signal<ul><li>比如所有会引起event的行为</li><li>或者是box中的文本发生了变化</li><li>signal会携带改变的数据一起发送过去</li></ul></li><li>在Qt的术语中，接受Signals的方法称为<strong>Slots</strong>，Qt类中提供了一些标准的Slots，但我们可以使用python func来自己定义slots</li></ul><h2 id="signals实验">Signals实验</h2><blockquote><p>Qt5已经有[Python的文档]</p></blockquote><p>常看文档后，发现<code>QMainWidget</code>有一个<code>windowTitleChanged</code> signal，我们现在使用它来进行下述实验：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example4.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QLabel<span class="token punctuation">,</span> QMainWindow<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> Qt<span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 使用connect方法会将signal连接到对应的slot（func）上去，一旦signal</span>        <span class="token comment" spellcheck="true">#   触发（window title改变），则会使用这些funcs</span>        <span class="token comment" spellcheck="true"># 我们可以一次连接多个这样的func，当signal触发时，这些func都会运行</span>        self<span class="token punctuation">.</span>windowTitleChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onWindowTitleChange<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>windowTitleChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> self<span class="token punctuation">.</span>my_custom_fn<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>windowTitleChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> self<span class="token punctuation">.</span>my_custom_fn<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>windowTitleChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> self<span class="token punctuation">.</span>my_custom_fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 在这里设置title的时候会触发上面的func一次</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Qt namespace中有大量的特征用于自定义widget的行为，类似常量</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将widget放入window的中央，默认widget将填满整个window</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">onWindowTitleChange</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 这个x是signal触发是排出的内容，具体要查看文档</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">my_custom_fn</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token string">"Hello"</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>许多signal会被传入已存在的、标准的一些方法中，自然我们可以通过更改这些方法完成我们的目的。同样我们也可以像上面描述的一样，使用<code>connect</code>来连接一个新的slot，这样不会影响原来的slot，他们都会被触发。</p></blockquote><h2 id="当我们不得不使用event时">当我们不得不使用event时</h2><p>所以，因为signals的存在，大多数时候我们不会用到events。但当signal无法解决我们的问题时，我们就必须和event打交道了。</p><p>下面是对右击窗口区域的行为的一次更改：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example5.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> QApplication<span class="token punctuation">,</span> QLabel<span class="token punctuation">,</span> QMainWindow<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> Qt<span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Qt namespace中有大量的特征用于自定义widget的行为，类似常量</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将widget放入window的中央，默认widget将填满整个window</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">contextMenuEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> event<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 右键点击会触发一个event，如果此发生在MainWindow中，则其会被送入</span>        <span class="token comment" spellcheck="true">#   此方法内，这里我们让它在console中打印一些东西</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Context menu event!"</span><span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/event.gif"><br></p><p>如果我们希望保留其原来的功能，可以使用下面的写法：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">contextMenuEvent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> event<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Context menu event!"</span><span class="token punctuation">)</span>    super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>contextMenuEvent<span class="token punctuation">(</span>event<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>其实就是调用了父类的方法。</p></blockquote><p>在一些比较复杂的application上，widget接受了event后，还会将此event发送到其父widget上，如果我们不希望此event发送，可以在widget的handler上添加下面的操作：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CustomButton</span><span class="token punctuation">(</span>Qbutton<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">event</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">:</span>        e<span class="token punctuation">.</span>accept<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>相似的，如果希望它发送，则使用</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">CustomButton</span><span class="token punctuation">(</span>Qbutton<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">event</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">:</span>        e<span class="token punctuation">.</span>ignore<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p>这个命名也有点太别扭了。</p></blockquote><h1 id="基础的组件">基础的组件</h1><h2 id="toolbars">Toolbars</h2><p>整个代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example11.py</span><span class="token keyword">import</span> sys<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">as</span> qtw<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">as</span> qtc<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">as</span> qtg<span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Qt namespace中有大量的特征用于自定义widget的行为，类似常量</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将widget放入window的中央，默认widget将填满整个window</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 创建一个toolbar，并将toolbar加入到main window中</span>        toolbar <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QToolBar<span class="token punctuation">(</span><span class="token string">"My Main toolbar"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 告诉toolbar，我们使用的icon 图片的大小，这样icon可以填充整个按钮</span>        toolbar<span class="token punctuation">.</span>setIconSize<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>QSize<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addToolBar<span class="token punctuation">(</span>toolbar<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 创建一个按钮（这里使用的是action，这是一个更加通用的抽象的按钮类）</span>        <span class="token comment" spellcheck="true">#   action相对于button的好处在于，button只是一个按钮，所以其唯一接受的交互形式是</span>        <span class="token comment" spellcheck="true">#   press。但action可以作为任何形式的交互出现，即其既可以是按钮，又可以出现在菜单栏，</span>        <span class="token comment" spellcheck="true">#   也可以通过键盘快捷键触发。这在toolbar和menubar的实现中是非常必要的，因为一般来说</span>        <span class="token comment" spellcheck="true">#   有很多内容在toolbar和menu中是共享的，如果没有action，我们需要为menu中和toolbar</span>        <span class="token comment" spellcheck="true">#   中都有的一样的功能实现两次。。</span>        <span class="token comment" spellcheck="true"># action接受的是一个QIcon对象作为其icon、string作为其介绍，还有最后的参数是其parent，</span>        <span class="token comment" spellcheck="true">#   这里其signal会传递非其父元素，所以这里设定为main window</span>        button_action <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Your button"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># hover到action上，会在status上打印下面的信息</span>        button_action<span class="token punctuation">.</span>setStatusTip<span class="token punctuation">(</span><span class="token string">"This is you button"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 为action的triggeredsignal绑定slot</span>        button_action<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 该设置使action 按钮有按下的效果</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将action加入到toolbar中</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 添加分割线</span>        toolbar<span class="token punctuation">.</span>addSeparator<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 添加第二个button</span>        button_action2 <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"You button2"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        button_action2<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># toolbar也可以加入其他的widgets</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QCheckBox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setStatusBar<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QStatusBar<span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">onMyToolBarButtonClick</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 这里可以知道，传入的信息是个boolean</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"click"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>app <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/toolbar.gif"><br></p><p>主要需要注意的内容有：</p><ol type="1"><li><p>虽然Qt的toolbars支持icons、text或者其他的Qt标准widgets，但最好的实现方式是使用<code>QAction</code>，原因如上所述。简单来说，<code>QAction</code>可以看做一个综合版的交互单元，可以放在任何组件内，提高了复用性。</p></li><li><p>使用<code>mainwin.setStatusBar</code>来创建状态栏，需要接受一个<code>QStatusBar</code>实例。</p></li><li><p>使用<code>setCheckable</code>来控制按下的效果。</p><blockquote><p>实际上有一个signal<code>.toggled</code>来传递这个按下的消息，但这个消息的功能太单一了，所以用的不多。</p><p>按钮可以下载<a href="http://p.yusukekamiyamane.com/" target="_blank" rel="noopener">fugue icon set</a>中的图片来进行美化。</p></blockquote></li><li><p>添加icon，需要使用下列3个步骤：</p><ul><li>使用<code>Action.setIconSize</code>方法来接受一个<code>QSize</code>对象，指定icon大小</li><li>使用<code>QIcon</code>类来接受图片创建一个Icon对象</li><li>将Icon对象送入Action的第一个参数</li></ul><blockquote><p>因为用的是相对路径来添加图片，所以运行时路径必须在文件所在的路径</p></blockquote><p>文字和Icon的显示方式，我们可以通过<code>.setToolButtonStyle</code>方法来调整，其值可以使用以下的flag：</p></li><li><p>最后可以添加多个<code>QAction</code>对象，甚至是其他的widgets。</p></li></ol><h2 id="menu">menu</h2><p>menu就是下图所示的gui元素：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-03-41-24.png"><br></p><p>代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example12.py</span><span class="token keyword">import</span> sys<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">as</span> qtw<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">as</span> qtc<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">as</span> qtg<span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Qt namespace中有大量的特征用于自定义widget的行为，类似常量</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将widget放入window的中央，默认widget将填满整个window</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        toolbar <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QToolBar<span class="token punctuation">(</span><span class="token string">"My Main toolbar"</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>setIconSize<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>QSize<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addToolBar<span class="token punctuation">(</span>toolbar<span class="token punctuation">)</span>        button_action <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Your button"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setStatusTip<span class="token punctuation">(</span><span class="token string">"This is you button"</span><span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 为了此action添加快捷键</span>        button_action<span class="token punctuation">.</span>setShortcut<span class="token punctuation">(</span>qtg<span class="token punctuation">.</span>QKeySequence<span class="token punctuation">(</span><span class="token string">"Ctrl+p"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 添加分割线</span>        toolbar<span class="token punctuation">.</span>addSeparator<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 添加第二个button</span>        button_action2 <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"You button2"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        button_action2<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># toolbar也可以加入其他的widgets</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QCheckBox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 本来QMainWindow就已经有menu bar了，只是menu bar里是空的</span>        menu <span class="token operator">=</span> self<span class="token punctuation">.</span>menuBar<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setStatusBar<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QStatusBar<span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 添加一个menu</span>        file_menu <span class="token operator">=</span> menu<span class="token punctuation">.</span>addMenu<span class="token punctuation">(</span><span class="token string">"&amp;File"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &amp;使得此Menu可以有alt来控制</span>        file_menu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 为file menu添加一个按钮</span>        file_menu<span class="token punctuation">.</span>addSeparator<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 添加一个分割线</span>        file_menu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action2<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 添加第二个按钮</span>        <span class="token comment" spellcheck="true"># 可以我menu继续添加子menu</span>        file_submenu <span class="token operator">=</span> file_menu<span class="token punctuation">.</span>addMenu<span class="token punctuation">(</span><span class="token string">"Submenu"</span><span class="token punctuation">)</span>        file_submenu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action2<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">onMyToolBarButtonClick</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"click"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>app <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol type="1"><li><p><code>QMainWindow</code>中本身自带了menuBar，所以只需要使用<code>self.menuBar</code>得到即可。</p></li><li><p>使用<code>addMenu</code>方法来添加menu，里面输入menu的名称即可</p><blockquote><p>不要把menu理解成一个按钮，其更是一个容器，一个下拉菜单，里面储存这一个一个的acton</p></blockquote></li><li><p>menu可以嵌套，只需要使用mean的<code>addMenu</code>方法即可。</p></li><li><p>使用<code>setShortCut</code>方法添加快捷键，需要传入<code>QKeySequence</code>对象。</p></li></ol><h2 id="widgets">widgets</h2><p>widgets就是UI的基本组件，是可以和用户产生交互的元素。我们看到的各种toolbar、button等，都是widgets。</p><p>Qt有大量的widgets，而且还支持自定义。以下代码将一些常用的widgets放置在一个<code>QWidget</code>基类中，并放置在main windows的中央。</p><blockquote><p>这里<code>QWidget</code>被用作一个容器</p></blockquote><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example13.py</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> sys<span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        widgets <span class="token operator">=</span> <span class="token punctuation">[</span>            QCheckBox<span class="token punctuation">,</span>            QComboBox<span class="token punctuation">,</span>            QDateTimeEdit<span class="token punctuation">,</span>            QDial<span class="token punctuation">,</span>            QDoubleSpinBox<span class="token punctuation">,</span>            QFontComboBox<span class="token punctuation">,</span>            QLCDNumber<span class="token punctuation">,</span>            QLabel<span class="token punctuation">,</span>            QLineEdit<span class="token punctuation">,</span>            QProgressBar<span class="token punctuation">,</span>            QPushButton<span class="token punctuation">,</span>            QRadioButton<span class="token punctuation">,</span>            QSlider<span class="token punctuation">,</span>            QSpinBox<span class="token punctuation">,</span>            QTimeEdit        <span class="token punctuation">]</span>        <span class="token keyword">for</span> w <span class="token keyword">in</span> widgets<span class="token punctuation">:</span>            layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>w<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-11-53-41.png"><br></p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-11-56-59.png" alt="常用的widgets"><br></p><h3 id="qlabel">1. QLabel</h3><p>这是最简单的widget，不存在交互，只是显示一行字而已。以下代码展示了如何改变其中的文字内容和文字样式：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example14.py</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> sys<span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        widget1 <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 可以直接传入文字</span>        widget1<span class="token punctuation">.</span>setText<span class="token punctuation">(</span><span class="token string">"Hello world"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 通过此方法改变文字的内容</span>        <span class="token comment" spellcheck="true"># 以下是改变文字样式的方法</span>        font <span class="token operator">=</span> widget1<span class="token punctuation">.</span>font<span class="token punctuation">(</span><span class="token punctuation">)</span>        font<span class="token punctuation">.</span>setPointSize<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>        widget1<span class="token punctuation">.</span>setFont<span class="token punctuation">(</span>font<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 改变文字的对齐位置</span>        widget1<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>AlignHCenter <span class="token operator">|</span> Qt<span class="token punctuation">.</span>AlignVCenter<span class="token punctuation">)</span>        widget2 <span class="token operator">=</span> QLabel<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>        widget2<span class="token punctuation">.</span>setPixmap<span class="token punctuation">(</span>QPixmap<span class="token punctuation">(</span><span class="token string">"space.jpg"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        widget2<span class="token punctuation">.</span>setScaledContents<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>widget1<span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>widget2<span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-12-30-20.png"><br></p><p>这里有几点需要注意：</p><ol type="1"><li><p>改变文字样式的方式，最好是先拿到其中的font对象，将其更改后，再把其送入widget中，这样能够保证一些默认样式不会丢失。</p></li><li><p>Qt中的flag可以被用于设置widgets的属性，这里使用了关于文字对齐的部分：</p><p>水平对齐的flags：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-12-13-58.png"><br></p><p>垂直对齐的flags：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-12-14-21.png"><br></p><p>一个特殊的flags：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-12-15-33.png"><br></p><blockquote><p>我们可以使用<code>|</code>来组合一个水平和一个垂直flags来得到4个角落，至于为什么使用<code>|</code>而不是<code>&amp;</code>，这涉及到bitmasks的问题，反正先记住吧。<strong>所有Qt的flags的合并操作都是这样的</strong></p></blockquote></li><li><p>可以使用<code>setPixMap(QPixmpa(a.png))</code>来设置图片。使用<code>.setScaledContents(True)</code>来将图片整个布满按钮。</p></li></ol><h3 id="qcheckbox">2. QCheckBox</h3><p>代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example15.py</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">import</span> sys<span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        widget1 <span class="token operator">=</span> QCheckBox<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这个使用boolean来设置是否选中</span>        <span class="token comment" spellcheck="true"># widget1.setCheckted(True)</span>        <span class="token comment" spellcheck="true"># 这个使用flag来设置状态，有3种</span>        widget1<span class="token punctuation">.</span>setCheckState<span class="token punctuation">(</span>Qt<span class="token punctuation">.</span>Checked<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 设置状态是checked</span>        <span class="token comment" spellcheck="true"># 可以使用此方法来选择第三种状态</span>        <span class="token comment" spellcheck="true"># widget1.setTristate(True)</span>        <span class="token comment" spellcheck="true"># 将state改变的flag连接到slot，传递给slot的实际上就是flag</span>        widget1<span class="token punctuation">.</span>stateChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>show_state<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget1<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">show_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 打印一下flag</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s <span class="token operator">==</span> Qt<span class="token punctuation">.</span>Checked<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/checkbox.gif"><br></p><p>注意：</p><ol type="1"><li><p>有两种方式来改变其checkbox的状态：</p><ul><li><p>使用<code>setCheckState</code>，需要传入flags</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-13-23-37.png"><br></p></li><li><p>或者使用方法<code>setChecked(True)</code>和<code>setTristate(True)</code>，这两个不需要flags，直接设置boolean就可以</p></li></ul></li><li><p>其有一个signal：<code>stateChanged</code>，其传入slot的参数就是上面的flags：</p><blockquote><p>这些flags实际上就是<code>0, 1, 2</code>，但有了flag，我们没有必要去进行记忆。</p></blockquote></li></ol><h3 id="qcombobox">3. QComboBox</h3><p>即下拉列表，代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example16.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QComboBox<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 增加可选元素</span>        widget<span class="token punctuation">.</span>addItems<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"Three"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这个signal默认传给slot的是index</span>        widget<span class="token punctuation">.</span>currentIndexChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>index_changed<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 可以通过此操作，使signal传递给slot的是上面的text</span>        widget<span class="token punctuation">.</span>currentIndexChanged<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_changed<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 此操作使得combo box可以输入文本</span>        widget<span class="token punctuation">.</span>setEditable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 这些输入的文本怎么处理</span>        <span class="token comment" spellcheck="true"># 当我们输入文本并按enter后，下面的设置会使这个文本选项称为新的Items</span>        <span class="token comment" spellcheck="true">#   并插入到Item列表的最后</span>        widget<span class="token punctuation">.</span>setInsertPolicy<span class="token punctuation">(</span>QComboBox<span class="token punctuation">.</span>InsertAtBottom<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># Items最多有5个</span>        widget<span class="token punctuation">.</span>setMaxCount<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">index_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">text_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/combobox.gif"><br></p><p>注意：</p><ol type="1"><li><p>设置插入模式，可以有以下的flags（不再<code>Qt</code>中，而是在<code>QComboBox</code>本身中）</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-13-52-20.png"><br></p></li><li><p>一个应用就是使用combobox来选择字体，但注意，Qt中有一个<code>QFontComboBox</code>直接实现了这个功能。</p></li></ol><h3 id="qlistwidget">4. QListWidget</h3><p>可以认为是始终展开的<code>QComboBox</code>，和<code>QComboBox</code>基本一致，区别在于可用的signals。代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example17.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QListWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 增加可选元素</span>        widget<span class="token punctuation">.</span>addItems<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"Three"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>currentItemChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>index_changed<span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>currentTextChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_changed<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">index_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 这里传入的不是index，而是一个QListItem对象</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">text_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/ListBox.gif"><br></p><p>注意：</p><ol type="1"><li>其将<code>QComboBox</code>的一个signal拆成了两个。</li><li>无法更改文本。</li></ol><h3 id="qlineedit">5. QLineEdit</h3><p>单行文本输入框，代码如下：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example18.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QLineEdit<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 设置可以输入的最大字符数量</span>        widget<span class="token punctuation">.</span>setMaxLength<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 设置预先填入的提示字符</span>        widget<span class="token punctuation">.</span>setPlaceholderText<span class="token punctuation">(</span><span class="token string">"Enter your text"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 此signal在按下enter时触发</span>        widget<span class="token punctuation">.</span>returnPressed<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>return_pressed<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 此signal在选中的文本发生变化的时候触发</span>        widget<span class="token punctuation">.</span>selectionChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>selection_changed<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 此signal在text发生变化时触发，并返回改变的文本</span>        widget<span class="token punctuation">.</span>textChanged<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_changed<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 此signal在进行编辑的时候触发，基本上和textChanged同时触发</span>        widget<span class="token punctuation">.</span>textEdited<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>text_edited<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">return_pressed</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Return preseed!"</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>centralWidget<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setText<span class="token punctuation">(</span><span class="token string">"BOOM!"</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">selection_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Selection changed"</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>centralWidget<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>selectedText<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">text_changed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Text changed..."</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">text_edited</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Text edited..."</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/lineedit.gif"><br></p><p>注意：</p><ol type="1"><li>可以使用<code>self.CentralWidget()</code>得到位于main window中央的widget，这里就是<code>QLineEdit</code>。</li><li>使用<code>widget.setText</code>和<code>widget.selectionText</code>设置输入框中的文本和返回选中的文本。</li></ol><h1 id="布局">布局</h1><p>在Qt中有4种布局方式：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-14-21-21.png"><br></p><blockquote><p>当然，Qt Designer也是可以的，这是更加方便的布局方式。</p></blockquote><h2 id="qvboxlayout">1. QVBoxLayout</h2><p>就是将widgets从上到下堆叠起来</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-16-52-14.png"><br></p><p>代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example19.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"blue"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-04-07.png"><br></p><h2 id="qhboxlayout">2. QHBoxLayout</h2><p>就是将widgets从左到右堆叠起来</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-08-07.png"><br></p><p>代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example20.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"blue"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-06-40.png"><br></p><h2 id="nesting-layouts">3. Nesting layouts</h2><p>任何一个widget都有<code>.addLayout</code>方法，当使用这个方法，其传入的layout中储存的多个widgets就会以当前widget为容器在其中进行排列。每个widget都可以成为这样一个容器，<code>layout</code>本身也不例外。只是layout除了可以<code>addLayout</code>外，还可以直接<code>addWidget</code>，而其他的widgets只能<code>addLayout</code>。</p><p>代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example21.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout1 <span class="token operator">=</span> QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout2 <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout3 <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout2<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout2<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"yellow"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout2<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"purple"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout1<span class="token punctuation">.</span>addLayout<span class="token punctuation">(</span>layout2<span class="token punctuation">)</span>        layout1<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout3<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout3<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"purple"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout1<span class="token punctuation">.</span>addLayout<span class="token punctuation">(</span>layout3<span class="token punctuation">)</span>        layout1<span class="token punctuation">.</span>setContentsMargins<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        layout1<span class="token punctuation">.</span>setSpacing<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout1<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-15-59.png"><br></p><p>另外，我们可以通过<code>layout.setContentsMargins</code>来控制layout的外边距的宽度，<code>layout.setSpacing</code>来控制里面元素的间隔。</p><p>所以我们在代码中加入:</p><pre class="line-numbers language-python"><code class="language-python">layout1<span class="token punctuation">.</span>setContentsMargins<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>layout1<span class="token punctuation">.</span>setSpacing<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>得到以下结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-22-41.png"><br></p><h2 id="qgridlayout">4. QGridLayout</h2><p>模式如下：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-24-44.png"><br></p><p>里面的元素没有必要全都给满，所以下面的模式也是可以实现的：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-25-30.png"><br></p><p>代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example22.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QGridLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"blue"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"purple"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-28-03.png"><br></p><h2 id="qstackedlayout">5. QStackedLayout</h2><p>这个布局是用来实现widgets的堆叠的。在实现graphics和类似书签式的东西时非常有用。</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-30-26.png"><br></p><p>代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example23.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QStackedLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"red"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"green"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"blue"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span><span class="token string">"yellow"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layout<span class="token punctuation">.</span>setCurrentIndex<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 让yellow显示在上面</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-17-32-51.png"><br></p><blockquote><p>注意，有一个<code>QStackedWidget</code>能够实现相同的功能，其一般作为放在Main Windows中央的widget。</p></blockquote><p>但上面的结果我们只能看到最上面的widget，所以，我们可以另外设置一些button来实现widgets的切换：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example24.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        pagelayout <span class="token operator">=</span> QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        button_layout <span class="token operator">=</span> QHBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        layout <span class="token operator">=</span> QStackedLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        pagelayout<span class="token punctuation">.</span>addLayout<span class="token punctuation">(</span>button_layout<span class="token punctuation">)</span>        pagelayout<span class="token punctuation">.</span>addLayout<span class="token punctuation">(</span>layout<span class="token punctuation">)</span>        cs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"red"</span><span class="token punctuation">,</span> <span class="token string">"green"</span><span class="token punctuation">,</span> <span class="token string">"blue"</span><span class="token punctuation">,</span> <span class="token string">"yellow"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> n<span class="token punctuation">,</span> color <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>cs<span class="token punctuation">)</span><span class="token punctuation">:</span>            btn <span class="token operator">=</span> QPushButton<span class="token punctuation">(</span>color<span class="token punctuation">)</span>            btn<span class="token punctuation">.</span>pressed<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token keyword">lambda</span> n<span class="token operator">=</span>n<span class="token punctuation">:</span> layout<span class="token punctuation">.</span>setCurrentIndex<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 这里使用了python的一个技巧。这里将index设为lambda参数的默认值，则其会被缓存，</span>            <span class="token comment" spellcheck="true">#   不然，所有的这四个lambda里的n都只会是黄色</span>            button_layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>btn<span class="token punctuation">)</span>            layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>Color<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        widget <span class="token operator">=</span> QWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        widget<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>pagelayout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>widget<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/stacklayout1.gif"><br></p><p>As a matter of fact，Qt内部实现了一个类似功能的组件，可以直接使用：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example25.py</span><span class="token keyword">import</span> sys<span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">from</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">Color</span><span class="token punctuation">(</span>QWidget<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    一个自定义的类，用于展示布局    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>Color<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 开启后，其自动使用window color来填充背景</span>        self<span class="token punctuation">.</span>setAutoFillBackground<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 得到调色板，默认是global desktop palette。调色板中记录了</span>        <span class="token comment" spellcheck="true">#   widgets的各种元素的颜色，可以看做是widgets颜色设置的一组</span>        <span class="token comment" spellcheck="true">#   集合</span>        palette <span class="token operator">=</span> self<span class="token punctuation">.</span>palette<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将调色板中窗口颜色改变，需要使用QColor类</span>        palette<span class="token punctuation">.</span>setColor<span class="token punctuation">(</span>QPalette<span class="token punctuation">.</span>Window<span class="token punctuation">,</span> QColor<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 将这组设置更新到当前的widgets中</span>        self<span class="token punctuation">.</span>setPalette<span class="token punctuation">(</span>palette<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        tabs <span class="token operator">=</span> QTabWidget<span class="token punctuation">(</span><span class="token punctuation">)</span>        tabs<span class="token punctuation">.</span>setDocumentMode<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        tabs<span class="token punctuation">.</span>setTabPosition<span class="token punctuation">(</span>QTabWidget<span class="token punctuation">.</span>East<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 控制标签所在的位置，右侧</span>        tabs<span class="token punctuation">.</span>setMovable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        cs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"red"</span><span class="token punctuation">,</span> <span class="token string">"green"</span><span class="token punctuation">,</span> <span class="token string">"blue"</span><span class="token punctuation">,</span> <span class="token string">"yellow"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> n<span class="token punctuation">,</span> color <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>cs<span class="token punctuation">)</span><span class="token punctuation">:</span>            tabs<span class="token punctuation">.</span>addTab<span class="token punctuation">(</span>Color<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>tabs<span class="token punctuation">)</span>app <span class="token operator">=</span> QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>win <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>win<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/stacklayout2.gif"><br></p><h1 id="对话框">对话框</h1><p>用于和用户交流，比如打开保存文件、设置或者其他不会在主窗口实现的内容。Qt实现了一系列常用的对话框类型。</p><p>作为对话框的基本class是<code>QDialog</code>，其接受的参数是其父元素（其依附的窗口）：</p><p>我们可以有以下代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py example26.py</span><span class="token keyword">import</span> sys<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtWidgets <span class="token keyword">as</span> qtw<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtCore <span class="token keyword">as</span> qtc<span class="token keyword">import</span> PyQt5<span class="token punctuation">.</span>QtGui <span class="token keyword">as</span> qtg<span class="token keyword">class</span> <span class="token class-name">CustomDialog</span><span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QDialog<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>CustomDialog<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"HELLO!"</span><span class="token punctuation">)</span>        QBtn <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QDialogButtonBox<span class="token punctuation">.</span>Ok <span class="token operator">|</span> qtw<span class="token punctuation">.</span>QDialogButtonBox<span class="token punctuation">.</span>Cancel        self<span class="token punctuation">.</span>buttonBox <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QDialogButtonBox<span class="token punctuation">(</span>QBtn<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>buttonBox<span class="token punctuation">.</span>accepted<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>accept<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>buttonBox<span class="token punctuation">.</span>rejected<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>reject<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layout <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QVBoxLayout<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>layout<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>self<span class="token punctuation">.</span>buttonBox<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setLayout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>layout<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 这里使用面向对象的方法</span><span class="token keyword">class</span> <span class="token class-name">MainWindow</span><span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QMainWindow<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>MainWindow<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setWindowTitle<span class="token punctuation">(</span><span class="token string">"My Awesome App"</span><span class="token punctuation">)</span>        label <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"This is a PyQt5 window!"</span><span class="token punctuation">)</span>        label<span class="token punctuation">.</span>setAlignment<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>Qt<span class="token punctuation">.</span>AlignCenter<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setCentralWidget<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        toolbar <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QToolBar<span class="token punctuation">(</span><span class="token string">"My Main toolbar"</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>setIconSize<span class="token punctuation">(</span>qtc<span class="token punctuation">.</span>QSize<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addToolBar<span class="token punctuation">(</span>toolbar<span class="token punctuation">)</span>        button_action <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"Your button"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setStatusTip<span class="token punctuation">(</span><span class="token string">"This is you button"</span><span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setShortcut<span class="token punctuation">(</span>qtg<span class="token punctuation">.</span>QKeySequence<span class="token punctuation">(</span><span class="token string">"Ctrl+p"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addSeparator<span class="token punctuation">(</span><span class="token punctuation">)</span>        button_action2 <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QAction<span class="token punctuation">(</span>            qtg<span class="token punctuation">.</span>QIcon<span class="token punctuation">(</span><span class="token string">"bug.png"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"You button2"</span><span class="token punctuation">,</span> self        <span class="token punctuation">)</span>        button_action2<span class="token punctuation">.</span>triggered<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>self<span class="token punctuation">.</span>onMyToolBarButtonClick<span class="token punctuation">)</span>        button_action<span class="token punctuation">.</span>setCheckable<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QLabel<span class="token punctuation">(</span><span class="token string">"Hello"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        toolbar<span class="token punctuation">.</span>addWidget<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QCheckBox<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        menu <span class="token operator">=</span> self<span class="token punctuation">.</span>menuBar<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>setStatusBar<span class="token punctuation">(</span>qtw<span class="token punctuation">.</span>QStatusBar<span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">)</span>        file_menu <span class="token operator">=</span> menu<span class="token punctuation">.</span>addMenu<span class="token punctuation">(</span><span class="token string">"&amp;File"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># &amp;使得此Menu可以有alt来控制</span>        file_menu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 为file menu添加一个按钮</span>        file_menu<span class="token punctuation">.</span>addSeparator<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 添加一个分割线</span>        file_menu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action2<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 添加第二个按钮</span>        file_submenu <span class="token operator">=</span> file_menu<span class="token punctuation">.</span>addMenu<span class="token punctuation">(</span><span class="token string">"Submenu"</span><span class="token punctuation">)</span>        file_submenu<span class="token punctuation">.</span>addAction<span class="token punctuation">(</span>button_action2<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">onMyToolBarButtonClick</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"click"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 主要改动在这里</span>        dlg <span class="token operator">=</span> CustomDialog<span class="token punctuation">(</span>self<span class="token punctuation">)</span>        <span class="token keyword">if</span> dlg<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Success!"</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Cancel!"</span><span class="token punctuation">)</span>app <span class="token operator">=</span> qtw<span class="token punctuation">.</span>QApplication<span class="token punctuation">(</span>sys<span class="token punctuation">.</span>argv<span class="token punctuation">)</span>window <span class="token operator">=</span> MainWindow<span class="token punctuation">(</span><span class="token punctuation">)</span>window<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>app<span class="token punctuation">.</span>exec_<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/dialog.gif"><br></p><p>注意：</p><ol type="1"><li><p>QDialog的启动形式和我们的application很像，因为它毕竟是一个新的窗口，也需要一个event loop。</p></li><li><p>开启QDialog的event loop后，其会阻塞主窗口的event loop，这个问题需要使用多线程来解决。</p></li><li><p>这里创建dialog按钮的方式有点异类，这里使用Qt准备好的一些flags来创建的，这些flags有以下：</p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-18-39-26.png"><br></p><p><img src="/2020/06/06/pylearning/pyqt5/pyqt5-tutorial-martin-ch1/pyqt5-tutorial-Martin-ch1_2020-06-07-18-39-39.png"><br></p><p>这种做法的好处在于可以将多个button的行为捏合到一个button对象上。之后再去将其不同的signals映射到不同的slots即可。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PyQt </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena Python-APIs</title>
      <link href="/2020/06/05/tools/ucsc/ucsc-python/"/>
      <url>/2020/06/05/tools/ucsc/ucsc-python/</url>
      
        <content type="html"><![CDATA[<blockquote><p>因为网连不上，所以就放弃这一部分了</p></blockquote><p>UCSC Xena官方提供了一个包--xenaPython，可以使用python程序来获得UCSC Xena的数据。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-deepNF预测蛋白质功能-2018</title>
      <link href="/2020/06/03/paper/omics/deepnf2018/"/>
      <url>/2020/06/03/paper/omics/deepnf2018/</url>
      
        <content type="html"><![CDATA[<h1 id="deepnf-deep-network-fusion-for-protein-function-prediction">deepNF: deep network fusion for protein function prediction</h1><ul><li>杂志: Bioinformatics</li><li>IF: 4.531(2018)</li><li>分区: 2区</li><li><a href="https://github.com/VGligorijevic/deepNF" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><h3 id="早期研究">早期研究</h3><ol type="1"><li><p>自动化蛋白质功能预测能够提高我们的效率，特别是在高通量分子组学诞生后，一些网络（蛋白质交互网络PPI、基因交互网络、基因共表达网络、代谢网络等）被发现。从这些网络中提取拓扑特性可能是理解蛋白质功能的重要一环，原因如下：</p><ul><li>相同功能的蛋白质可能是相互作用的【Sharan et al., 2007】；</li><li>相同功能的蛋白质可能在交互网络中有相似的拓扑属性【Milenkovic and Przulj, 2008】；</li><li>相同功能的蛋白质可能属于同一个复合物或pathway【Chen et al., 2014】。</li></ul></li><li><p>CAFA【Radivojac et al., 2013】和MouseFunc【Pena-Castillo ~ et al., 2008】代表了一类尝试，其利用了大量的数据（network、sequence、structure等）来进行功能预测，这会优于只使用单个数据的方法【Cozzetto et al., 2013; Lanckriet et al., 2004; Wass et al., 2012】，但整合多种数据造成的复杂性和稀疏性也带来了挑战。本研究专注于network-based features的integration，更容易得到一般性的结论，并且容易和其他工作进行比较。</p></li><li><p>早期的network integration的研究：</p><ul><li>Bayesian inference【Franceschini et al., 2013; Lee et al., 2011】；</li><li>kernel-based methods【Yu et al., 2015】，如GeneMANIA【Mostafavi et al., 2008; Mostafavi and Morris, 2012】；</li></ul><p>上述方法会首先将多个来源的往来进行合并，整合成一个网络，然后再输入基于graph kernel的supervised或semi-supervised model去进行训练，这使得网络合并的时候可能损失了一些信息【Cho et al. (2016)】。</p><ul><li>【Yan et al., 2010】在每个网络上训练一个classifier，然后使用ensemble learning的方法来将这些预测合并</li></ul><p>但这样的方法又不能考虑到不同网络间的相互关系。</p><p>另外，这些方法还面临诸多问题：</p><ul><li>网络的层次关系【Barutcuoglu et al., 2006】；</li><li>negative examples（没有指定功能的proteins）【Youngs et al., 2013】；</li><li>不完整的功能注释【Gligorijevic et al., 2014】。</li></ul></li></ol><h3 id="相关工作">相关工作</h3><p>Mashup【Cho et al., 2016】，可以克服fusing noisy和网络不完整的问题。流程为：</p><ul><li>matrix factorization得到低维表示；</li><li>使用SVM训练classifier预测功能标签。</li></ul><p>这项工作重要的地方在于feature learning的过程（也称为network embedding）。但挑战也在于此，方法必须能够将network structure中的connectivity patterns学习到，基于：</p><ul><li>homophily（在网络中的距离）</li><li>其局部的连接模式，与在网络中的位置无关</li></ul><p>而且学习到的特征在不同的蛋白质交互作用网络中是一致的。</p><p>实际上之前一些network embedding的方法，比如node2vec【Grover and Leskovec, 2016】和DeepWalk【Perozzi et al., 2014】，都是使用的一些shallow、linear的技术来实现的，这可能在捕捉非线性能力方面存在不足。</p><blockquote><p>但实际上这两种方法都是node embedding的方法，不是network embedding的方法<br>但细一想，这篇文章的任务是学习蛋白质的低维表示，蛋白质确实是node，没错。只是他也把这个叫做network embedding而已。</p></blockquote><p>基于当前Deep Learning技术的成功，一系列基于DNNs的方法【Cao et al., 2016; Grover and Leskovec, 2016; Wang et al., 2016】应运而生，而且在link prediction、network clustering、multi-label classification等领域取得了进步，但还没有研究致力于多种不同network类型的数据的整合。</p><h3 id="本文概述">本文概述</h3><p>所以本研究提出了deep Network Fusion（deepNF）--一个整合多种网络数据学习蛋白质低维表示的方法：</p><ul><li>能蹦捕捉多种PPI networks的复杂的topological patterns；</li><li>用于预测蛋白质的功能标签。</li></ul><p>其使用分开的layers来分别学习不同的network types，然后使用deep AEs的架构将其融合到bottleneck layer的features中，最后使用SVM来进行预测。</p><p>deepNF的优势：</p><ul><li>能够捕捉非线性特征，学习到的特征丰富；</li><li>能够处理noisy links，因为AEs被证明有降噪的效果【Vincent et al., 2010】；</li><li>可扩展，因为其特征学习的过程是无监督的。而且可以轻松地扩展到semi-supervised领域。</li></ul><p>本研究将deepNF应用到human和yeast的STRING networks中来学习低维表示，使用GO annotation（2015）作为training label，并在GO annotation（2017）上进行验证。并和Mashup、GeneMANIA进行了比较，发现deepNF有显著的性能提升。</p><h2 id="methods">Methods</h2><p><span class="math inline">\(N=6\)</span>表示不同的undirected weighted STRING networks，使用矩阵表示</p><p><span class="math display">\[\left\{\mathbf{A}^{(1)}, \mathbf{A}^{(2)}, \ldots, \mathbf{A}^{(N)}\right\}\]</span></p><p>每个矩阵有<span class="math inline">\(n\)</span>个proteins，我们希望学习到一个<span class="math inline">\(d_c\)</span>维的特征，其中<span class="math inline">\(d_c&lt;&lt;n\)</span>。有下列3个步骤：</p><ul><li>使用Random Walk with Restarts（RWR）和Positive Pointwise Mutual Information（PPMI）来捕捉networks中的结构信息；</li><li>使用AEs来融合PPMI matrices，提取低维特征；</li><li>使用SVM基于低维特征来预测功能标签。</li></ul><h3 id="rwr-ppmi表示">1. RWR-PPMI表示</h3><p>这里之所以选择RWR而不是node2vec和DeepWalk中的采样过程，是因为RWR计算更加方便、不需要额外的超参数调整。</p><ol type="1"><li><p>进行Random Walk：</p><p><span class="math display">\[\mathbf{p}_{i}^{(t)}=\alpha \mathbf{p}_{i}^{(t-1)} \widehat{\mathbf{A}}+(1-\alpha) \mathbf{p}_{i}^{(0)}\]</span></p><p><span class="math inline">\(\mathbf{p}_i^{(0)}\)</span>是一个one-hot向量，其第<span class="math inline">\(i\)</span>个元素是1。<span class="math inline">\(\alpha\)</span>表示重启概率，用来控制其学习的特征是局部的还是全局的。是row-wise normalization后的邻接矩阵。</p><blockquote><p>这里的意思是从某个点出发进行随机游走，则得到的sequence可以作为该点的特征</p></blockquote></li><li><p>基于【Cao et al. (2016)】的操作，计算<span class="math inline">\(\mathbf{r}_i\)</span>和<span class="math inline">\(\mathbf{R}\)</span></p><p><span class="math display">\[\mathbf{r}_{i}=\sum_{t=1}^{T} \mathbf{p}_{i}^{(t)}\]</span></p><p><span class="math inline">\(T\)</span>表示RW的步数，将所有的节点的<span class="math inline">\(\mathbf{r}_i\)</span>组合形成<span class="math inline">\(\mathbf{R}\)</span>。</p><blockquote><p>表示的是在整个游走期间，到达某一点的"概率"。</p></blockquote><p>当<span class="math inline">\(\alpha=1\)</span>的时候</p><p><span class="math display">\[\mathbf{R}=\widehat{\mathbf{A}}+\widehat{\mathbf{A}}^{2}+\cdots+\widehat{\mathbf{A}}^{T}\]</span></p><blockquote><p>其中<span class="math inline">\(\widehat{\mathbf{A}}^k\)</span>是k阶邻接矩阵，即经过k次通路后是否相连。</p></blockquote><p>所以，<span class="math inline">\(\mathbf{R}\)</span>表示了network的高阶连接特性。</p></li><li><p>基于<span class="math inline">\(\mathbf{R}\)</span>计算每个节点的PPMI表示</p><p><span class="math display">\[\mathbf{X}_{l m}^{(j)}=\max \left(0, \log _{2}\left(\frac{\mathbf{R}_{l m}^{(j)} \sum_{l} \sum_{m} \mathbf{R}_{l m}^{(j)}}{\sum_{l} \mathbf{R}_{l m}^{(j)} \sum_{m} \mathbf{R}_{l m}^{(j)}}\right)\right)\]</span></p><p>其中<span class="math inline">\(j\)</span>表示network<span class="math inline">\(j\)</span>。注意到，这个步骤可以直接在原始邻接矩阵上使用，但经过上两步可以减弱矩阵的稀疏性。</p><blockquote><p>MI就是<span class="math inline">\(p(x,y)\)</span>和<span class="math inline">\(p(x)p(y)\)</span>的KL散度（相对熵），表示为<span class="math inline">\(\mathbb{E}_{p(x,y)}[\log{\frac{p(x,y)}{p(x)p(y)}}]\)</span>。可以看得出来，上面的公式就是一个典型的MI。<span class="math inline">\(R_lm\)</span>表示的是在<span class="math inline">\(l\)</span>（或<span class="math inline">\(m\)</span>）的RW上出现<span class="math inline">\(m\)</span>（或<span class="math inline">\(l\)</span>）的概率，所以经过归一化后可以看做是<span class="math inline">\(p(x,y)\)</span>，而分母可以看做是边际概率的乘积。MI是这些项的期望，则其每一项将都可以看做是<strong>每对点对所有点间相关性（即MI）的贡献</strong>。</p></blockquote></li></ol><h3 id="使用aes整合networks">2. 使用AEs整合networks</h3><p>整个架构使用下图表示：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-00-08-56.png" alt="deepFN的流程图"><br></p><ul><li>输入：<span class="math inline">\(\mathbf{X}^{(j)} \in \mathbb{R}^{n \times n}\)</span>。</li><li>首先使用第一层，对每个网络分别提取器特征，激活函数是sigmoid。</li><li>第二层将得到的特征concat到一起，然后就是正常的NN的fc layers（L层），直到bottleneck layers，至此encoder结束。</li><li>decoder是encoder的镜像。</li><li>loss是binary cross entropy。</li><li>使用带有momentum的标准SGD进行训练，并探索了不同超参数（batchsize、lr、nums of hidden layers and units）的表现，结果在附录中。</li></ul><h3 id="预测蛋白质功能">3. 预测蛋白质功能</h3><ul><li><p>使用LIBSVM实现SVM来做分类，RBF kernel。</p></li><li><p>为了评价SVM的性能，使用了两种验证方式：</p><ul><li>5-CV：将有标记的proteins分为training和testing，在training set中内嵌一个5-CV来进行超参数调整（RBF kernel的<span class="math inline">\(\gamma\)</span>和正则化参数<span class="math inline">\(C\)</span>，grid search）。一共进行了10次交叉验证。</li><li>temporal holdout validation：将GO annotation在2015和2017中相同注释的proteins作为training set，将2015和2017不同注释的proteins作为validation，将2015没有但2017补充的annotations作为test。使用validation调整超参数，在test上使用bootstrap验证1000次得到结果。【Jiang et al., 2016; Radivojac et al., 2013】</li></ul></li><li><p>比较的方法：Mashup、GeneM，都使用了validation来进行超参数的调整。</p></li><li><p>评价指标：</p><ul><li>ACC</li><li>Micro-averaged F1 score【Cho et al. (2016)】</li><li>Micro-AUPR【Davis and Goadrich, 2006】</li></ul><blockquote><p>Macro是在类别的基础上平均，Micro是在样本的基础上进行平均。<br>Micro-AUPR指的是先把预测得分和标签都计算出来，然后将其concat到一起后计算一个AUPR值；Macro-AUPR是对每一个部分计算AUPR，然后平均。<br>f1 score是用下面的公式计算的： <span class="math display">\[F_{\beta}=\left(1+\beta^{2}\right) \frac{\text { precision } \times \text { recall }}{\beta^{2} \text { precision }+\text { recall }}\]</span> macro就是先计算每个类别的f1-score，然后平均；micro是先计算所有类别中的true positive、predicted positive、label positive，然后据此计算一个precision和recall，然后利用这两个计算f1-score。更加详细可见<a href="https://scikit-learn.org/stable/modules/model_evaluation.html" target="_blank" rel="noopener">sklearn的解释</a>。</p></blockquote></li></ul><h3 id="数据预处理">4. 数据预处理</h3><ul><li><p>yeast的功能注释（标签）来自MIPS，其被组织为3个levels：</p><ul><li>level1，17个最主要的功能分类</li><li>level2，74个功能分类</li><li>level3，153最特殊的功能分类</li></ul></li><li><p>human的功能注释来自GO，其分为3个大类：</p><ul><li>MF（molecular function）</li><li>BP（biological process）</li><li>CC（cellular component）</li></ul><p>也被分为3个levels：</p><ul><li>11-30：153 MFs，262 BPs，82 CCs；</li><li>31-100：72 MFs，100 BPs，48 CCs；</li><li>101-300：18 MFs，28 BPs，20 CCs。</li></ul><blockquote><p>关于GO的介绍，可以参见这篇<a href="https://hui-liu.github.io/blog/Gene-Ontology-GO-%E6%B3%A8%E9%87%8A/" target="_blank" rel="noopener">博客</a></p></blockquote></li><li><p><span class="math inline">\(N=6\)</span>，使用的这六类网络是：</p><ul><li>neighborhood</li><li>fusion</li><li>cooccurence</li><li>coexpression</li><li>experimental</li><li>database</li></ul></li></ul><h2 id="results">Results</h2><p>experiments的implementations：</p><ul><li><span class="math inline">\(\alpha=0.98\)</span>，<span class="math inline">\(T=3\)</span>，通过validation得到</li><li>AEs的架构和SVM的超参数也通过validation进行了搜索，其更详细的介绍再supplementary S3中</li></ul><h3 id="cv的结果">1. CV的结果</h3><p>在Yeast数据集上的结果如下图所示，使用的是5-layers的架构：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-14-54-14.png"><br></p><p>在human数据集上，使用的是7-layers架构，正文中只有MF的结果，BP和CC的结果在附录中：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-14-57-46.png"><br></p><p>下图中，比较了单个网络和多个网络整合的结果，网络整合还是要好于单个网络的：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-15-02-27.png"><br></p><h3 id="temporal-holdout-validation的结果">2. Temporal holdout validation的结果</h3><p>在Yeast和human数据集上的结果依次展现在下面：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-15-04-40.png" alt="Yeast"><br></p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-15-04-57.png" alt="Human"><br></p><p>下图展示了deepNF和Mashup在单个GO term上的效果：</p><p><img src="/2020/06/03/paper/omics/deepnf2018/deepNF2018_2020-06-04-15-08-01.png"><br></p><blockquote><p>还有许多的结果需要去看supplementary files，这里就不贴出来了。</p></blockquote><h2 id="conclusion">Conclusion</h2><p>未来，期望能够将deepNF进一步发展，可以将proteins sequences、structure数据考虑到。</p><hr><h2 id="questions">Questions</h2><ol type="1"><li>关于human的GO注释怎么分为3个levels的，没怎么看懂？</li><li>这里在实验的时候，是找的最好的architecture的deepNF和其他方法进行的比较，是不是不妥呀？</li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena 搜索-高亮-过滤-分组</title>
      <link href="/2020/06/03/tools/ucsc/ucsc-shfs/"/>
      <url>/2020/06/03/tools/ucsc/ucsc-shfs/</url>
      
        <content type="html"><![CDATA[<p>依靠上方的搜索框，可以完成一系列数据筛选工作，甚至可以创建自己的分组。</p><p><img src="/2020/06/03/tools/ucsc/ucsc-shfs/ucsc-shfs_2020-06-03-15-21-43.png"><br></p><p>我们可以在上面输入supported search terms，符合这些terms的样本将被高亮并使用black bar标记，然后就可以通过右侧的filter button下的不同的选择实现不同的功能：</p><ul><li><p><code>Filter</code>：将那些没有被高亮的样本移除。</p></li><li><p><code>Zoom</code>：方法这些被高亮的样本。</p></li><li><p><code>New column</code>：创建一个新的spreadsheet，其中被高亮的样本为True，不符合的样本为False，然后这个spreadsheet就可以用于接下来的分析（比如K-M plot等等）。</p><blockquote><p>可以选择spreadsheet下拉菜单中的display，将true和false改成其他的名称。</p></blockquote></li></ul><h1 id="支持的search-terms">支持的search terms</h1><ol type="1"><li><p>分类features：某个分类变量的level，比如Stage变量的'IIA'或'Stage IIA'。</p></li><li><p>连续features：必须使用"ABC..."来进行，"A:&gt;2"来选择大于2的样本，还有=、&gt;=、&lt;=、&lt;、&gt;、!=等。</p></li><li><p>对于mutation数据：</p><ul><li>找到所有存在protein change的mutations的样本：V600E</li><li>找到所有功能影响是'frame'或'nonsense'的样本：D:frame OR nonsense</li><li>找到所有TP53带有突变的样本：TP53</li><li>找到所有TP53不带突变的样本：!=TP53</li></ul></li><li><p>缺失值：</p><ul><li>所有没有缺失值的样本：!=null</li><li>只有一列（第二列）有缺失值的样本：B:!=null</li></ul></li><li><p>样本ID：TCGA-DB-A4XH。</p></li><li><p>A表示第一列、B表示第二列、...，A:YES表示第一列中值为YES的样本。</p></li><li><p>逻辑运算符（OR、AND），还可以配合括号来改变运算顺序："Stage II"(B:Negative OR C:Negative)，表示任何column中有"Stage II"并且第二列是Negative或第三列是Negative的样本。</p></li></ol><hr><p>FOXM1 RNAseq表达以10为分界进行分组，并绘制K-M plot：</p><p><img src="/2020/06/03/tools/ucsc/ucsc-shfs/subgroups.gif"><br></p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-VAE-2013</title>
      <link href="/2020/05/27/paper/dl/vae2013/"/>
      <url>/2020/05/27/paper/dl/vae2013/</url>
      
        <content type="html"><![CDATA[<h1 id="auto-encoding-variational-bayes">Auto-Encoding Variational Bayes</h1><ul><li>杂志: None</li><li>IF: None</li><li>分区: None</li><li><a href="https://github.com/luyiyun/VAE" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>对带有连续隐变量的概率图模型进行概率密度估计时，会存在一个难以处理的后验分布。variational bayesian（VB，或者叫做variational inference（VI），其最常见的实现是mean-field方法）可以进行近似推断。但现有的技术存在一些问题：</p><ul><li>类似mean-field的方法需要小心地选择使用的函数，使得变分下界（variational lower bound，或者evidence lower bound，ELBO）有精确解。</li><li>使用Monte Carlo方法来估计ELBO或ELBO的梯度（ELBO本质上是一个期望）可以避免精确解的需求，但现有的方法的估计方差比较大，使得后验估计或随之而来的参数学习过程无法有效的完成。</li></ul></li><li><p>本研究介绍了一种基于recognition model的Monte Carlo方法来进行后验估计，称为<strong>SGVB</strong>。其将ELBO参数化，并通过重参数化技巧降低了Monte Carlo估计的方差，可以使用随机梯度下降算法进行训练。</p><blockquote><p>这实际上就是概率图模型的inference</p></blockquote></li><li><p>更进一步，将信息编码理论（自编码器）和SGVB结合，本研究进一步提出了<strong>AEVB</strong>算法。其可以利用SGVB的后验估计能力进行概率图模型的参数学习，比iterative inference方法（如MCMC）更加有效率，得到的模型可以用于识别、去噪、表示、可视化等多种任务。</p><blockquote><p>这里指的实际上是概率图模型的learning</p><p>当AEVB方法是使用神经网络（NN）实现时，即我们熟知的<strong>variational autoencoder（VAE）</strong>算法。</p></blockquote></li></ol><p><em>为了能够对本文有更好的认识，需要以下的背景知识</em></p><h3 id="先验和后验分布">1. 先验和后验分布</h3><p>在bayes统计中，有先验和后验的概念：</p><p><span class="math display">\[p(H=h|X) = \frac{p(X|H=h)p(H=h)}{\int{p(X|H=s)p(H=s)}ds} \tag{1}\]</span></p><p>其中<span class="math inline">\(p(H|X)\)</span>为后验分布（posterior），<span class="math inline">\(p(H)\)</span>为先验分布（prior），<span class="math inline">\(p(X|H)\)</span>为似然函数（likelihood），如果是有多个iid样本的话，其一般表示为<span class="math inline">\(\prod_{i=1}^N{p(X=x_i|H)}\)</span>，分母的部分被称为证据（evidence）。bayes统计的关键在于如何在已知先验、似然函数的基础上来得到后验，计算方式就来自上面的公式。但在以上计算式中，分母通常难以得到：</p><ul><li>对于高维的<span class="math inline">\(H\)</span>，我们无法通过近似离散方法得到。</li><li>而对于比较复杂的似然函数和先验分布形式，我们也无法得到精确解（甚至有时候似然函数和先验分布的精确形式也无法得到）。</li></ul><p>所以必须使用一些inference的方法来进行推断。</p><h3 id="隐变量模型">2. 隐变量模型</h3><p>典型的隐变量模型有：GMM（高斯混合模型）、HMM（隐马尔可夫）等。通常隐变量模型可以看做是一个有向图模型，其中箭头由隐变量指向显变量表示了数据的生成方式。</p><p>我们有显变量<span class="math inline">\(X\)</span>，其分布依赖于一些隐变量<span class="math inline">\(H\)</span>，由隐变量得到显变量的关系式为<span class="math inline">\(p(X|H)\)</span>，如果这个关系式未知，则需要使用参数化的函数<span class="math inline">\(p_{\theta}(X|H)\)</span>来表示，并且需要学习到这个参数<span class="math inline">\(\theta\)</span>。如果套用图概率模型的概念，则我们一般需要做两个任务：</p><ul><li><p>inference：已知<span class="math inline">\(X=x_i\)</span>，其对应的隐变量的分布是什么：<span class="math inline">\(p(H|X=x_i)\)</span>。</p></li><li><p>learning：寻找参数<span class="math inline">\(\theta^{\star}\)</span>，使得满足下面的边际似然最大化：</p><p><span class="math display">\[\theta^{\star}=\arg\min_{\theta}{\log{p_{\theta}(X)}} \tag{2}\]</span></p></li></ul><p>显然，对于inference，和bayes统计中的问题是一致的：隐变量分布即<span class="math inline">\(H\)</span>，显变量即<span class="math inline">\(X\)</span>，<span class="math inline">\(p(X|H)\)</span>即似然。</p><p>至于learning，在解决了inference后，一般也比较容易解决，毕竟边际似然可以比较容易地由后验来表示：</p><p><span class="math display">\[\log{p_{\theta}(X)} = \log{p_{\theta}(X|H)}+\log{p(H)}-\log{p_{\theta}(H|X)} \tag{3}\]</span></p><blockquote><p>后面我们会看到，使用VI，inference和learning将会走到相同的思路上去，我们同时解决了这两个问题。</p><p>当然，有很多模型设计的时候就尽量让模型的训练不依赖于后验估计，这是因为后验估计本身很难，所以其learning的算法和后验估计是没有关系的。</p></blockquote><h3 id="mcmc">3. MCMC</h3><p>MCMC是进行后验推断的最重要的方法，特别是在bayes统计领域（<em>MCMC拯救了bayes估计</em>）。</p><p>为什么MCMC能够进行进行后验估计？我们需要先简单了解一下MCMC的过程（这里是最简单的Metropolis算法，Metropolis-Hastings算法和他类似，另外的算法也都跑不出其框架）:</p><blockquote><p>target distribution：<span class="math inline">\(p(X)\)</span><br>proposed distribution：<span class="math inline">\(q(X)\)</span>，任意分布</p><p>第一步：随机一个初始值<span class="math inline">\(X=x_0\)</span>，只要让<span class="math inline">\(p(X=x_0)\ne0\)</span>即可。</p><p>第二步：使用<span class="math inline">\(q(X)\)</span>得到一个随机的点<span class="math inline">\(x'_i\)</span>。</p><p>第三步：计算transition probability：</p><p><span class="math display">\[p_{move}=\min(\frac{p(x'_i)}{p(x_i)}, 1) \tag{4}\]</span> 其中<span class="math inline">\(p(x_i)\)</span>是当前所在的点。依据此概率来判断是否接受<span class="math inline">\(x'_i\)</span>作为<span class="math inline">\(x_{i+1}\)</span>，否则<span class="math inline">\(x_{i+1}=x_{i}\)</span>。</p><p>回到第二步。</p></blockquote><p>现在我们的目标分布是<span class="math inline">\(p(H|X)\)</span>，当把它代入上面的transition probability的计算的时候，我们发现，<strong>分母上的积分式被约掉了，我们只需要能够计算似然和先验就可以进行MCMC采样了。</strong></p><p>这也就是为什么MCMC可以进行后验推断的原因。</p><p>现实应用的时候，Metropolis或Metropolis-Hastings算法效率非常低，需要使用Gibbs算法或Hamilton算法来替代，但本质上原理是一样的。</p><p>MCMC的优点：</p><ul><li>无偏估计</li><li>适用性强，只要能够写出似然函数即可</li></ul><p>MCMC的缺点：</p><ul><li>太慢了</li><li>采集的样本也不能直接用，必须要做一些处理，比如降低其自相关性、预烧期等等，而这些处理并不是容易</li></ul><h3 id="变分推断">4. 变分推断</h3><p>后验推断的另一种思路，是使用一个可学习的参数化分布（<span class="math inline">\(q_{\phi}(H)\)</span>）去逼近后验分布。这里使用KL散度来度量两个分布间的相似程度。</p><p>由上面的公式<span class="math inline">\((2)\)</span>，我们可以得到：</p><p><span class="math display">\[\log{p(X)} = \log{\frac{p(X|H)}{q_{\phi}(H)}}+\log{p(H)}-\log{\frac{p(H|X)}{q_{\phi}(H)}}\]</span></p><p>等式两边对<span class="math inline">\(q_{\phi}(H)\)</span>做期望，得到：</p><p><span class="math display">\[\begin{aligned}\log{p(X)}&amp;=-D_{KL}(q_{\phi}(H)|p(X|H))+E_{q_{\phi}}[\log{p(H)}]+D_{KL}(q_{\phi}(H)|p(H|X))  \\&amp;=\mathbb{E}_{q_{\phi}}[\log{p(X,H)}-\log{q_{\phi}(H)}]+D_{KL}(q_{\phi}(H)|p(H|X))\end{aligned}\tag{5}\]</span></p><p>等式左边是关于<span class="math inline">\(\phi\)</span>不变的，所以如果希望最小化<span class="math inline">\(D_{KL}(q_{\phi}(H)|p(H|X))\)</span>，只需要最大化下面的东西即可，这个就是<strong>ELBO(evidence lower bound)</strong>：</p><p><span class="math display">\[\begin{aligned}ELBO&amp;=-D_{KL}(q_{\phi}(H)|p(X|H))+E_{q_{\phi}}[\log{p(H)}] \\&amp;=\mathbb{E}_{q_{\phi}}[\log{p(X,H)}-\log{q_{\phi}(H)}]\end{aligned} \tag{6}\]</span></p><blockquote><p>以上结果也可以通过Jessen不等式得到<br>另外，还有研究从weighted sampling的角度来理解VAE，同样可以推导出上面的结果</p></blockquote><p>现在问题就变成了如何最小化ELBO，这时候，<span class="math inline">\(q_{\phi}(H)\)</span>的选择就变得格外重要了，其必须要满足以下两个方面：</p><ul><li><p>足够简单，可以保证ELBO可以计算出来</p><blockquote><p>注意到，ELBO本质上是一个期望，所以可以使用Monte Carlo方法来估计从而避免显式的去求期望，但此时需要可以对<span class="math inline">\(q_{\phi}(H)\)</span>采样。</p></blockquote></li><li><p>足够复杂，能够比较好的拟合后验分布。</p></li></ul><p>这时候，大家传统的选择是mean-field，即使用相互独立的多个分布组成的高维分布来做<span class="math inline">\(q_{\phi}(H)\)</span>。</p><h3 id="平均场">5. 平均场</h3><blockquote><p>关于mean-field的详细公式推导这里就不写了，之后会辟出单独的篇章来讨论。</p></blockquote><p>在保证了似然函数是简单的（指数分布簇）的前提下，我们可以使用多个相互独立的低维分布组成的高维分布作为<span class="math inline">\(q_{\phi}(H)\)</span>，这有下面的优点：</p><ul><li>可以构造很高维的分布，对于高维的<span class="math inline">\(H\)</span>也可以完成拟合。</li><li>尽管每个独立的组分是简单的，但只要其是参数化的，其组合而成的高维分布依然是有一定的拟合能力的。</li><li>只要每个组分是简单的（指数族分布），那么不管有多少个组分，都可以迭代的、显式的将ELBO计算出来，从而完成inference。</li><li>显式的计算出ELBO，意味着没有使用Monte Carlo估计，自然其相关的缺点也没有（估计有误差等等）。</li></ul><p>但是其缺点也是显然的：</p><ul><li>显然<span class="math inline">\(q_{\phi}(H)\)</span>能够拟合的函数的范围也非常有限。</li><li>要求似然函数比较简单，容易计算，这在很多模型中无法办到。</li></ul><p><strong>本文使用Monte Carlo估计的方法来克服上述缺点，并且尽量规避了Monte Carlo估计自身所带来的缺点</strong></p><h2 id="methods">Methods</h2><h3 id="问题">1. 问题</h3><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-09-04-25.png" alt="概率模型"><br></p><p>现在将讨论的范围限制在下面的区域内（如上图所示的模型）：</p><p>数据集为<span class="math inline">\(X=\{x^{(i)}\}_{i=1}^N\)</span>，是iid的，假设数据由某个未观测到的连续变量<span class="math inline">\(z\)</span>生成，其有两个步骤：</p><ol type="1"><li><span class="math inline">\(z\)</span>从某个先验的分布<span class="math inline">\(p_{\theta}(z)\)</span>得到；</li><li><span class="math inline">\(x^{(i)}\)</span>由条件概率<span class="math inline">\(p_{\theta}(x|z)\)</span>得到。</li></ol><p>另外假设这两个分布都是可以参数化的（<span class="math inline">\(\theta\)</span>），而且对于参数是可导的。在此之外，不再增加额外的假设。</p><blockquote><p>假设这些分布可以由NN参数化，则就使用NN构建模型；假设这些分布可以由线性模型参数化，则使用线性函数构建模型......</p></blockquote><p>现在，我们希望构建一个模型，得到下面的结果：</p><ol type="1"><li>每个iid样本都有一个对应的隐变量；</li><li>使用maximum likelihood（ML，实际上最大化的是边际似然）和 maximum a posteriori（MAP）来估计参数<span class="math inline">\(\theta\)</span>；</li><li>使用变分推断来估计隐变量。</li></ol><p>我们会面临两个问题：</p><ul><li>Intractability：边际似然<span class="math inline">\(p(X)\)</span>不好算、后验分布不好算、似然函数很复杂（比如是一个NN）导致传统的mean-field用不了。</li><li>large dataset：大数据，所以batch optimization无法做到，凡是基于采样的方法也无法做到。</li></ul><p>我们希望得到的解决方法具有下面的特点：</p><ul><li>能够进行高效地ML或MAP，估计<span class="math inline">\(\theta\)</span>，从而model可以进行数据生成；</li><li>能够高效地估计给定<span class="math inline">\(x\)</span>的后验分布<span class="math inline">\(z\)</span>，从而可以对数据进行编码或表示学习；</li><li>能够得到<span class="math inline">\(x\)</span>的边际估计，从而可以进行降噪、补全或超分辨率操作。</li></ul><p>为了能够得到上面的特性，这里引入一个recognition model<span class="math inline">\(q_{\phi}(z^{(i)}|x^{(i)})\)</span>，来逼近真实后验。需要注意到，这里的<span class="math inline">\(q_{\phi}(z^{(i)}|x^{(i)})\)</span>不需要有mean-field的独立性假设和closed-form expectation，比如可以是一个NN。</p><p><strong>注意到现在我们是希望为每个样本求各自的后验分布。</strong></p><blockquote><p>如果熟悉贝叶斯统计可能知道，为每个对象或单位都搞一个后验，一般出现在层次模型中（Hierarchical Models）：</p><blockquote><p>一个人<span class="math inline">\(n\)</span>的血压服从一个分布<span class="math inline">\(x^i_n\sim p(x^i_n|x_n)\)</span>，比如是gaussian。自然这个分布有参数--个人的血压平均值<span class="math inline">\(x_n\)</span>，其服从另一个分布--所有人的血压平均值分布<span class="math inline">\(x_n\sim p(x_n|x)\)</span>（假设其还是服从一个gaussian）。这个分布依然有一个参数（可以看做是全世界人的血压平均值），这个参数服从一个先验分布<span class="math inline">\(x\sim p(x)\)</span>。</p></blockquote><p>这里就要涉及到关于贝叶斯估计的一个问题：显然我们可以将“分布的参数的分布”这个过程无限套娃下去，那到底套娃多少次呢？</p><p>这个问题的关键在于我们的任务想要回答什么的问题。</p><ul><li>一般来说，对于上面的血压的例子，我们希望知道所有人的血压平均值的分布<span class="math inline">\(x\)</span>的信息，则先验分布最多就设置到它的分布即可。所以上面的例子我们讨论到了<span class="math inline">\(x\sim p(x)\)</span>。 <span class="math display">\[x^i_n\sim p(x^i_n|x_n) \quad x_n\sim p(x_n|x) \quad x\sim p(x)\]</span> 以下是我们想要得到的后验： <span class="math display">\[x\sim p(x|\{x^i_n|i\in I_n,n\in N\})\]</span> 其中<span class="math inline">\(I_n\)</span>和<span class="math inline">\(N\)</span>表示第n个人的样本指标集合和所有人的指标集合。</li><li>但有时候，我们希望得到的只是每个人的血压平均值的分布<span class="math inline">\(x_n\sim p(x_n)\)</span>，则我们就把先验设置到此为止就好了。这时候可以为每个人的血压平均值分布设置相同的先验，也可以为每个人设置不同的先验。此时我们的模型是这样的： <span class="math display">\[x_n^i\sim p(x_n^i|x_n) \quad x_n\sim p(x_n)\]</span> 或者 <span class="math display">\[x_n^i\sim p(x_n^i|x_n) \quad x_n\sim p_n(x_n)\]</span> 我们得到的后验是： <span class="math display">\[x_n\sim p(x_n|\{x_n^i|i\in I_n,n\in N\})\]</span> 如果进一步假设各个人间是独立的，则对于<span class="math inline">\(x_n\)</span>有下面简化的后验（其只取决于自己的样本）： <span class="math display">\[x_n\sim p(x_n|\{x_n^i|i\in I_n\})\]</span></li></ul></blockquote><p>本文的情况和上述的第二种情况比较类似，即我们没有意愿去求解所有样本的隐变量所共同遵循的分布的性质，即下面的<span class="math inline">\(\bar{z}\)</span>的性质： <span class="math display">\[x^{(i)}_n\sim p(x_n^{(i)}|z^{(i)}_n)\quad z_n\sim p(z_n|\bar{z}) \quad \bar{z}\sim p(\bar{z})\]</span> 得到后验 <span class="math display">\[\bar{z}\sim p(\bar{z}|\{x_n^{(i)}\})\]</span> 我们仅仅关注于<span class="math inline">\(p(z^{(i)})\)</span>，所有是下面的模型： <span class="math display">\[x^{(i)}_n\sim p(x_n^{(i)}|z^{(i)}_n)\quad z_n\sim p(z_n)\]</span> 得到后验 <span class="math display">\[z_n\sim p(z_n|\{x_n^{(i)}\})\]</span> 这里<span class="math inline">\(z_n\)</span>只取决于其自己的样本。</p><p>另外，在本文中，一个<span class="math inline">\(z_n\)</span>只能对应一个样本<span class="math inline">\(x_n\)</span>，所以上面的大括号也不用加：</p><p><span class="math display">\[z_n\sim p(z_n|x_n)\]</span></p><blockquote><p><em>这里的符号、格式、上下标和文章中的不符，后面会改成和文章符合的格式</em> <span class="math display">\[z^{(i)} \sim p(z^{(i)}|x^{(i)})\]</span></p></blockquote><p>从编码理论上来看，<span class="math inline">\(q_{\phi}(z|x)\)</span>可以看做是一个encoder，而<span class="math inline">\(p_{\theta}(x|z)\)</span>可以看做是一个decoder。</p><h3 id="变分下界">2. 变分下界</h3><p>结合上面提到的关于单个样本的隐变量的讨论，以及式5，我们可以得到下面的公式（整体的边际似然可以是单个样本的似然的乘积，所以这里只针对单个样本的边际似然进行讨论）：</p><p><span class="math display">\[\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)=D_{K L}\left(q_{\boldsymbol{\phi}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right) \| p_{\boldsymbol{\theta}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right)\right)+\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) \tag{7}\]</span></p><p>其中ELBO可以写成：</p><p><span class="math display">\[\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right) \geq \mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)=\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})}\left[-\log q_{\boldsymbol{\phi}}(\mathbf{z} | \mathbf{x})+\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})\right] \tag{8}\]</span></p><p>或者另一个形式：</p><p><span class="math display">\[\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)=-D_{K L}\left(q_{\boldsymbol{\phi}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right) \| p_{\boldsymbol{\theta}}(\mathbf{z})\right)+\mathbb{E}_{q_{\boldsymbol{\phi}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right)}\left[\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} | \mathbf{z}\right)\right] \tag{9}\]</span></p><p>现在我们试着针对这个ELBO进行Monte Carlo梯度估计，但使用Monte Carlo梯度估计需要从带有参数<span class="math inline">\(\phi\)</span>的分布中采样，这会使得结果对于<span class="math inline">\(\phi\)</span>不可导。</p><blockquote><p>当然，还有另外的办法，也可以使用RL中的方法（如<code>pyro</code>的<a href="http://pyro.ai/examples/svi_part_iii.html" target="_blank" rel="noopener">tutorial</a>中给出了一个推导）：</p><p><span class="math display">\[\begin{aligned}  \nabla_{\phi} \mathbb{E}_{q_{\phi}(\mathbf{z})}\left[f_{\phi}(\mathbf{z})\right]&amp;=\nabla_{\phi} \int d \mathbf{z} q_{\phi}(\mathbf{z}) f_{\phi}(\mathbf{z})\\  &amp;=\int d \mathbf{z}\left\{\left(\nabla_{\phi} q_{\phi}(\mathbf{z})\right) f_{\phi}(\mathbf{z})+q_{\phi}(\mathbf{z})\left(\nabla_{\phi} f_{\phi}(\mathbf{z})\right)\right\} \\  &amp;=\mathbb{E}_{q_{\phi}(\mathbf{z})}\left[\left(\nabla_{\phi} \log q_{\phi}(\mathbf{z})\right) f_{\phi}(\mathbf{z})+\nabla_{\phi} f_{\phi}(\mathbf{z})\right]\end{aligned}\]</span></p><p>其中</p><p><span class="math display">\[\nabla_{\phi} q_{\phi}(\mathbf{z})=q_{\phi}(\mathbf{z}) \nabla_{\phi} \log q_{\phi}(\mathbf{z})\]</span></p><p>但这个方法得到的估计方差太大，很难使用，要不然就得采大量的样本来降低方差。针对此问题，本研究提出了一个更加有针对性的策略--即<strong>重参数化技巧</strong>。</p></blockquote><h3 id="sgvb估计器和aevb算法">3. SGVB估计器和AEVB算法</h3><h4 id="sgvb来最小化elbo">3.1 SGVB来最小化ELBO</h4><p>这里会产生两个版本的SGVB estimator：</p><ol type="1"><li><p>第一个版本，使用重参数化技巧对公式9进行处理，得到：</p><p>利用后面会介绍的reparameterization trick，可以将<span class="math inline">\(\phi\)</span>从期望里面移出来：</p><p><span class="math display">\[\widetilde{\mathbf{z}}=g_{\phi}(\boldsymbol{\epsilon}, \mathbf{x}) \quad with \quad \boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})\]</span></p><p>然后就可以使用Monte Carlo方法估计期望：</p><p><span class="math display">\[\mathbb{E}_{q_{\phi}\left(\mathbf{z} | \mathbf{x}^{(i)}\right)}[f(\mathbf{z})]=\mathbb{E}_{p(\boldsymbol{\epsilon})}\left[f\left(g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}, \mathbf{x}^{(i)}\right)\right)\right] \simeq \frac{1}{L} \sum_{l=1}^{L} f\left(g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}^{(l)}, \mathbf{x}^{(i)}\right)\right) \quad where \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon})\]</span></p><p>只需要使用这个技术，即得到了我们的SGVB estimator：</p><p><span class="math display">\[\begin{aligned} \widetilde{\mathcal{L}}^{A}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) &amp;=\frac{1}{L} \sum_{l=1}^{L} \log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}^{(i, l)}\right)-\log q_{\boldsymbol{\phi}}\left(\mathbf{z}^{(i, l)} | \mathbf{x}^{(i)}\right) \\ \text { where } \quad \mathbf{z}^{(i, l)} &amp;=g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}^{(i, l)}, \mathbf{x}^{(i)}\right) \quad \text { and } \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon}) \end{aligned} \tag{10}\]</span></p></li><li><p>第二个版本，对第一个版本的进一步细化。如果我们能够将式9中的KL散度显式的写出来，则我们只需要对后面那一项使用Monte Carlo采样估计即可：</p><p><span class="math display">\[\widetilde{\mathcal{L}}^{B}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right)=-D_{K L}\left(q_{\boldsymbol{\phi}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right) \| p_{\boldsymbol{\theta}}(\mathbf{z})\right)+\frac{1}{L} \sum_{l=1}^{L}\left(\log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} | \mathbf{z}^{(i, l)}\right)\right) \\ \text{where} \quad \mathbf{z}^{(i, l)}=g_{\boldsymbol{\phi}}\left(\boldsymbol{\epsilon}^{(i, l)}, \mathbf{x}^{(i)}\right) \quad \text{and} \quad \boldsymbol{\epsilon}^{(l)} \sim p(\boldsymbol{\epsilon}) \tag {11}\]</span></p></li></ol><h4 id="aevb算法极大化边际似然估计模型参数">3.2 AEVB算法极大化边际似然估计模型参数</h4><p>我们能够估计ELBO之后，就可以做极大边际似然了：</p><p><span class="math display">\[\mathcal{L}(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{X}) \simeq \widetilde{\mathcal{L}}^{M}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{X}^{M}\right)=\frac{N}{M} \sum_{i=1}^{M} \widetilde{\mathcal{L}}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) \tag{12}\]</span></p><p>其中<span class="math inline">\(M\)</span>是每个minibatch使用的样本的数量，<span class="math inline">\(N\)</span>表示对于每个样本进行Monte Carlo计算期望使用的采样数量，在实验中发现，<span class="math inline">\(N=1\)</span>就有不错的效果。整个过程可以通过SGD系列算法进行。</p><blockquote><p>这里，我的理解：正常的步骤，<br>第一步更新<span class="math inline">\(\phi\)</span>最大化ELBO，则此时使得后验的估计是准确的。在后验估计准确的情况下，ELBO等于边际似然。<br>第二步，更新<span class="math inline">\(\theta\)</span>最大化ELBO，此时等价于最大化边际似然。<br>以上两个步骤重复进行，类似EM。<br><strong>但我们又可以知道，如果交替训练可以找到最优点，则不交替训练也一定能找到最优点，所以我们直接一起训练反而能够找到更好的结果。</strong></p></blockquote><blockquote><p>在AEs的角度来看式6，我们能够看到其每一项的意义。<br>第一项是一个regularization，用来尽量保证后验和先验相同；<br>第二项是一个negative reconstruction loss。<br>即整个ELBO的含义在于，在保证后验估计和先验尽量相似的情况下，最小化重建误差；或者是在尽量缩小重建误差的情况下，最小化后验估计和先验的差距就能得到准确的后验估计。<br></p></blockquote><h3 id="重参数化技巧">4. 重参数化技巧</h3><p>其需要解决的问题：我们计算梯度的过程中需要进行采样，采样的分布上有我们需要估计的参数，则梯度流无法通过“采样”这个过程，所以无法进行估计。</p><p>解决方法：把需要采样的那个分布<span class="math inline">\(z\sim q_{\phi}(z|x)\)</span>表示成<span class="math inline">\(z=g_{\phi}(\epsilon, x)\text{,}\quad \epsilon\sim q(\epsilon)\)</span>，这样参数就被移出了采样过程。</p><p>示例：现在我们需要采样进行期望估计的分布为<span class="math inline">\(z \sim p(z | x)=\mathcal{N}\left(\mu, \sigma^{2}\right)\)</span>，则我们可以表示为<span class="math inline">\(z=\mu+\sigma\epsilon\)</span>，其中<span class="math inline">\(\epsilon\sim\mathcal{N}(0,1)\)</span>，这时我们发现实际上z还是服从原来的分布的，则我们会有下面的期望估计的变化：</p><p><span class="math display">\[\mathbb{E}_{\mathcal{N}\left(z ; \mu, \sigma^{2}\right)}[f(z)]=\mathbb{E}_{\mathcal{N}(\epsilon ; 0,1)}[f(\mu+\sigma \epsilon)] \simeq \frac{1}{L} \sum_{l=1}^{L} f\left(\mu+\sigma \epsilon^{(l)}\right) \\ \text { where } \epsilon^{(l)} \sim \mathcal{N}(0,1)\]</span></p><p>要能够使用重参数化技巧，意味着<span class="math inline">\(q_{\phi}(z|x)\)</span>必须满足一定的条件：</p><ol type="1"><li>可以知道<span class="math inline">\(q_{\phi}(z|x)\)</span>的inverse CDF。我们假设这个inverse CDF为<span class="math inline">\(g_{\phi}(\epsilon, x)\)</span>，则取<span class="math inline">\(\epsilon\sim\mathcal{U}(0,I)\)</span>即可。比如：Exponential, Cauchy, Logistic, Rayleigh, Pareto, Weibull, Reciprocal, Gompertz, Gumbel and Erlang distributions</li><li>像gaussian一样，其参数是location scale的，即表示的是平移、缩放。则可以表示<span class="math inline">\(g(.)=location+scale\cdot\epsilon\)</span>，其中<span class="math inline">\(\epsilon\)</span>服从那个在location=0、scale=1的那个分布。比如：Laplace, Elliptical, Student’s t, Logistic, Uniform, Triangular and Gaussian distributions</li><li>可以分解为不同的容易处理的组分的。比如：Log-Normal (exponentiation of normally distributed variable), Gamma (a sum over exponentially distributed variables), Dirichlet (weighted sum of Gamma variates), Beta, Chi-Squared, and F distributions</li></ol><h3 id="变分自编码器">5. 变分自编码器</h3><p><em>以上相对于为研究人员提供了一个框架。其中还没有假设<span class="math inline">\(p(z)\)</span>、<span class="math inline">\(p(z|x)\)</span>和<span class="math inline">\(p(z|x)\)</span>的形式。</em></p><p>以下便是最常用的一种：</p><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-00-04-21.png" alt="AEVB算法"><br></p><ol type="1"><li>认为latent variables的prior是独立的标准正态分布。<ul><li>了解贝叶斯统计的可以知道，如果样本量够大，样本的影响会基本彻底淹没先验的影响，这时候先验取什么对后验的影响是非常小的；</li><li>这个有点像岭回归，相对于只是起一个对隐变量的微小约束。如果没有这个约束，隐变量可以取任意的值，这显然不合理，而且估计的方差也会很大。从岭回归的角度，这相当于限制隐变量估计的方差。</li><li>对于一个没有任何其他知识的隐变量的估计，我们预先的认为其不会很大（这就是标准正态先验的含义）是合理的。</li></ul></li><li><span class="math inline">\(p_{\theta}(x|z)\)</span>是经过NN输出参数化的独立Gaussian或Bernoulli。</li><li>认为<span class="math inline">\(p_{\theta}(z|x)\)</span>是经过NN输出参数化的独立Gaussian。<ul><li>2和3的含义即认为确定的<span class="math inline">\(x\)</span>或<span class="math inline">\(z\)</span>对应的<span class="math inline">\(z\sim p(z|x)\)</span>或<span class="math inline">\(x\sim p(x|z)\)</span>依然是个分布，但是是一个在预测值周围震荡的gaussian或Bernoulli，这没有什么限制，毕竟是将其非线性变换后的（如果NN换成线性，不就是OLS和Logistic嘛）。</li></ul></li></ol><p>对于<span class="math inline">\(q_{\phi}(x|z)\)</span>的选择就随意多了，我们让它和<span class="math inline">\(p_{\theta}(x|z)\)</span>有相同的形式。所以在上面的2假设成立的情况下，则我们会得到最优解。如果上面的2假设不成立，那么我们也不会有太大的损失（比较前面有NN，使得我们能够拟合成一个Gaussian的机会大大增加了）(<em>不好理解就类比线性模型</em>)。</p><p>经过一阵推导，得到下面的loss公式：</p><p><span class="math display">\[\mathcal{L}\left(\boldsymbol{\theta}, \boldsymbol{\phi} ; \mathbf{x}^{(i)}\right) \simeq \frac{1}{2} \sum_{j=1}^{J}\left(1+\log \left(\left(\sigma_{j}^{(i)}\right)^{2}\right)-\left(\mu_{j}^{(i)}\right)^{2}-\left(\sigma_{j}^{(i)}\right)^{2}\right)+\frac{1}{L} \sum_{l=1}^{L} \log p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} | \mathbf{z}^{(i, l)}\right)\tag{13}\]</span></p><p><span class="math display">\[\text { where } \mathbf{z}^{(i, l)}=\boldsymbol{\mu}^{(i)}+\boldsymbol{\sigma}^{(i)} \odot \boldsymbol{\epsilon}^{(l)} \quad \text { and } \quad \boldsymbol{\epsilon}^{(l)} \sim \mathcal{N}(0, \mathbf{I})\]</span></p><p>loss的第二项根据数据的形式（continuous or binary）选择Gaussian或Bernoulli的形式。</p><blockquote><p>关于KL散度项的推导和后面的重构项在不同的情况下怎么计算，将在supplementary部分解释。</p></blockquote><h2 id="related-work">Related work</h2><ol type="1"><li>wake-sleep算法【HDFN95】是目前为止已知的和本研究一样general的continuous latent variables建模方法。其缺点是需要2-steps的optimization（有两个目标函数）。优点是可以应用于discrete latent variables。其计算复杂度和AEVB相当。</li><li>在Stochastic variational inference【HBWP13】的领域，一些研究通过限制一些技巧可以控制gradient estimator的方差【BJP12】、【RGB13】，而【SK13】使用了类似的重参数化技巧。</li><li>之前已经有相关研究【Row98】，探索PCA和ML的结合，相对于是使用linear AEs。</li><li>AEs方面的最新研究【VLL+10】，试图去最小化<span class="math inline">\(X\)</span>和<span class="math inline">\(Z\)</span>之间的MI，但这个regularization不如本文的方法自然；【BTL13】使用Markov Chain的样本来训练noisy的AEs。</li><li>【GMW13】、【RMW14】和本文类似的结果，但各研究之间是独立进行的。</li></ol><h2 id="experiments">Experiments</h2><p>在MNIST和Frey Face数据集上进行了实验，并和其他算法进行了比较。</p><p>在decoder的输出层是sigmoid，使之归一化到0-1。参数采样自<span class="math inline">\(\mathcal{N}(0, 0.01)\)</span>，使用Adagrad进行训练。minibatch size是100。对于MNIST，encoder hidden是500；对于Frey Face则是200。</p><ol type="1"><li><p>首先是lower bound的比较，AEVB能够得到更大的lower bound</p><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-00-48-14.png" alt="和wake-sleep的比较，看谁能得到更大的lower bound"><br></p></li><li><p>和MCMC EM方法、wake-sleep方法比较了一下边际似然，发现AEVB还是好的。</p><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-00-58-43.png" alt="边际似然的比较"><br></p></li><li><p>高维数据的可视化：</p><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-00-59-49.png"><br></p><p><img src="/2020/05/27/paper/dl/vae2013/vae2013_2020-05-28-01-00-00.png"><br></p></li></ol><h2 id="conclusion">Conclusion</h2><p>未来：</p><ul><li>CNNs；</li><li>时间序列数据；</li><li>应用到global paramters；</li><li>应用到supervised models。</li></ul><h2 id="supplementary">Supplementary</h2><h3 id="损失函数中kl散度项的求解">1. 损失函数中KL散度项的求解</h3><p>这里使用前面VAE的假设，即<span class="math inline">\(p(\mathbf{z})\)</span>独立标准正态，<span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})\)</span>是独立正态：</p><p><span class="math display">\[\begin{aligned}p(\mathbf{z})&amp;=\mathcal{N}(0, I) \\&amp;=\prod_{i=1}^{d}{\frac{1}{\sqrt{2\pi}}\exp{(-\frac{z_i^2}{2})}}\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}    q_{\phi}(\mathbf{z}|\mathbf{x}^{(i)})    &amp;=\mathcal{N}(\mathbf{\mu},\mathbf{\sigma}^2) \\    &amp;=\prod_{i=1}^d{\frac{1}{\sqrt{2\pi}\sigma_i}\exp{(-\frac{(z_i-\mu_i)^2}{2\sigma_i^2})}}\end{aligned}\]</span> 其中<span class="math inline">\(\mu_i=\mu_{\phi}(x^{(i)})\)</span>，<span class="math inline">\(\sigma_i=\sigma_{\phi}(x^{(i)})\)</span>，将<span class="math inline">\(x^{(i)}\)</span>输入NN计算得到的。</p><p>我们将KL散度拆成两项分别计算，得到：</p><p><span class="math display">\[\begin{aligned}-D_{K L}\left(\left(q_{\phi}(\mathbf{z}) \| p_{\boldsymbol{\theta}}(\mathbf{z})\right)\right.&amp;=\int q_{\boldsymbol{\theta}}(\mathbf{z})\left(\log p_{\boldsymbol{\theta}}(\mathbf{z})-\log q_{\boldsymbol{\theta}}(\mathbf{z})\right) d \mathbf{z} \\&amp;=\frac{1}{2} \sum_{j=1}^{J}\left(1+\log \left(\left(\sigma_{j}\right)^{2}\right)-\left(\mu_{j}\right)^{2}-\left(\sigma_{j}\right)^{2}\right)\end{aligned}\]</span></p><p>其中</p><p><span class="math display">\[\begin{aligned}\int q_{\boldsymbol{\theta}}(\mathbf{z}) \log p(\mathbf{z}) d \mathbf{z} &amp;=\int \mathcal{N}\left(\mathbf{z} ; \boldsymbol{\mu}, \boldsymbol{\sigma}^{2}\right) \log \mathcal{N}(\mathbf{z} ; \mathbf{0}, \mathbf{I}) d \mathbf{z} \\&amp;=-\frac{J}{2} \log (2 \pi)-\frac{1}{2} \sum_{j=1}^{J}\left(\mu_{j}^{2}+\sigma_{j}^{2}\right)\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}\int q_{\boldsymbol{\theta}}(\mathbf{z}) \log q_{\boldsymbol{\theta}}(\mathbf{z}) d \mathbf{z} &amp;=\int \mathcal{N}\left(\mathbf{z} ; \boldsymbol{\mu}, \boldsymbol{\sigma}^{2}\right) \log \mathcal{N}\left(\mathbf{z} ; \boldsymbol{\mu}, \boldsymbol{\sigma}^{2}\right) d \mathbf{z} \\&amp;=-\frac{J}{2} \log (2 \pi)-\frac{1}{2} \sum_{j=1}^{J}\left(1+\log \sigma_{j}^{2}\right)\end{aligned}\]</span></p><h3 id="指定样本的边际似然的计算">2. 指定样本的边际似然的计算</h3><ol type="1"><li>使用MCMC方法对<span class="math inline">\(\mathbf{z}\)</span>进行采样（现在我们知道先验--标准正态、似然--我们拟合的<span class="math inline">\(p_{\theta}(x|z)\)</span>，我们自然可以使用MCMC进行采样）。</li><li>将这些使用这些样本拟合一个密度估计器<span class="math inline">\(q(\mathbf{z})\)</span>（<em>实际上拟合的不是整体的后验吗？</em>）。</li><li>从确定的某个样本<span class="math inline">\(x^{(i)}\)</span>的后验分布中进行采样，利用上一步得到的密度估计器，计算下面的估计：</li></ol><p><span class="math display">\[p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right) \simeq\left(\frac{1}{L} \sum_{l=1}^{L} \frac{q\left(\mathbf{z}^{(l)}\right)}{p_{\boldsymbol{\theta}}(\mathbf{z}) p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} | \mathbf{z}^{(l)}\right)}\right)^{-1} \text {where } \mathbf{z}^{(l)} \sim p_{\boldsymbol{\theta}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right)\]</span></p><p>这个估计的推导如下所示：</p><p><span class="math display">\[\begin{aligned}\frac{1}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)} &amp;=\frac{\int q(\mathbf{z}) d \mathbf{z}}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)}=\frac{\int q(\mathbf{z}) \frac{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}\right)}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}\right)} d \mathbf{z}}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)} \\&amp;=\int \frac{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}\right)}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}\right)} \frac{q(\mathbf{z})}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}\right)} d \mathbf{z} \\&amp;=\int p_{\boldsymbol{\theta}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right) \frac{q(\mathbf{z})}{p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)}, \mathbf{z}\right)} d \mathbf{z} \\&amp; \simeq \frac{1}{L} \sum_{l=1}^{L} \frac{q\left(\mathbf{z}^{(l)}\right)}{p_{\boldsymbol{\theta}}(\mathbf{z}) p_{\boldsymbol{\theta}}\left(\mathbf{x}^{(i)} | \mathbf{z}^{(l)}\right)} \quad \text { where } \quad \mathbf{z}^{(l)} \sim p_{\boldsymbol{\theta}}\left(\mathbf{z} | \mathbf{x}^{(i)}\right)\end{aligned}\]</span></p><h3 id="full-vb">3. full VB</h3><p>这里将神经网络的参数也视为一个随机变量，则使用变分推断时，推断的不止是隐变量，还有参数的分布。类似贝叶斯神经网络的思想。这里也是文中关于“global parameters”的部分。</p><hr><h2 id="questions">Questions</h2><ol type="1"><li><p>我按照论文中的介绍，实现了一下，发现即使是在MNIST上也出现了一些问题:</p><ul><li>loss中的kl项会降至0，而reconstruction项基本不怎么降，或者降的幅度不大。</li><li>使用训练好的模型进行采样，采不出样本或者采到的都是相同的模糊样本。</li></ul><p>我查阅了一些资料，怀疑是“KL vanishing”的问题：</p><blockquote><p>KL vanishing指的是我们的模型陷入到了一个特殊的局部最小值中，这个局部最小值具有以下特点：</p><ul><li>encoder并不会将X的信息编码到Z中，只是让得到的Z和P(Z)的KL散度变为0</li><li>因为Z中没有X的信息，所以<span class="math inline">\(p(X|Z)=p(X)\)</span>（Z和X独立），如果decoder足够强大，其会自己来生成<span class="math inline">\(p(X)\)</span>的分布，这时候decoder自己变成了一个概率模型</li></ul><p>造成这个的原因一般有两个：</p><ul><li>最小化KL散度比最小化重构误差容易（原始的VAE确实容易这样，因为我们毕竟只是在最小化和Gaussian的差异，Gaussian还是简单的），我们很容易就先最小化了KL。</li><li>decoder太强，这在一些做NLP的工作中经常出现，因为做NLP需要将decoder做的比较强。</li></ul></blockquote><p>以后可能会单独就这个问题进行研究，现在先提供一个较为简单的解决方案：</p><ul><li>在KL loss项前乘以一个较小的权重，降低其重要性（<a href="https://github.com/AntixK/PyTorch-VAE" target="_blank" rel="noopener">PyTorch-VAE</a>中是这样实现的，我是直接乘了一个0.001效果就不错），或者使这个权重在训练的过程中从0逐步增大到1（KL cost annealing），保证encoder可以学习到X的信息</li></ul><p>当然还有其他的方法：比如不让KL降的太小、使用flow来代替单纯的Gaussian、使用cycleGAN的思想添加一个从X_rec返回到Z的路径并最小化两个Z间的差距（保证X中含有Z的信息）、各种降低decoder能力的方法（这个可能并不是我的model出现问题的原因）。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper-Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Unsupervised Learning </tag>
            
            <tag> Variational Inference </tag>
            
            <tag> Deep Leanring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena 数据集</title>
      <link href="/2020/05/25/tools/ucsc/ucsc-dataset/"/>
      <url>/2020/05/25/tools/ucsc/ucsc-dataset/</url>
      
        <content type="html"><![CDATA[<h1 id="下载数据集">下载数据集</h1><p>一共有4种方式：</p><ol type="1"><li><p>spreadsheet的下拉菜单中有Download按钮，用于下载此单个column上的数据。</p></li><li><p>整个Visual Spreadsheet网页的右上角有一个下载按钮，用来下载当前页面中所有columns的数据。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-dataset/ucsc-dataset_2020-06-03-21-30-22.png"><br></p></li><li><p>想要下载整个数据集，则需要进入<a href="https://xenabrowser.net/datapages/" target="_blank" rel="noopener">DATA SETS</a>，进入对应数据集的页面，选择其下载链接进行下载。</p></li><li><p>还可以使用python和R的APIs进行下载，这将在和中具体介绍。</p></li></ol><h1 id="所管理的数据集">所管理的数据集</h1><p>主要分为两大块：</p><ul><li><p>TCGA，最常使用的数据集，其数据有以下4个版本：</p><ul><li><a href="https://pancanatlas.xenahubs.net/" target="_blank" rel="noopener">TCGA Pan-Cancer Atlas</a>，TCGA团队将33种癌症的基因组数据进行了整合，进行了泛癌研究。此数据集即TCGA团队在进行泛癌研究时使用的数据集，也可以看做是最终的数据集。</li><li><a href="https://gdc.xenahubs.net/" target="_blank" rel="noopener">TCGA data from Genomic Data Commons</a>，使用最新的Human Genome Assembly hg38，对TCGA数据重新进行了分析。所有的open-access数据被下载，并保存到UCSC Xena中，根据癌症的种类被分成了33个单独的studies。</li><li><a href="https://toil.xenahubs.net/" target="_blank" rel="noopener">TCGA data in the UCSC RNA-seq Recompute Compendium</a>，使用UCSC bioinformatic pipeline（TOIL RNA-seq）对TCGA数据和GTEx数据进行了共分析（co-analyzed），可以用于比较tumor gene/transcript和normal gene/transcript的差异。</li><li><a href="https://tcga.xenahubs.net/" target="_blank" rel="noopener">Legacy TCGA data</a>，Pan-Cancer Atlas公布之前使用的TCGA数据，UCSC Xena hosts其level-3 data。</li></ul><blockquote><p>关于TCGA的数据的进一步详细信息，我将另开一个来记录，其中将详细讲述这些数据。</p></blockquote></li><li><p>其他</p><ul><li><a href="https://toil.xenahubs.net/" target="_blank" rel="noopener">UCSC RNA-seq recompute compendium</a>：这个实际上和上面的<a href="https://toil.xenahubs.net/" target="_blank" rel="noopener">TCGA data in the UCSC RNA-seq Recompute Compendium</a>是一个数据集，这里之所以再介绍一遍，是因为这个项目中除了TCGA的数据外，还有TARGET和GTEx的数据集。</li><li><a href="https://icgc.xenahubs.net/" target="_blank" rel="noopener">ICGC</a>：全称International Cancer Genome Consortium，致力于描述癌症在全球范围内的基因组、转录组、表观组的变化。除了TCGA作为美国小组的数据外，还有来自世界其他各地ICGC小组成员提供的数据。其中UCSC Xena管理的是其中公开的non-coding somatic mutation data。</li><li><a href="https://xenabrowser.net/datapages/?cohort=MET500%20(expression%20centric)" target="_blank" rel="noopener">MET500</a>：此数据来自研究： <a href="https://www.ncbi.nlm.nih.gov/pubmed/28783718" target="_blank" rel="noopener">Robinson et al 2017 Integrative clinical genomics of metastatic cancer</a>，是关于癌症转移性的研究。</li><li><a href="https://xenabrowser.net/datapages/?cohort=Cancer%20Cell%20Line%20Encyclopedia%20(CCLE)" target="_blank" rel="noopener">CCLE</a>：全称Cancer Cell Line Encyclopedia。是对于人类细胞系基因特征和药理学特征的综合描述。</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena绘制Kaplan-Meier曲线</title>
      <link href="/2020/05/25/tools/ucsc/ucsc-kmplot/"/>
      <url>/2020/05/25/tools/ucsc/ucsc-kmplot/</url>
      
        <content type="html"><![CDATA[<p>介绍Kaplan-Meier曲线的<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3932959/" target="_blank" rel="noopener">文章</a>。</p><p>绘制K-M曲线是简单的，只需要在相应的spreadsheet的菜单中选择'Kaplan Meier Plot'即可。</p><blockquote><p>绘制时，所有的缺失值被移除</p></blockquote><h1 id="分组">分组</h1><ol type="1"><li><p>对于连续性变量，如果一个spreadsheet中存在多个变量，则首先求其平均值。然后会有以下3种分组方式可以选择：</p><ul><li>2 groups，使用median划分；</li><li>3 groups，将数据按照值的大小排序后3等分；</li><li>quartiles，只保留小于25%分位数和大于75%分位数的样本并作为两组。</li></ul></li><li><p>对于分类变量，则至多只会展示其前10个类别。</p></li><li><p>对于mutation数据，将样本划分为有突变和没有突变两个组。</p></li><li><p>也可以定义自己的subgroups，详见。</p></li></ol><h1 id="注意事项">注意事项</h1><ol type="1"><li><p>如果存在重复样本（比如同一个人的正常组织和肿瘤组织），则得到的p值会存在警告，需要使用filter将重复的数据滤除。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-kmplot/ucsc-kmplot_2020-06-03-15-16-36.png"><br></p></li><li><p>使用log-rank检验，等同于R中的<code>survdiff</code>。</p></li><li><p>如果数据从存在不同的生存时间类型，则可以选择不同的生存类型可视化。</p></li><li><p>可以选择生存数据到底截止到1年还是5年。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena Visual-Spreadsheet介绍</title>
      <link href="/2020/05/25/tools/ucsc/ucsc-spreadsheet/"/>
      <url>/2020/05/25/tools/ucsc/ucsc-spreadsheet/</url>
      
        <content type="html"><![CDATA[<p>整个可视化界面有多个动态的spreadsheets组成，任何数据都可以形成一个spreadsheet。所有的spreadsheets横向排列在一起，使得每一行是相同的一个样本，便于查看样本间的趋势。样本会被排序，顺序是先按照最左边的spreadsheet上的值排序，然后依次向右逐步推进。</p><h1 id="移动排序">移动排序</h1><p>我们可以通过拖动spreadsheet来改变spreadsheets间的顺序，从而改变样本排列的顺序。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/move.gif"><br></p><h1 id="放大功能">放大功能</h1><p>框选部分范围（部分样本或部分变量），将会放大选中的部分。点击页面顶部的<code>Clear Zoom</code>则取消放大。如果只想取消单个spreadsheet的放大显示，则点击spreadsheet中出现的红色x即可。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/allzoominout.gif"><br></p><h1 id="tooltips">Tooltips</h1><p>Tootip位于页面顶部，用来显示当前鼠标所指的数据的信息。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/ucsc-spreadsheet_2020-06-03-12-25-18.png"><br></p><p>如果想要freeze住当前鼠标指定的数据的信息，可以使用'Alt+click'，unfreeze则点击右边的x即可。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/ucsc-spreadsheet_2020-06-03-12-30-18.png"><br></p><h1 id="gene-signatures">Gene Signatures</h1><p>即我们可以人为的创造多个gene expression的weighted sum作为一个spreadsheet。其具体做法如下所示：</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/signatures.gif"><br></p><p>注意事项：</p><ul><li><code>+</code>和<code>-</code>两边必须加空格</li><li>必须选择Gene Expression</li></ul><p>UCSC Xena官方基于TCGA Pan-Cancer计算了一些signatures：</p><ul><li><a href="https://xenabrowser.net/datapages/?dataset=Pancan12_GenePrograms_drugTargetCanon_in_Pancan33.tsv&amp;host=https%3A%2F%2Fpancanatlas.xenahubs.net" target="_blank" rel="noopener">gene programs</a></li><li><a href="https://xenabrowser.net/datapages/?dataset=TCGA.HRD_withSampleID.txt&amp;host=https%3A%2F%2Fpancanatlas.xenahubs.net" target="_blank" rel="noopener">HRD score, genome-wide DNA damage footprint</a></li><li><a href="https://xenabrowser.net/datapages/?dataset=TCGA_pancancer_10852whitelistsamples_68ImmuneSigs.xena&amp;host=https%3A%2F%2Fpancanatlas.xenahubs.net" target="_blank" rel="noopener">Immune Signature Scores (Denise Wolf et al)</a></li><li><a href="https://xenabrowser.net/datapages/?dataset=StemnessScores_DNAmeth_20170210.tsv&amp;host=https%3A%2F%2Fpancanatlas.xenahubs.net" target="_blank" rel="noopener">Stemness score (DNA methylation based)</a></li><li><a href="https://xenabrowser.net/datapages/?dataset=StemnessScores_RNAexp_20170127.2.tsv&amp;host=https%3A%2F%2Fpancanatlas.xenahubs.net" target="_blank" rel="noopener">Stemness score (RNA based)</a></li></ul><p>这些可以在Genomic型数据中（Show Adanced）中找到。</p><h1 id="数据展示">数据展示</h1><p>样本的排序：</p><ul><li>对于copy number数据，其使用整个gene regions上的值的平均值来排序。</li><li>对于mutation数据，使用其最早发生变异的position来进行排序。</li></ul><blockquote><p>对于以上两类数据，我们可以放大其部分，这样，排序的依据将依照这放大的部分进行。</p></blockquote><p>整个spreadsheet的图示部分可以分为3个区域，即：</p><ul><li>gene/chromosome展示区</li><li>表达量展示区</li><li>图例区</li></ul><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/ucsc-spreadsheet_2020-06-03-13-09-50.png"><br></p><h2 id="genechromosome展示区">1. gene/chromosome展示区</h2><ul><li><p>在输入数据时，使用gene名或probes来选择gene</p><p>绘制这个gene的transcript。其中CDS区域（coding DNA Sequence，编码序列）使用较高的black bar表示，UTR区域（untranslated Regions，位于mRNA两端的非编码序列）使用较矮的black bar表示，内含子区域（intron region，可变剪切切除的区域）单纯使用轴表示。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/ucsc-spreadsheet_2020-06-03-13-26-17.png"><br></p><p>如果mutation数据，则可以选择是否显示内含子区域，注意，此时下面的变异点的可视化也会随之变化。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/intron.gif"><br></p></li><li><p>可以输入整个chromosome（chr1）、chromosome的arms（chr19q）或者chromosomes的定位（chr1:1-2000000）来得到gene区域的表示</p><p>这里所有的gene都会表示出来，也无法隐藏gene的intron region</p><blockquote><p>因为许多gene其所占的在染色体上的区域会有重叠，所以这里使用了多行来表示。</p></blockquote><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/chromosome.gif"><br></p></li></ul><h2 id="表达量展示区">2. 表达量展示区</h2><p>这个区域主要是以heatmap的形式显式的。唯一的区别在于mutation的数据，其在对应的的发生图片的位点上使用不同颜色的点来表示。</p><p>还要注意，exon RNAseq数据和Rnaseq数据有所不同，exon数据单个gene会有多个值，分别代表每个exon的表达。</p><p><img src="/2020/05/25/tools/ucsc/ucsc-spreadsheet/ucsc-spreadsheet_2020-06-03-14-31-24.png"><br></p><h2 id="图例区">3. 图例区</h2><p>在最下面，比如越红表示值越大，不同的mutation type使用不同的类型表示...</p><h1 id="功能菜单">功能菜单</h1><p>在spreadsheet的右上角，有一个下拉菜单，有许多其他功能，这些功能会在其他章节中分别介绍。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena Demo-针对私人数据集进行分析</title>
      <link href="/2020/05/24/tools/ucsc/ucsc-demo2/"/>
      <url>/2020/05/24/tools/ucsc/ucsc-demo2/</url>
      
        <content type="html"><![CDATA[<p>经过，我们能够对TCGA等公开数据库进行简单的可视化处理了，但实际上UCSC Xena可以做到更多。</p><p>这里我们从GEO下载数据集GSE121720作为私人数据集，然后使用UCSC Xena进行分析。这一部分的tutorial可以见官方提供的<a href="https://ucsc-xena.gitbook.io/project/tutorials" target="_blank" rel="noopener">视频教程</a>，或者是其<a href="https://ucsc-xena.gitbook.io/project/local-xena-hub/getting-started" target="_blank" rel="noopener">网页</a>。</p><h1 id="安装local-xena-hub">1. 安装Local Xena Hub</h1><blockquote><p>为了安全性和服务器压力考虑，对于私人数据的处理，其服务器是使用Local Xena Hub软件架设在本地机上的。Local Xena Hub由java编写。</p></blockquote><p>下载需要点击<a href="https://xenabrowser.net/datapages/?addHub=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223&amp;host=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223" target="_blank" rel="noopener">VIEW MY DATA</a>，这里提供windows的<a href="https://genome-cancer.ucsc.edu/download/public/get-xena/ucsc_xena_windows-x64_0_25_0.exe" target="_blank" rel="noopener">直接下载链接</a>。在windows上的安装比较简单，就是点一点就好了。</p><h1 id="开启local-xena-hub">2. 开启Local Xena Hub</h1><p>直接进入<a href="https://xenabrowser.net/datapages/?addHub=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223&amp;host=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223" target="_blank" rel="noopener">VIEW MY DATA</a>，如果已经安装了Local Xena Hub，并且其安装位置在Applications folder中（其实自动就安装到这里），则浏览器会自动开启它。如果没有自动开启，需要主动双击打开exe文件。这时候网页会连接到本地服务器。</p><blockquote><p>需要使用Chrome或Firefox浏览器。</p></blockquote><h1 id="清理数据集">3. 清理数据集</h1><p>为了本地服务器可以识别私人数据集，我们必须把数据集整理成一定的格式。</p><p>总的来说有以下几条要求：</p><ul><li>首先，本地服务器可以识别多种数据，但这些数据必须是TCGA的“level 3”格式的数据（比如gene表达的值、transcript的值、probe的值）。不支持FASTQ、BAMs等更加“raw”的数据格式。</li><li>所有的数据必须是tab-delimited的，文件的后缀一般是<code>.tsv</code>或<code>.txt</code>，不支持Excel格式（<code>.xls</code>或<code>.xlsx</code>）。</li><li>不要有重复的genes/probes/identifiers或samples，不然本地服务器只会保留重复的第一个。</li><li>使用空格或<code>"NA"</code>来表示缺失值。</li><li>使用<code>.</code>来表示小数点，不要使用<code>,</code>（在一些语言中用逗号做小数分割符）。</li></ul><p>至于具体的数据格式，这里细化分为了4种，分别进行介绍：</p><h2 id="basic-genomic-data">3.1 Basic Genomic data</h2><p>大部分的基因组level3级数据，是正常的numerical rectangle/matrix/spreadsheet型数据。即每一列是一个样本，每一行是一个变量，反过来也可以。比如下面的这些：</p><ul><li><strong>RNA-seq expression (exon, transcript, gene, etc)</strong></li><li><strong>Array-based expression (probe, gene, etc)</strong></li><li><strong>Gene-level mutation</strong></li><li><strong>Gene-level copy number</strong></li><li><strong>DNA methylation</strong></li><li><strong>RPPA</strong></li><li>and more ...</li></ul><p>图示（注意<code>Sample</code>的存在）：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-27-11.png"><br></p><blockquote><p>服务器可以自动将一些probesname（比如TP53、EGFR等）。其支持的probes中可以查到。</p></blockquote><h2 id="basic-phenotypic-data">3.2 Basic Phenotypic data</h2><p>也是rectangle/matrix/spreadsheet型数据，用来描述临床信息，可以是categorical或numerical的。可以是一行是样本一列是变量或者反过来，比如下面的这些：</p><ul><li><strong>phenotype/patient/clinical data (age, weight, if there was blood drawn, etc)</strong></li><li><strong>sample/aliquot data (where it was sequenced, tumor weight, etc)</strong></li><li><strong>derived data (regulon activity for a gene, etc)</strong></li><li><strong>genomic signatures (EMT signature score, stemness score, etc)</strong></li><li><strong>other (whether a sample has an ERG-TMPRSS2 fusion, whether a sample has WGS data available, etc)</strong></li></ul><p>这一类数据是最灵活的，比如下面的形式：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-33-49.png"><br></p><h2 id="advanced-segmented-data">3.3 Advanced Segmented data</h2><p>需要有5列，分别是<code>sample</code>、<code>chr</code>、<code>start</code>、<code>end</code>、<code>value</code>，现在支持的coordinators是hg38、hg19和hg18。主要就是copy number。</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-37-07.png"><br></p><h2 id="advanced-positional-data">3.4 Advanced Positional data</h2><p>需要有6列，分别是<code>sample</code>、<code>chr</code>、<code>start</code>、<code>end</code>、<code>reference</code>（参考基因组）、<code>alt</code>（变异后的编码）。另外还可以有的列有<code>gene</code>、<code>effect</code>、<code>DNA_VAF</code>、<code>RNA_VAF</code>、<code>Amino_Acid_Change</code>。这些列不是必须的但会增强数据的可视化（比如根据<code>effect</code>为不同的突变赋予不同的颜色）。</p><p>现在支持的coordinators是hg38、hg19和hg18。</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-45-59.png"><br></p><h2 id="其他">3.5 其他</h2><p>也支持其他数据，但需要和官方联系得到支持。</p><hr><p>现在我们下载的数据是这样的格式：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-57-13.png" alt="clinical matrix"><br></p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-22-57-43.png" alt="genomic matrix"><br></p><p>也需要进一步的处理才会符合上面的要求，以下是处理代码：</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># py preprocess.py</span><span class="token keyword">import</span> os<span class="token punctuation">.</span>path <span class="token keyword">as</span> osp<span class="token keyword">import</span> re<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddata_root <span class="token operator">=</span> <span class="token string">"G:\\dataset\\UCSCexamples"</span>cli_fn <span class="token operator">=</span> <span class="token string">"GSE121720_series_matrix.txt"</span>gene_fn <span class="token operator">=</span> <span class="token string">"tpm.txt"</span><span class="token comment" spellcheck="true"># 处理clinical 数据</span>cli_data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> cli_fn<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>        <span class="token keyword">if</span> line<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">"!Sample"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 1. 将每一行的第一个元素去除!Sample_作为key，剩下的提取出“”中的部分作为value</span>            key<span class="token punctuation">,</span> value <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">,</span> maxsplit<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            key <span class="token operator">=</span> key<span class="token punctuation">[</span>len<span class="token punctuation">(</span><span class="token string">"!Sample_"</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>            value <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>r<span class="token string">'"(.*?)"'</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 2. 如果value中的元素以xx：yy形式存在，则xx作为其新的变量名</span>            <span class="token keyword">if</span> all<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">":"</span> <span class="token keyword">in</span> v <span class="token keyword">for</span> v <span class="token keyword">in</span> value<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                v1s<span class="token punctuation">,</span> v2s <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>                <span class="token keyword">for</span> v <span class="token keyword">in</span> value<span class="token punctuation">:</span>                    v1<span class="token punctuation">,</span> v2 <span class="token operator">=</span> v<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">":"</span><span class="token punctuation">,</span> maxsplit<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                    v1s<span class="token punctuation">.</span>append<span class="token punctuation">(</span>v1<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                    v2s<span class="token punctuation">.</span>append<span class="token punctuation">(</span>v2<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> len<span class="token punctuation">(</span>set<span class="token punctuation">(</span>v1s<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                    key <span class="token operator">=</span> v1                    value <span class="token operator">=</span> v2s            <span class="token comment" spellcheck="true"># 保存到dict中</span>            cli_data<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> valuecli_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>cli_data<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 这里变量名是title，需要对其进行一些处理：包括去掉一些冗余的字符和改一下变量名</span>cli_data<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>    <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"Sample"</span><span class="token punctuation">,</span> cli_data<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> expand<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>cli_data<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"title"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 把名称超过255长度的列去掉</span>bool_index <span class="token operator">=</span> cli_data<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> len<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">255</span><span class="token punctuation">)</span>cli_data <span class="token operator">=</span> cli_data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> bool_index<span class="token punctuation">]</span>cli_data<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">"clean_cli.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 处理RNAseq data（主要为第一列加Sample的column name）</span>writer <span class="token operator">=</span> open<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> <span class="token string">"clean_rnaseq.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span><span class="token keyword">with</span> open<span class="token punctuation">(</span>osp<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_root<span class="token punctuation">,</span> gene_fn<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> line <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            line <span class="token operator">=</span> <span class="token string">"Sample\t"</span> <span class="token operator">+</span> line        writer<span class="token punctuation">.</span>write<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>处理结果：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-23-42-07.png" alt="clean clinical matrix"><br></p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-02-23-38-50.png" alt="clean genomic matrix"><br></p><h1 id="载入数据集">4. 载入数据集</h1><p>载入数据集的方式有两种：</p><h2 id="使用view-my-data网页载入">4.1 使用<a href="https://xenabrowser.net/datapages/?addHub=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223&amp;host=https%3A%2F%2Flocal.xena.ucsc.edu%3A7223" target="_blank" rel="noopener">VIEW MY DATA</a>网页载入</h2><p>直接使用网页上的3-steps wizard来完成，这需要一个文件一个文件的import，对于文件比较少的比较适合。</p><blockquote><p>注意事项： * 变量名长度不能超过255。 * 将表示样本的列放在第一列或第一行。</p></blockquote><p>结果：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-03-00-00-27.png"><br></p><h2 id="使用命令行载入">4.2 使用命令行载入</h2><p><a href="https://ucsc-xena.gitbook.io/project/local-xena-hub/loading-data-from-the-command-line" target="_blank" rel="noopener">Toturial地址</a>，这适合数据文件比较多的时候，可以通过写一个metadata file来载入。</p><blockquote><p>但实际上也不是很方便，每一个数据文件就必须创建一个json文件。</p></blockquote><h3 id="metadata-file">Metadata file</h3><ul><li>需要和数据文件在同一个路径下</li><li>需要json文件名和数据文件名一致：<code>my_data.tsv</code> -- <code>my_data.json</code></li></ul><p>metadata file有以下field可以填写：</p><ul><li><p><code>type</code>：必填，是数据这个数据文件的类型，</p><ul><li><code>genomicMatrix</code>：Basic Genomic data，必须是一列是一个样本，一行是一个变量，不支持另一种形式。</li><li><code>clinicalMatrix</code>：Basic Phenotypic data，必须是一列是一个样本，一行是一个变量，不支持另一种形式。</li><li><code>mutationVector</code>：Advanced Positional data。</li><li><code>genomicSegment</code>：Advanced Segmentation data。</li></ul></li><li><p><code>cohort</code>：必填，即study的名字。</p></li><li><p><code>assembly</code>：如果是mutation或segmentation copy number数据，需要填写，即支持的coordinations。</p></li><li><p>Probemap：这个比较麻烦，简单来说，就是如果数据集使用的是自己的probes，则需要建立一个probes到其他identifiers的map，所以需要上传有这个映射关系的文件。所以需要准备3个文件：</p><ul><li><p>Probemap文件：比如：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-03-01-07-23.png"><br></p></li><li><p><code>probemap.json</code>：</p><pre><code>{ “type”:“probeMap”,“assembly”:“hg19"}</code></pre></li><li><p><code>data.json</code></p><p>加上如下一条：</p><pre><code>":probeMap":"/unc_v2_exon_hg19_probe_TCGA"</code></pre></li><li><p><code>data.tsv</code></p></li></ul></li></ul><blockquote><p>UCSC Xena官方准备了一些probemap文件，可以使用xenaPython app来获得，可见{% post_link ucsc-python %}的介绍。</p></blockquote><h3 id="命令行">命令行</h3><ul><li><p>上传数据：</p><pre class="line-numbers language-shell"><code class="language-shell"># 上传文件下的所有数据java -jar cavm-0.xx.0-standalone.jar -l ~/xena/files/*# 上传一个数据java -jar cavm-0.xx.0-standalone.jar -l ~/xena/files/file1.tsv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>删除数据：</p><pre class="line-numbers language-shell"><code class="language-shell">java -jar cavm-0.xx.0-standalone.jar -x ~/xena/files/file1.tsvjava -jar cavm-0.xx.0-standalone.jar -x ~/xena/files/file1.tsv ~/xena/files/file2.tsv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>帮助：</p><pre class="line-numbers language-shell"><code class="language-shell">java -jar cavm-0.xx.0-standalone.jar -h<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ul><blockquote><p>需要找到那个<code>cavm*.jar</code>文件，在那个文件所在路径下运行。</p></blockquote><h1 id="数据集分析">5. 数据集分析</h1><p>其分析方式和一致，下面是最后的可视化结果：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo2/ucsc-demo2_2020-06-03-01-20-02.png" alt="GSE121720的可视化"><br></p><p>有几点需要注意：</p><ol type="1"><li>如果想要做K-M plot，则需要clinical data中有相应的Time to Event和Event变量。其命名必须按照<a href="https://ucsc-xena.gitbook.io/project/local-xena-hub/km-plots-using-data-from-a-local-xena-hub" target="_blank" rel="noopener">tutorial-kmplot</a>中进行。</li><li>如果要为自己的实验室或科室创建一个数据服务器，则需要另外的步骤，请见<a href="https://ucsc-xena.gitbook.io/project/local-xena-hub/hubs-for-institutions-collaborations-labs-and-larger-projects" target="_blank" rel="noopener">Hubs for institutions, collaborations, labs, and larger projects</a>。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena Demo-低级胶质瘤和胶质母细胞瘤的分子特征</title>
      <link href="/2020/05/24/tools/ucsc/ucsc-demo1/"/>
      <url>/2020/05/24/tools/ucsc/ucsc-demo1/</url>
      
        <content type="html"><![CDATA[<p>此部分的内容来自UCSC Xena官方提供的<a href="https://ucsc-xena.gitbook.io/project/tutorials" target="_blank" rel="noopener">视频教程</a>，大家也可以到YouTube自行观看。此教程共分为3个部分：</p><ol type="1"><li>第一部分是一个对Xena的简单的介绍（时长大约5min）；</li><li>第二部分是利用TCGA中的LGG和GBM数据来做一个简单的操作演示（时长大约17min），经过第二部分的学习就能够掌握Xena可视化的大部分操作；</li><li>第三部分是一个时长55分钟的报告（第二部分是此部分的一个节选片段），详细介绍了UCSC Xena解决的问题、其所包含的公共数据库有哪些、利用公共数据库进行可视化分析、利用下载的数据（或私人数据）进行分析等等。</li></ol><p>本篇内容主要来自于第二部分和第三部分。主要是如何基于公共数据库使用UCSC Xena进行简单的可视化分析。其中关于数据库的介绍，会另外单独辟出篇章进行。公开数据库的示例数据集是TCGA-LGG和TCGA-GBM的chr1和chr19的copy number，还有TP53、ATRX的mutation。私人数据的演示将放在下一篇 中进行。</p><h1 id="数据的载入">数据的载入</h1><h2 id="进入ucsc-xena-functional-genomics-explorer">1. 进入UCSC Xena Functional Genomics Explorer：</h2><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-14-57-33.png" alt="UCSC Xena首页"><br></p><p>以下是我们主要使用的界面：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-15-02-58.png" alt="[Functional Genomics Explorer]"><br></p><p>在这个界面内，数据以spreadsheet为单位展示。其可以包含单个phenotypic变量，也可以是某个gene上的DNA methylation或mutation、某条染色体上的copy number、1个或多个gene expression。其每一行表示一个样本，所要分析的所有样本叠加在一起组合成headmap（或者其他），不同种类的数据在spreadsheet上会有不同形式的展示。关于spreadsheet更加详细的介绍请见。</p><p>一般来说，我们至少需要添加3个spreadsheets（sample datasets、一个phenotypic变量、一个genomics变量）才能进行一般的genomics分析，所以页面会提供一个3-steps的wizard。</p><h2 id="选择一个合适的study第一步">2. 选择一个合适的study（第一步）</h2><p>这里实际上就是加载第一个sreadsheet--sample datasets。TCGA等公开数据库中的数据根据不同的研究目的（针对特定癌症、或者泛癌分析等）进行了打包，选择特定的研究就会载入其相关的所有样本：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-16-36-37.png" alt="第一个column"><br></p><p>使用条带来表示样本量大小，并标注一个条带代表了多少个样本（上图中是500）。</p><h2 id="选择研究的第一个变量第二步">3. 选择研究的第一个“变量”（第二步）</h2><p>第二步需要我们添加第二个spreadsheet，一般来说这都是一个临床信息变量，即phenotype。这里根据我们的示例任务，我们选择“癌症类型”。这属于phenotypic类型（即临床信息），如下图所示：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-16-43-07.png" alt="癌症类型"><br></p><p>当然，我们没有必要只增加一个phenotype，如果我们的分析需要更多的phenotypes，则添加继续添加即可。当增加到3个spreadsheets的时候，界面便会跳转到分析界面上，但这没有关系，在此界面上可以继续添加spreadsheets。我们也可以在一次添加中添加多个变量，只需要同时勾选多个phenotypes即可。</p><h3 id="变量类型">变量类型</h3><p>变量类型一共有3种，除了上面提到的phenotypic，还有另外两种类型，genomics和analytic，genomics将在下一步进行介绍，这里简单介绍一下analytic。</p><p>analytic型变量，就是基于genomics数据，通过一些数据分析方法得到的诸如分子亚型、评分等数据，比如免疫亚型：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-16-41-11.png" alt="免疫亚型"><br></p><h2 id="选择第二个变量第三步">3. 选择第二个“变量”（第三步）</h2><p>一般是genomics类型。</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-16-52-04.png" alt="进入分析页面"><br></p><h1 id="数据分析">数据分析</h1><p>整个分析界面如下面所示。<em>实际上挺简单的，图形界面操作，看一眼也都能知道是怎么用。</em></p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-17-26.png" alt="整个分析界面"><br></p><h2 id="继续添加剩下的chr19数据和mutation数据">1. 继续添加剩下的chr19数据和mutation数据</h2><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-26-37.png" alt="将所需要的的数据添加完"><br></p><p>我们可以看到，连续性的变量主要以heatmap的格式存在，而至于分类变量则是以不同颜色的条带来表示。很多genomics的数据，拥有更多的信息（比如copy number、methylation等），则会给出更多的信息，比如每个位点所在基因或染色体的位置、状态等等。总之，信息量是很丰富的。</p><h2 id="筛选出我们需要的数据">2. 筛选出我们需要的数据</h2><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-29-51.png" alt="筛选LGG和GBM"><br></p><p>得到下面的结果：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-32-11.png" alt="筛选结果"><br></p><p>实际上我们可以通过移动spreadsheet来实现样本按照不同的类型进行排序。比如我们可以将TP53的mutation移到前面去，则样本会优先按照tp53的值进行排序，然后才是cancer type：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-34-43.png" alt="通过移动columns实现样本的不同排序"><br></p><p>我们可以看到有大量的null（缺失样本），我们不希望要这些样本，则可以继续使用上的样本搜索框来实现过滤（这里把tp53的expression数据类型改成了mutation，之前只是为了方便说明不同类型的变量的展示结果）：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-39-49.png" alt="删除缺失值"><br></p><h2 id="简单的数据分析">3. 简单的数据分析</h2><blockquote><p>这一部分的图可能和上面的不太一样，进行上面的内容的时候，网不是太稳定，所以只能加载一段染色体上的copy number数据，而本部分是加载了1号和19号染色体的全部copy number数据，所以才能够比较直观的看出差异来。</p></blockquote><p>实际上根据这些可视化内容，我们就已经可以进行一些简单的分析了：</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo1_2020-05-25-13-30-53.png" alt="肉眼聚类"><br></p><ul><li><p>可以看到，根据1号和19号染色体的copy number，可以很明显地将LGG的样本分为2个部分，这两个部分在TP53和ATRX mutation上也存在着明显的不同。</p></li><li><p>而在GBM上，则无法看到这样明显的区别。不过基于1号染色体的copy number数据，可以看到GBM样本也可以进一步分为2个小的亚型。</p></li></ul><h2 id="绘制两种癌症的k-m-plot">4. 绘制两种癌症的K-M plot</h2><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo_2020-05-24-17-44-46.png" alt="K-M plot"><br></p><p>详细的关于K-M plot的信息，请见。</p><h2 id="对数据进行statistic可视化">5. 对数据进行statistic可视化</h2><p>点击右上角进入chart页面，可以绘制一些统计图示，从整体上来对数据进行一定的分析。（不是所有数据都可以绘制chart，比如mutation数据就不行）</p><p><img src="/2020/05/24/tools/ucsc/ucsc-demo1/ucsc-demo1_2020-06-02-16-35-09.png"><br></p><p>关于chart的详细信息，请见</p><h1 id="暂存当前的分析结果bookmarks">暂存当前的分析结果（Bookmarks）</h1><p>有两种方式：bookmarks url和export files（但都只能保存30天）。</p><ul><li>Bookmarks url，将当前的内容保存到云端，会生成一个url，用来进行分享。为了安全起见，私人数据在保存的时候会被剔除。</li><li>export会将当前可视化所需要的所有内容都整理成一个json文件，保存到本地，当使用时，再通过import导入即可，这种方式可以将私人数据的可视化保存。</li></ul><h1 id="其他">其他</h1><p>以上图示结果都可以下载为PDF文件，比较方便。</p><p>这基本上就是UCSC Xena的所有功能，功能不算太多，但重要的在于可以马上形成漂亮的可视化。在相关研究的计划阶段，可以使用这些功能快速的验证猜想，有助于之后的研究设计和决策。</p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UCSC Xena 介绍</title>
      <link href="/2020/05/24/tools/ucsc/ucsc-introduction/"/>
      <url>/2020/05/24/tools/ucsc/ucsc-introduction/</url>
      
        <content type="html"><![CDATA[<p><a href="http://xena.ucsc.edu" target="_blank" rel="noopener">UCSC Xena</a>主要解决两个问题：</p><ol type="1"><li>genomics数据的可视化，无论是大型公开数据库还是自己的私人数据。<ul><li><p>主要数据来自TCGA、ICGC、CCLE等；</p></li><li><p>所有可以进行可视化的数据都可以下载，而且这些数据被预处理过，可以直接下载使用；</p></li><li><p>可以比较方便的可视化私人数据。</p><blockquote><p>这里对于私人数据集，基于可利用资源、安全性的诸多考虑，Xena将此分析过程放在本地进行。所以其交互模式如下图所示：</p></blockquote><p><img src="/2020/05/24/tools/ucsc/ucsc-introduction/ucsc-demo2_2020-05-25-10-13-52.png" alt="Xena Platform的工作模式"><br></p></li></ul></li><li>将私人数据和公开数据进行合并分析。<ul><li>可以查看的数据类型有：Copy number variation、DNA methylation、Gene and exon expression、Protein expression、miRNA expression、Positional mutation和Phenotype/annotations；</li><li>另外一个整合的web分析工具--MuPIT，可以在3D蛋白质空间中查看变异。</li></ul></li></ol><p>UCSC Xena总体来说，为geneomics研究提供了一个快速实现的平台。一些简单的、即时性的可视化内容，或者分析单个或几个gene，可以直接使用UCSC Xena实现，无需下载、预处理数据。</p><p>当然，其功能相对于使用R、python分析来说，还是比较简单的，并且其主要目的在于快速的可视化，而不是复杂的数据分析。所以对于稍微复杂的数据分析流程、成百上千个genes的可视化等任务，其可能无法完成。而且在中国大陆使用的话，可能需要找个合适的时间（比如上午）。</p><p>UCSC Xena的各种功能众多，并且还储存了大量的可用precompiled data，所以这里我会分多篇文章进行介绍：</p><ol type="1"><li>，UCSC Xena的基本操作等也在此处进行了介绍</li><li></li><li></li><li></li><li><a href="https://ucsc-xena.gitbook.io/project/overview-of-features/chart-view-box-plots-scatter-plots-and-bar-charts" target="_blank" rel="noopener">UCSC 统计图示</a>，这个比较简单，就直接链接到tutorial了</li><li></li><li></li><li></li></ol><p>另外，UCSC Xena的一些重要的内容，我也以链接的形式放到下面，方便访问：</p><ol type="1"><li><a href="https://ucsc-xena.gitbook.io/project/live-examples" target="_blank" rel="noopener">官方做好的例子</a></li></ol><p>UCSC Xena介绍的其他的项目：</p><ol type="1"><li><a href="https://ucsc-xena.gitbook.io/project/overview-of-features/tumormap" target="_blank" rel="noopener">TumorMap</a>，由UCSC开发的另一个项目。</li><li><a href="https://ucsc-xena.gitbook.io/project/overview-of-features/untitled" target="_blank" rel="noopener">MuPIT</a>，可以可视化mutation所带来的蛋白质的影响。</li><li><a href="https://ucsc-xena.gitbook.io/project/overview-of-features/transcript-view" target="_blank" rel="noopener">Transcript View</a>，可视化肿瘤样本（TCGA）和正常样本（GTEx）间的差异。</li><li><a href="https://ucsc-xena.gitbook.io/project/overview-of-features/gene-sets-about" target="_blank" rel="noopener">Gene Sets Tool</a>，比较了两个队列间癌症相关基因的somatic mutation和copy number。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> UCSC Xena </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gitignore的文件忽略规则</title>
      <link href="/2020/05/21/tools/gitignore-wen-jian-hu-lue-gui-ze/"/>
      <url>/2020/05/21/tools/gitignore-wen-jian-hu-lue-gui-ze/</url>
      
        <content type="html"><![CDATA[<p>在正常的工作中，经常使用到git，那自然.gitignore文件的使用是必须要掌握的。所幸我们一般用到的的.gitignore的规则都比较简单，而且其语法是使用的通配符语法，容易掌握，这里将它的语法进行一下归纳整理，便于之后查阅。</p><p><em>这里的内容主要参考的是<a href="https://git-scm.com/docs/gitignore" target="_blank" rel="noopener">git的官方文档</a></em></p><ul><li>空行被程序无视，所以可以用来组织文件使之便于阅读。</li><li><code>#</code>开头的行被视作注释。</li><li>每一行之后的空格被忽略，除非使用<code>\</code>将其包裹。</li><li><code>!</code>前缀表示反向选择，即之前被排除的文件或文件夹，如果符合<code>!</code>之后的模式，将会被重新包括在内，但是：<ul><li>如果<code>!</code>希望重新包含的文件或文件夹，其父文件夹被排除，则无法重新包括在内。</li><li>如果想要匹配的是字符<code>!</code>，则需要前面使用反斜杠转义<code>\!</code>。</li></ul></li><li>正斜杠<code>/</code>被看做是目录分隔符。</li><li>如果存在<code>/</code>（在开头或中间），则被排除的文件或目录将只是这个相对路径下的；如果不存在<code>/</code>，则该模式表示的文件或目录（<code>AAA/</code>）不管存在于哪一级目录中，都将被排除。<ul><li>例：<code>doc/frotz/</code>只会排除<code>doc/frotz/</code>而不能排除<code>a/doc/frotz</code></li><li>例：<code>frotz/</code>则会排除<code>doc/frotz/</code>、<code>a/doc/frotz/</code>、<code>frotz</code>等</li></ul></li><li><code>AAA/</code>将只会匹配在任何一级目录下的<code>AAA</code>目录，而<code>AAA</code>则会匹配在任何一级目录下的目录或文件<code>AAA</code>。</li><li><code>*</code>匹配任意字符串除了<code>/</code>，而<code>?</code>匹配任意单个字符除了<code>/</code>。</li><li><code>[a-zA-z]</code>用来匹配在这个范围内的单个字符。</li></ul><p>下面来介绍<code>**</code>的用法：</p><ul><li><code>**/</code>表示在任何目录下，即<code>**/foo</code>其等价于<code>foo</code>。</li><li><code>/**</code>表示在目录中的东西，比如<code>foo/**</code>表示<code>foo</code>文件夹下的任何东西都被排除（但<code>foo</code>目录本身不会被排除）。</li><li><code>a/**/b</code>将匹配<code>a/b</code>、<code>a/x/b</code>、<code>a/x/y/b</code>等等。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-使用VAE整合多组学数据进行PanCancer分析-OmiVAE2019</title>
      <link href="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/"/>
      <url>/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/</url>
      
        <content type="html"><![CDATA[<h1 id="integrated-multi-omics-analysis-using-variational-autoencoders-application-to-pan-cancer-classification">Integrated Multi-omics Analysis Using Variational Autoencoders: Application to Pan-cancer Classification</h1><ul><li>杂志: arXiv</li><li>IF: --</li><li>分区: --</li><li><a href="https://github.com/zhangxiaoyu11/OmiVAE" target="_blank" rel="noopener">github</a></li></ul><hr><p><strong>写在前面的话：</strong></p><p><em>可以说本文件为我生动的上了一课--数据备份的重要性。为了测试自己编写的python-gui-bolg管理系统，却没有将当前写完的笔记进行备份，尽管慎之又慎，但还是覆盖了几篇我辛辛苦苦写下的文件，本篇就是其中之一。尽管尝试了多种数据恢复软件，但依然无法从被覆盖的文件中找到其以前的版本，所以我放弃了挣扎，只能重新再写一遍。</em></p><p><em>为此，我进行的补救措施有：首先查看了所有我写过的十几篇笔记，查看有哪些有问题；将当前写笔记的文件环境同步到坚果云，利用其可以历史备份的功能；重新编写了我的博客管理系统的备份功能，现在其备份不会被覆盖，而是每次备份时都会备份称为单独的一个文件夹；为hexo博客系统的source文件夹添加git管理，并在每次generate的时候都commit一次。</em></p><p><em>以后再要测试一些新的东西的时候，一定要把其可能影响到的文件保护好，一旦丢失（比如先复制一份到其他文件夹下），想要找回实在是太难了（一晚上没有睡，就整这个了。。）</em></p><h2 id="introduction">Introduction</h2><ol type="1"><li>组学数据，或者更进一步的多组学数据，存在“维度灾难”的问题，需要使用变量筛选或降维的方法来进行预处理。</li><li>基于DL领域的特征提取方法（如VAE）在其他领域已经显现出其作用，但在组学领域还没有得到足够的研究。</li><li>本文提出了OmiVAE模型，其可以：<ul><li>基于VAE的降维；</li><li>整合classification到VAE模型中进行end-to-end的学习，可以得到task-oriented的features；</li></ul>本研究使用tcga的PanCancer multi-omics数据（33/34癌症类型分类）验证了OmiVAE的性能，发现其可以学习到有效的特征。</li></ol><h3 id="相关工作">相关工作</h3><p>受到CV和NLP领域的启发，DL领域的许多算法被应用到多组学领域：</p><ol class="example" type="1"><li>【6】使用AE来对多组学数据进行降维，并在此基础上使用kNN和SVM得到了有生存差异的亚组。</li><li>【7】提出了基于LSTM的VAE模型用于建模代谢组学、蛋白质组学的时间序列数据。</li></ol><p>以上提到的研究构建的模型都不是end-to-end，</p><ol start="3" class="example" type="1"><li>【8】提出了提出了一个end-to-end的multi-omics模型，使用factorization AE来预测无病生存期，得到了0.664（膀胱癌）和0.746（胶质瘤）的avPR。</li></ol><p>至于癌症分类领域：</p><ol start="4" class="example" type="1"><li><p>【9】将PCA和spAE结合来学习gene expression的表示来进行癌症分类。</p></li><li><p>【10】则使用sdAE。</p></li><li><p>【11】使用VAE来提取gene expression的latent representation，然后再分析其和表型间的联系。</p></li><li><p>【12，13】使用VAE来分析methylation数据。</p></li><li><p>【14】将GCN和relation network结合，来进行乳腺癌亚型分类，并使用到了PPI数据。</p><blockquote><p>这篇看过</p></blockquote></li><li><p>【15】开发了一个CNS系统来进行癌症分类，其基于DNA methylation数据和RF。</p></li></ol><p>以上的模型大多集中特定的某个癌症类型，至于在pan-cancer领域：</p><ol start="10" class="example" type="1"><li>【16】使用knn模型和遗传算法来对TCGA Pan-cancer数据进行处理，得到了95.6%的预测acc。</li><li>【17】将gene expression转变成2D images，然后使用CNN进行33类分类任务，得到了95.59%的avACC。</li><li>【18】使用CNN应用到相同的数据上，得到了95.7%的ACC和95%的ACC（34类分类）。</li></ol><h2 id="methods">Methods</h2><h3 id="数据">数据</h3><p>TCGA pan-cancer的RNAseq数据和DNA methylation数据，共有33种癌症:</p><ul><li>gene expression （RNAseq）：11538 samples，其中741 normal samples，外显子标记60483个，使用的数据格式是FPKM的log2转换值。</li><li>DNA methylation：使用450K的数据，共有485578个探针，9736个样本，其中746个normal samples，使用的数据格式是beta值（探针对应CpG位点的甲基化率）。</li></ul><h3 id="数据预处理">数据预处理</h3><ul><li><p>gene expression：</p><ol type="1"><li>将位于Y染色体的基因（594）、全部都是0值的基因（1904）和有超过10%样本缺失的基因（248）去除；</li><li>最终去除2440个分子特征，保留58043。</li></ol></li><li><p>DNA methylation：</p><ol type="1"><li>将无法映射到hg38标记（89512）、在Y染色体上的（346）、超过10%样本是缺失值的（414）probes去掉；</li><li>最终得到392761个CpG位点，然后将这些CpG位点根据其所属染色体，分到23个组中，每个组平均拥有的probes数量是17077。</li></ol></li><li><p>缺失值使用均值填补，FPKM的log2值被归一化到0-1间，Beta值不用变（因为作为率，其本身就在0-1之间），然后保留在两类数据集中都有的样本（9081，其中407个normal samples）。</p></li></ul><h3 id="网络架构">网络架构</h3><p>如果fig1所示：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-25-24.png" alt="OmiVAE网络架构"><br></p><p><em>关于VAE原理的部分不再赘述，只是将其ELOB公式粘贴在下面，供参考。</em></p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-37-13.png"><br></p><p>关于网络架构的要点：</p><ol type="1"><li><p>为了能够处理methylation data的高维度，先分别对单个染色体上的位点进行映射（每个染色体映射至256），然后再合并。</p></li><li><p>将合并后的methylation特征再映射一次（1024），才和也映射到1024的expression特征（--&gt;4096--&gt;1024）cat。</p></li><li><p>瓶颈层是128维/2维（用于可视化）。</p></li><li><p>从瓶颈层的均值部分接一个（--&gt;128--&gt;64--&gt;33/34）的网络进行end-to-end的分类训练，所以使用的是下面的loss：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-35-06.png"><br></p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-34-41.png"><br></p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-35-51.png"><br></p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-36-16.png"><br></p></li><li><p>这里有两个training phase：</p><ul><li>如果是unsupervised phase，就使用式4（实际上就是ELBO的具体形式，或者是式7，但beta值设为0）来训练VAE部分；</li><li>如果是supervised phase，则先进行unsupervised phase（看做是预训练），然后使用式7（其中beta值是1）进行微调。</li></ul></li></ol><p>Implementation：</p><ul><li>使用的隐层激活函数是ReLU，decoder的输出层是sigmoid，分类使用softmax。</li><li>使用PyTorch（1.1）。</li><li>使用了2块1080Ti，一个用来放decoder，一个用来放encoder训练。</li><li>Adam，lr=10-3，batch size=32，early stopping。</li></ul><h2 id="results">Results</h2><p>使用10-CV来评价性能</p><h3 id="无监督过程">无监督过程</h3><p>先把瓶颈层的维度设置成2，看VAE的可视化能力：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-49-55.png" alt="OmiVAE可视化"><br></p><p>可以明显看到其要优于PCA。</p><p>再进一步拿出单独的几个癌症来看：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-11-56-20.png" alt="OmiVAE可视化-单独的癌症"><br></p><p>结合上面的图像，可以看到以下结论：</p><ul><li>OmiVAE不止能够将各个癌症类型分开，而且对于癌症的亚型，也能分开。</li><li>OmiVAE也能够将癌症和对应的normal sample分开。</li><li>从整体上来看，对应癌症的normal samples是和对应的癌症样本在一起的，然后在局部他们再分开。</li></ul><p>为了评价VAE提取的特征是否优于其他方法，这里进行实验：</p><ul><li>比较的方法有PCA、kernelPCA、t-SNE、UMAP。</li><li>都降到2维，然后使用rbf-SVM进行34类分类任务，结果如下表所示：</li></ul><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-12-02-18.png" alt="2维特征的分类效果"><br></p><p>可以明显看到OmiVAE的优势。</p><blockquote><p>这里最接近OmiVAE的是t-SNE，但其还有以下另外两个缺点：</p><ol type="1"><li>t-SNE非参数的，无法应用到其他数据集；</li><li>t-SNE只能降维到2-3维，对于更高维度的降维不适用。</li></ol></blockquote><h3 id="监督过程">监督过程</h3><p>为了保留更多的信息，这里将瓶颈层维度设为128进行。</p><p>这里比较了一下end-to-end的OmiVAE和使用瓶颈层特征+SVM的效果差异。首先是34类分类任务：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-12-07-41.png" alt="34分类任务结果"><br></p><p>以上结果超越了之前同类研究的表现【18】。</p><p>另外，128维特征（经过了监督过程微调）使用t-SNE进一步可视化，发现各个癌症类型可以比较好的分开，说明了微调过程使得特征学习偏向了癌症类型分类：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-12-14-27.png" alt="分类特征可视化"><br></p><p>同样的，也进行了33类分类任务的比较，效果如下图所示：</p><p><img src="/2020/05/21/paper/omics/vae-jian-mo-pancancer2019/VAE建模PanCancer2019_2020-05-21-12-15-38.png" alt="33分类任务结果"><br></p><p>其结果也超越了之前的研究结果（【16-18】）。</p><h2 id="conclusion">Conclusion</h2><p><em>没什么营养。</em></p><hr><h2 id="questions">Questions</h2><p><em>文章最大的亮点，在我看来，是利用染色体分组来减少参数量，这同样增加了一定的生物学先验信息到模型中。那通过进一步考虑基因等在染色体上的相对位置，是否有更好的效果能？</em></p><ol type="1"><li><em>将Y染色体的基因去除是否不妥，其存在可能会对男性高发癌症（前列腺癌、膀胱癌、肺癌等）起到积极的意义。</em></li><li><em>gene expression去除变量的数量有点对不上？</em></li><li><em>文章中只提到了beta值的设置，但alpha值没有提？</em></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
            <tag> VAE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-PAMOGK-2019</title>
      <link href="/2020/05/19/paper/omics/pamogk2019/"/>
      <url>/2020/05/19/paper/omics/pamogk2019/</url>
      
        <content type="html"><![CDATA[<h1 id="pamogk-a-pathway-graph-kernel-based-multi-omics-clustering-approach-for-discovering-cancer-patient-subgroups">PAMOGK: A Pathway Graph Kernel based Multi-Omics Clustering Approach for Discovering Cancer Patient Subgroups</h1><ul><li>杂志: bioRxiv</li><li>IF: ---</li><li>分区: ---</li><li><a href="https://github.com/tastanlab/pamogk" target="_blank" rel="noopener">github</a></li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>cancer是一个分子多样性基本，能够分离出不同的分子亚型对于疾病的诊断和治疗将有重大的意义；</p></li><li><p>多个组学的数据有助于研究者对cancer病人的认识【48,46,9】，因此基于多组学的cluster methods被广泛研究【35】：</p><ul><li><p>最简单的就是把所有组学的数据concatenated，但带来了问题：维度灾难、每个组学的权重相同。</p></li><li><p>iClusterBayes及其变体【42, 30, 29】、LRACluster应用一些降维方法和正则化方法来试图解决上述问题。</p></li><li><p>另一种策略：分别在每个组学中进行聚类，然后再将多个组学的结果集成。这一类方法有一致性聚类【31】、PINS【34】、COCA【17】等。其缺点是无法捕捉各个组学间的相互关系。</p></li><li><p>之后，一批intermediate integration algorithm被开发出来【36】：</p><ol type="a"><li>SNF【51】先为每个数据类型构建一个patient similarity network，然后使用一些算法（比如message passing）来将这些network融合在一起；</li><li>【28】则提出一种降维策略，其维度被转换到多个组学间最大协方差的方向；</li><li>【27】提出了JIVE；</li><li>MCCA【54,5】则将CCA扩展到了多组学领域；</li><li>【21,7】将谱聚类【50】扩展到了多组学领域，谱聚类可以看做是一种kernel method；</li><li>【56,45,13】一系列generic multi-view kernel cluster methods也被扩展到多组学领域。</li></ol></li></ul><blockquote><p>这里对multi-omics（多组学）和multi-view（多视图）进行一下解释。</p><p>multi-view表示的是对于同一种事物，我们使用多种途径或多种角度来进行描述，由此形成的数据称为multi-view datasets，而基于此的机器学习门类称为multi-view learning。</p><p>multi-omics则是一个组学、生物信息学的概念，即使用多个组学的数据来共同分析。注意到，这多个组学可能并不是同一样本的数据。</p><p>所以对于两者来说，是有交叉的：当multi-omics数据是同一批病人的不同组学数据时，这实际上就是一个multi-view问题。</p><p>当然，两者在概念上也有一定的区别，multi-view更多是一个机器学习的概念，而multi-omics是一个生物信息学的概念或者组学的概念，有点类似CV和医学影像处理之间的关系。</p><p>还有一个多模态学习（multimodal），这是multi-view的一个子集，指的是人的不同感官的数据，或对于同一个事物使用不同的方法收集到的数据。</p></blockquote></li><li><p>可能单纯地使用多个组学还不足以明晰病人间的相似性，配合分子网络的稀疏性【8】可能更好。</p></li><li><p>本研究提出PAMOGK方法。其将每个病人视为一个有标签的无向图，结合一个novel graph kernel - SmSPK来提取病人的相似性。然后可以将病人分到不同的亚组中，并提供了每个pathway、组学对聚类所做的贡献。</p></li><li><p>本研究将此方法应用到TCGA-KIRC数据集（somatic mutations、gene expression、protein expression）中，得到了4个亚组，并在生存上存在差异。</p></li></ol><h2 id="methods">Methods</h2><p><span class="math inline">\(S\)</span>表示病人集合，我们的目的是希望得到一个划分<span class="math inline">\(\{C_i\}\)</span>，<span class="math inline">\(M\)</span>表示pathways的数量，<span class="math inline">\(D\)</span>表示组学数据数量，<span class="math inline">\(N\)</span>表示病人的数量。</p><h3 id="overview">overview</h3><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-19-17-52-39.png" alt="PAMOGK概述"><br></p><p>主要包括3步：</p><ol type="1"><li>对于每个组学，将其映射到pathway中，每个patients被表示成<span class="math inline">\(M\times D\)</span>的graph；</li><li>使用SmSPK来定量两个patients间的相似性（kernel matrices）；</li><li>使用multi-view clustering algorithms，利用第2步得到的kernel matrices，将patients分离到有意义的亚组中。</li></ol><h3 id="step1-patient-graph-representation">step1-Patient graph representation</h3><p>对于pathway i和patient j，我们得到graph <span class="math inline">\(G_i^j=(V_i, E_i, l_i^j)\)</span>。其中<span class="math inline">\(V_i\)</span>是该pathway中的基因set，<span class="math inline">\(E_i\)</span>是该pathway中存在的基因之间的调控关系（没有方向），<span class="math inline">\(l_i^j\)</span>表示patient j在各个基因上的值（因为本研究中使用的都是binary的数据，所以这里的值就是0-1）。</p><p>显然，对于同一个pathway来说，所有patients的graph的结构是相同的，不同的只是那个<span class="math inline">\(l_i^j\)</span>。</p><p>最终我们得到<span class="math inline">\(N\times M\times D\)</span>个labeled pathway graphs。</p><h3 id="step2-computing-multi-view-kernels-with-graph-kernels">step2-Computing Multi-View Kernels with Graph Kernels</h3><ol type="1"><li><p>graph kernel function输入两个graphs，输出这两个graphs间的相似性【49】，已经有许多graph kernel function【43,4,33】，但这些都是输入的不同结构的graphs来通过结构的差异来确定两个图的相似性，并不适合当前的任务，所以本研究自己建立了一个新的graph kernel。</p></li><li><p>基于shortest path graph kernel【4】，开发得到SmSPK：</p><ul><li><p>首先进行label propagation（即随机游走），得到smoothed graph，其计算公式为：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-09-32-00.png"><br></p><p>其中，<span class="math inline">\(g\)</span>表示pathway graph，<span class="math inline">\(t\)</span>表示step，<span class="math inline">\(A_g\)</span>是pathway <span class="math inline">\(g\)</span>的度归一化邻接矩阵，<span class="math inline">\(S_g(0)\)</span>就是<span class="math inline">\(l\)</span>，<span class="math inline">\(\alpha\in[0,1]\)</span>是用来定义光滑度的参数。</p><p>进行迭代计算，直到收敛，然后我们得到了label smooth graphs。</p></li><li><p>对于两个人在相同通路下的相似性，这样计算：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-09-46-57.png"><br></p><p>其中，<span class="math inline">\(s_p^{(i)}\)</span>表示smoothed图<span class="math inline">\(G_g\)</span>在patient <span class="math inline">\(i\)</span>上的最短路径<span class="math inline">\(p\)</span>上的节点组成的向量，<span class="math inline">\(P\)</span>表示最短路径的数量。</p></li><li><p>经过上述计算，我们得到<span class="math inline">\(M\times D\)</span>个<span class="math inline">\(N\times N\)</span>的matrices。</p></li></ul><p><em>注意，这里的逻辑是，我们将图进行随机游走，如果图上每个节点的值是先验的概率，则经过随机游走后得到的是最终会出现在各个点上的概率。这一定程度上是综合了节点值和图结构的embedding，然后用这个embedding来计算两个图的相似性。</em></p><p><em>要深入理解这里graph kernel的内容，可能需要去了解相关知识。</em></p></li><li><p>这里为了能够将多组学信息融合，本研究了存在的multi-view kernel clustering methods，发现multiple kernel k-means中matrix-induced regularization（MKKM-MR，【25】）效果最好，所以本研究采用这个方法，当然也可以使用其他的方法：</p><ul><li><p>Multiple Kernel K-Means with Matrix-Induced Regularization（MKKM-MR）：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-10-33-11.png"><br></p><p><em>大体的思想是去找一个所有kernel matrices的最佳组合来做聚类。</em></p><p>其中<span class="math inline">\(m\)</span>表示使用的kernel matrices的数量，<span class="math inline">\(n\)</span>表示样本的数量，<span class="math inline">\(k\)</span>表示的聚类数量，<span class="math inline">\(\gamma=[\gamma_1,\cdots,\gamma_m]\)</span>是在融合所有kernel matrices时每个kernel matrix的权重，<span class="math inline">\(K_{\gamma}=\gamma_1D_1+\cdots+\gamma_mD_m\)</span>，<span class="math inline">\(D_i\)</span>是第<span class="math inline">\(i\)</span>个kernel matrix，<span class="math inline">\(M\)</span>是各个kernel matrices间的关系的度量，<span class="math inline">\(I_x\)</span>是<span class="math inline">\(x\times x\)</span>的identity matrix，<span class="math inline">\(1_m\)</span>是值全为1的m维向量，<span class="math inline">\(\lambda\)</span>是来调节正则化的参数。</p></li><li><p>Average Kernel K-Means （AKKM）：就是使用Kernel K-means（KKM）【39】，使用的Kernel是所有的Kernel matrices的平均。</p></li><li><p>Localized multiple kernel K-means（LMKMM）【13】。</p></li></ul></li></ol><h2 id="results-and-discussion">Results and Discussion</h2><h3 id="数据">数据</h3><ol type="1"><li><p>pathway数据：来自NDEXBio【38】的NCI-PID（2019-04-24下载），专注于癌症研究，将和omics数据中没有任何重叠genes的pathway去掉，还剩下165个pathways。</p></li><li><p>病人的分子数据和临床数据：</p><ol type="a"><li>使用TCGA PanCancer的KIRC数据（来自<a href="https://www.synapse.org/#!Synapse:syn300013" target="_blank" rel="noopener">Synapse</a>），使用了三种类型的数据（RNAseq gene expression，RPPA，somatic mutation）；</li><li>只使用其中的primary solid tumour samples；</li><li>删除了在超过一半样本中没有表达的genes；</li><li>对于RPPA，只使用没有磷酸化的蛋白表达；</li><li>通过GDC得到临床信息；</li><li>在3个组学上都有，而且生存信息完整的病人被保留，共得到<strong>361个patients，236个right-censored，125个passed away。</strong></li></ol></li><li><p>将分子数据融入graph中：</p><ol type="a"><li>计算gene和protein的z-scores，然后对于z-score大于1.96的看做是overexpressed，z-score小于-1.96的看做而是underexpressed。</li><li>最终得到5中binary的数据，即somatic mutation、RNAseq的over/underexpressed data、RPPA的over/underexpressed data。</li></ol></li></ol><h3 id="实验设置">实验设置</h3><ol type="1"><li>得到了825个kernel matrices （165 x 5）。</li><li>试验了聚类数<span class="math inline">\(k=2,3,4,5\)</span>，12种不同的<span class="math inline">\(\alpha\)</span>，并试验了上面提到了3种multi-view clustering methods。</li><li>将kernel matrix中非0值少于1%的kernel matrices删除以增加运行速度。</li><li><span class="math inline">\(\lambda\)</span>用grid-search选择。</li><li>评价指标使用生存分析【2,22,1,12】，即绘制K-M曲线和计算log-rank p值来进行比较。</li></ol><h3 id="新的graph-kernel的必要性">新的graph kernel的必要性</h3><p>必要性：其他的graph kernel只能检测拓扑结构的相似性，而对于拥有相同拓扑结构但不同值的graph，其检测能力不足，所以开发了SmSPK。</p><p>比较：使用the densest kernels数据（overexpressed genes）来作为评价数据集，然后比较了SmSPK、shortest path kernel【4】、propagation kernel【33】、Weisfeiller Lehman subtree kernel【43】。</p><p>软件：Grakel library。</p><p>计算：将每一个kernel matrix中的值都分到不同的bins中，然后计算这个kernel matrix在不同bins中的频率，然后将所有kernel matrices的频率进行平均，结果如fig2a显示：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-23-57.png" alt="各个kernel method的平均相似性"><br></p><p>结果：可以看到，除了SmSPK之外，其他的方法大多认为patients间的相似性应该是1，这说明结构相同的graphs，这些kernel无法检测出其之间的差别，若SmSPK对这些差别是敏感的。</p><h3 id="应该使用mkkm-mr">应该使用MKKM-MR</h3><p>这里比较了多种multi-view clustering methods，每种聚类方法在使用的时候可以自动进行超参数的调整（聚类数<span class="math inline">\(k\)</span>，光滑参数<span class="math inline">\(\alpha\)</span>，RBF kernel的参数<span class="math inline">\(\gamma\)</span>，MKKM-MR的<span class="math inline">\(\lambda\)</span>）。</p><p>并且也使用了不同的kernel methods，防止kernel methods对multi-view clustering methods的影响。但因为之前已经证明了除了SmSPK之外的methods无法找到patients之间的差异性，所以这里只选择了shortest path kernel（最相近的），另外还选择了RBF kernel来看graph kernel是否有必要。结果如fig2b所示：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-33-31.png" alt="k=4,不同multi-view聚类方法的比较"><br></p><p>结果显示，MKKM-MR配合SmSPK，在<span class="math inline">\(k=4,\alpha=0.3,\lambda=8\)</span>时，得到最好的结果（p=7.4e-10），其K-M plots在下面（<span class="math inline">\(k=3\)</span>时也不错，在附录中有展示）：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-36-47.png" alt="k=4时，PAMOGK subgroups的K-M plots"><br></p><h3 id="和当前最好的多组学方法比较">和当前最好的多组学方法比较</h3><p>和其中8种方法进行了比较，这些方法在【36】中有介绍，这里使用的超参数是各自在benchmark study中的配置（除了聚类数），聚类数则是设置一个最大值，然后选择各自最好的。</p><p>抽取了300个patients，进行聚类。将上述过程重复10次，来比较不同方法。fig3b显示PAMOGK的效果是最好的。</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-43-39.png" alt="不同多组学聚类方法的比较"><br></p><p>另外，还比较了一下运行速度：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-45-04.png" alt="不同多组学聚类方法的速度比较"><br></p><h3 id="pamogk的kirc亚组分析">PAMOGK的kIRC亚组分析</h3><ol type="1"><li><p>和临床指标的关系：发现和年龄、性别是没关系的，但和其他的都有关系，结果如下：</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-47-33.png" alt="亚组和临床信息"><br></p><p>cluster 1（预后最好的一组）的病人有更低的stage和grade，而cluster 4（预后最不好的一组）的病人有更高的stage和grade，这表明PAMOGK的亚组是有临床意义的。</p></li><li><p>也可以通过<span class="math inline">\(\gamma\)</span>来判断哪个组学、哪条通路是更加重要的：</p><ul><li><p>IL-6 mediated signaling events + gene overexpression是最重要的；</p></li><li><p>通过平均权重，可以得知gene expression是最重要的data type，而protein expression几乎没有影响（可能是因为RPPA数据中的genes数量太少了）；</p></li><li><p>最高权重的通路是IL-6 mediated signaling events。</p><p><img src="/2020/05/19/paper/omics/pamogk2019/PAMOGK2019_2020-05-20-11-55-24.png" alt="patway的贡献"><br></p></li></ul></li></ol><h2 id="conclusion">Conclusion</h2><p>本研究的局限性：使用的TCGA数据，即bulk数据，这些数据是多种类型细胞的混合，有比较强的intra-tumor heterogeneity【10】。所以未来可以将PAMOGK应用到单细胞数据上。</p><p>还有许多方向可以探索：将binary扩展到continuous；SmSPK是基于shortest path kernel而来，可能有其他更好的选择；考虑graph的方向性；考虑蛋白质交互作用网络。</p><hr><h2 id="questions">Questions</h2><p><em>这篇论文写的还是挺不错的，很清楚。但其中关于multi-view clustering的技术和graph kernel的技术我并不太擅长，这可能影响了我对本文的理解，所以之后要多看一些这方便的内容了。</em></p><p><em>本研究中比较让我感兴趣的是其中的fig2a，这里显示其改进得到的SmSPK kernel确实可以比其他的kernel更加关注于graph labels的内容，而不把宝都压在graph topology。我对原本的graph kernel的方法并不太清楚，所以我也不知道作者的那一部分修改使得效果这么立竿见影。但随之而来一个要问的问题是：SmSPK是否能够在graph topology不同的graphs中起到效果，即它是否既能够有效的捕获labels information，又能够提取topology的information呢？</em></p><p><em>本研究的最后表示，使用bulk的数据已经是一个缺点了（:(），看来单细胞是大势呀。</em></p><p><em>关于kernel的方法可以赶紧学一下，说不定能够和深度学习产生一些火花。</em></p>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Omics </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> Cluster </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-基于RNN的GRN-2016</title>
      <link href="/2020/05/17/paper/omics/rnn-jian-wang-2016/"/>
      <url>/2020/05/17/paper/omics/rnn-jian-wang-2016/</url>
      
        <content type="html"><![CDATA[<h1 id="recurrent-neural-network-based-hybrid-model-of-gene-regulatory-network">Recurrent Neural Network Based Hybrid Model of Gene Regulatory Network</h1><ul><li>杂志: Computational biology and chemistry</li><li>IF: 1.581</li><li>分区: 4区</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>建模生物网络的目的：</p><ul><li>网络的模式可以提供更好的、在整体上的、关于交互和关联的理解；</li><li>允许研究者对gene的功能进行预测并验证；</li><li>分子和细胞间交互作用的复杂性，使得我们也对这种能够设计和解释实验结果的建模工具有着巨大的需求；</li><li>对于理解细胞行为是关键的，可能会启发更好的治疗方法；</li><li>可以预测更多的未知的生物大分子；</li><li>可以为药效模拟提供依据。</li></ul></li><li><p>基因调控网络（gene regulatory networks, GRNs）</p><ul><li>包括了输入信号通路、接受输入信号的调控蛋白、靶基因、靶基因产生的RNA和蛋白质等。</li><li>可能还有动态的反馈调节。</li><li>使用graph的形式来表示，其中node是genes，edge是调控关系。是一个directed graph。</li></ul></li><li><p>本研究提出了一种hybrid方法，基于RNN，并整合了generalized extended Kalman filter。</p></li></ol><h2 id="建模grns的方法">建模GRNs的方法</h2><p><em>文章中列举了很多，这里就只把其分类说一下就好了</em></p><ul><li>Directed Graph</li><li>Boolean networks</li><li>Bayesian networks</li><li>linear and non-linear ordinary differential equations（ODEs）</li><li>machine Learning approaches</li></ul><p><em>之后介绍的大多数方法都是基于ML的了，而且大多数是基于NNs的了</em></p><ul><li>【Vohradsky, 2001】使用ANN来进行建模，但模型参数过多；</li><li>【Keedwell et al., 2002】简化了上述模型，并且使用标准的BP算法来进行学习；</li><li>【Tian &amp; Burrage, 2003】使用了随机神经网络来建模GRNs；</li><li>【Xu et al., 2004】则使用RNN来进行建模，使用BPTT和PSO（粒子群算法）来进行学习；</li><li>【Chiang &amp; Chao, 2007】将GA和RNN杂交（GA-RNN）去进行学习；</li><li>【Xu et al, 2007b】提出了PSO-RNN；</li><li>【Xu et al., 2007a】进一步去试验了另外的3种优化方法：DE、PSO、DE-PSO，发现DE-PSO和RNN的结合是最好的；</li><li>【Ghazikhani et al., 2011】提出了一个基于multi-population PSO算法的模型，在SOS repair network的构建中体现除了更好的效果；</li><li>【Noman et al., 2013】提出了decoupled-RNN model，decoupled意味着其将参数的估计分成几部分进行，从而提高了效率，使得对于大规模网络的建模称为可能；</li><li>【Raza et al., 2014】，这是作者的早期研究，使用了一种进化算法-ACO来找到genes间的关键交互。</li></ul><h2 id="methods">Methods</h2><h3 id="rnns">RNNs</h3><p><em>这一部分涉及RNNs基础的，就不再赘述了。</em></p><p><em>从后面对于模型的叙述并结合这一部分的RNNs的介绍，这里的RNNs并不是DL中的RNNs，而更像是前DL时代中的RNNs</em></p><h3 id="基于rnns的grns模型">基于RNNs的GRNs模型</h3><p>假设：特定基因上的调控效应可以表示为NN的形式，其中节点表示的是gene，链接表示的是调控关系。</p><p>根据【Rui et al., 2004; Hu et al., 2005; Noman et al., 2013; Raza, 2014】，GRNs的模型可以表示为以下的格式：</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-17-12-05-19.png"><br></p><p>其中<span class="math inline">\(e_i\)</span>表示基因<span class="math inline">\(i\)</span>的表达水平，<span class="math inline">\(n\)</span>表示所有的genes的数量，<span class="math inline">\(f\)</span>是一个非线性函数，一般使用sigmoid（<span class="math inline">\(f(z)=1/(1+exp(-z))\)</span>），<span class="math inline">\(w_{ij}\)</span>表示gene <span class="math inline">\(j\)</span>对gene <span class="math inline">\(i\)</span>的调控权重。<span class="math inline">\(u_k\)</span>表示的是外部变量，<span class="math inline">\(v_{ik}\)</span>表示的是外部变量对gene <span class="math inline">\(i\)</span>的影响。<span class="math inline">\(\tau_i\)</span>是一个时间常数，<span class="math inline">\(\beta_i\)</span>是偏置项，<span class="math inline">\(\lambda_i\)</span>是衰减率参数。</p><p>我们可以知道，<span class="math inline">\(w_{ij}\lt0\)</span>表示gene <span class="math inline">\(j\)</span>对gene <span class="math inline">\(i\)</span>是抑制作用，而<span class="math inline">\(w_{ij}=0\)</span>表示gene <span class="math inline">\(j\)</span>对gene <span class="math inline">\(i\)</span>没有调控作用。</p><p>上面公式也可以写成下面的离散形式：</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-17-12-14-07.png"><br></p><h3 id="使用bptt来训练">使用BPTT来训练</h3><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-17-12-37-59.png"><br></p><h3 id="kalman-filter">Kalman filter</h3><p>关于卡尔曼滤波器的基本信息，可以查看<a href="https://en.wikipedia.org/wiki/Kalman_filter" target="_blank" rel="noopener">wiki</a>。</p><p><a href="https://zhuanlan.zhihu.com/p/39912633" target="_blank" rel="noopener">这里</a>是一个关于kalman filter的解释，可能更加容易理解。</p><blockquote><p>一个时间序列，我们已知一个时间点<span class="math inline">\(t\)</span>的最佳估计（当然这个估计也是随机的，有一个方差），我们有两种方式来得到下一个时间点<span class="math inline">\(t+1\)</span>的估计：</p><ul><li>根据时间点间的关系进行<strong>预测</strong>、</li><li>直接在下一个时间点进行测量或<strong>观测</strong>。</li></ul><p>但还有一个更好的方式，就是将这两种方式结合，此即<strong>卡尔曼滤波</strong>。</p><p>简单来说，就是通过计算<strong>预测</strong>和<strong>观测</strong>各自的方差，利用方差做权重来调整对下一个时间点的估计。如果利用贝叶斯的观点来说，<strong>预测</strong>得到的结果可以看做是下一个时间点的先验估计，而<strong>观测</strong>可以看做是样本，然后调整先验估计，得到后验估计。</p><p>在kalman filter的命名中，<strong>预测</strong>即predict，而<strong>观测</strong>进行调整的过程即correct。</p><p>如果上一个时间点的估计是精确的，即此时方差为0，则计算权重的时候将不会再为<strong>观测</strong>分配权重，则整个时间序列过程退化为一个确定性过程。</p><p>更加general的模型还会有一个外部环境影响因素，这个也是一个随机变量，则此时，就算是初始估计是精确地，因为此随机外部环境的影响，我们也无法忽略<strong>观测</strong>过程。</p><p>在本文的例子中，RNN所预测的权重被看做是一个<strong>预测</strong>。</p><p>对于本文用到的generalized extended kalman filter （GEKF），是更加general的清楚，将非线性的过程加入其中。</p></blockquote><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-17-14-36-38.png" alt="GEKF for RNNs"><br></p><p><em>如何把RNN的weight matrix应用到Kalman filter中进行处理，这一段没有看懂？？？</em></p><h3 id="工作流程">工作流程</h3><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-17-12-15-20.png" alt="工作流"><br></p><ol type="1"><li>读取microarray数据（时间序列数据或者稳态数据），并进行预处理和标准化；</li><li>模型训练；</li><li>读取模型的weight matrix，将其离散化为0和1；</li><li>将离散化的matrix可视化；</li><li>和true network进行比对，对结果进行评价。</li></ol><h2 id="results-and-discussion">Results and Discussion</h2><p>本方法一共在4个数据集（2个real、2个simulated）上进行了验证和比较。</p><h3 id="sos-dna-repair-networks">SOS DNA repair networks</h3><p>使用proposed method得到weight matrix，然后应用Inter-Quartile离散化，得到结果如下：</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-13-59-23.png" alt="在SOS-DNA修复网络评价"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-00-32.png" alt="在SOS-DNA修复网络上和其他方法的比较"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-01-18.png" alt="在SOS-DNA修复网络上和其他方法的比较2"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-04-33.png" alt="SOS-DNA修复网络基因表达量预测-uvrD"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-05-41.png" alt="SOS-DNA修复网络基因表达量预测-lexA"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-06-10.png" alt="SOS-DNA修复网络基因表达量预测-umuDC"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-06-42.png" alt="SOS-DNA修复网络基因表达量预测-recA"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-07-15.png" alt="SOS-DNA修复网络基因表达量预测-uvrA"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-07-40.png" alt="SOS-DNA修复网络基因表达量预测-ruvA"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-08-05.png" alt="SOS-DNA修复网络基因表达量预测-polB"><br></p><h3 id="in-vivo-reverse-engineering-and-assessment-yeast-network-irma">in-vivo reverse-engineering and assessment yeast network （IRMA）</h3><ol type="1"><li><p>switch OFF状态</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-26-22.png"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-27-02.png"><br></p></li><li><p>swith ON状态</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-27-29.png"><br></p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-27-45.png"><br></p></li></ol><h3 id="silico-networkssimulated-datadream4">silico networks（simulated data，DREAM4）</h3><ol type="1"><li><p>DREAM4 10-genes network：</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-28-48.png"><br></p></li><li><p>DREAM3 50-genes network:</p><p>一共125条调控作用，预测到其中的121条，但有662条假阳性预测，得到了0.76的sensitivity和0.72的specificity。</p></li></ol><h3 id="模型的稳健性">模型的稳健性</h3><p>在silico 10-genes data上加了5% std的高斯噪声，发现proposed method还是能够得到不错的预测：</p><p><img src="/2020/05/17/paper/omics/rnn-jian-wang-2016/RNN建网2016_2020-05-19-14-32-20.png"><br></p><h2 id="conclusion">Conclusion</h2><p>本文提出了一种基于RNN的基因调控网络构建方法，其混合使用Kalman filter对weight matrix进行进一步的增强。在4个数据集上进行了验证，发现在前3个数据集上都能够超越之前的建网方法。另外，还进行了稳健性的验证，也得到了不错的结果。</p><p>基因调控网络的构建依然面临着诸多问题：维度灾难问题、数据的异质性（比如批次）噪声、不可靠数据等，有待进一步解决。</p><hr><h2 id="questions">Questions</h2><p><em>读过本文后才发现，本文并不是deep learning意义上的RNNs的应用，这里RNNs的定义还带有前DL时代的影子。这里的RNNs只是单层的，其应用的目的也只是为了解决一个普通的时间序列预测问题。</em></p><p><em>在我看来，本文的主要贡献是在于在RNNs之后又应用了kalman filter进行进一步的校正。这样的组合让我想起了我研究生期间研究的一种建网策略：即先利用建网方法进行网络建立，然后使用一些方法来删除其中的假阳性预测。我想这两者之间在策略、哲学上还是有共同之处的。</em></p><p><em>通过阅读本论文，我第一次、一定程度地了解了Kalman filte的知识，希望在之后的研究中有帮助吧。</em></p><p><em>但本研究对于RNN和filter的组合太过生硬了，而且实验使用的数据集gene的数量也不多，还没有到达组学的范畴。</em></p><p><em>本文所叙述的一些内容（使用的数据集，kalman filter等）我是第一次接触，所以读起来还是有些磕磕绊绊，results部分也是简单的浏览了一下表格和图，没有进行深入的理解。</em></p><p><em>下面的是我在阅读时产生的问题，权当是为了记录而记录，便于当之后的研究需要本文时有个快速回忆的锚点。</em></p><ol type="1"><li><em>在这个kalman filter过程中，什么充当了观测的角色？</em></li></ol>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Method </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读-深度学习组学应用-2018综述</title>
      <link href="/2020/05/15/paper/omics/dl-in-omics2019/"/>
      <url>/2020/05/15/paper/omics/dl-in-omics2019/</url>
      
        <content type="html"><![CDATA[<h1 id="deep-learning-in-omics-a-survey-and-guideline">Deep learning in omics: a survey and guideline</h1><ul><li>杂志: Briefings in functional genomics</li><li>IF: 3.133</li><li>分区: 2区</li></ul><hr><h2 id="introduction">Introduction</h2><ol type="1"><li><p>1943年MCP原型首次提出【1】--&gt; Rosenblatt提出感知机模型【2】--&gt; 1974年首次提出了back propagation（bp，反向传播算法）【3】--&gt; 2006年Hinton首次解决了梯度消失问题并显示了DL技术的重大潜力【4】。之后，因为：</p><ul><li>数据量大，数据维度高且复杂使得传统Machine Learning（ML）方法变得吃力；</li><li>硬件发展使得计算能力达到要求；</li><li>DL社区，特别是想Google的大公司推动了DL技术的发展；</li></ul><p>DL得到了空前的发展。其中也包括一系列bioinformatics领域的应用：</p><ul><li>利用电子病历数据进行疾病预测【5,6】；</li><li>生物医学图像分类【7-10】；</li><li>生物信号处理【11-13】；</li></ul></li><li><p>现代omics研究面临两个难题：</p><ul><li>在诊断、预测等应用领域，实验室方法昂贵且费时；</li><li>现存数据复杂、多态，传统方法已经难以处理；</li></ul></li></ol><p>但这些难题都有望被深度学习克服。</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-16-51-26.png" alt="深度学习及其在omics上的应用的文章数量变化"><br></p><h2 id="dl-models-in-omics">DL Models in Omics</h2><blockquote><p>这里涉及到很多基础的DL知识的，就不赘述了。</p></blockquote><h3 id="dnns">DNNs</h3><p>这里指代了MLP、AEs、RBMs和DBNs【4】等多种模型。其中DBNs解决了蛋白质残基连接预测【27】和RNA结合蛋白位点预测问题【28】。</p><h3 id="cnns">CNNs</h3><p>略。</p><h3 id="rnns">RNNs</h3><p>略。</p><h2 id="applications-in-omics">Applications in omics</h2><h3 id="genomics">Genomics</h3><ol type="1"><li><p>预测DNA序列的功能单元，如复制域（replication domain）、转录因子结合位点（transcription factor binding sites, TFBS）、转录起始点、启动子、增强子、基因删除位点等。</p><blockquote><p>复制域：DNA复制时间调控的单位。 转录因子：指能够结合在某基因上游特异核苷酸序列上的蛋白质，这些蛋白质能调控其基因的转录。方法是转录因子可以调控核糖核酸聚合酶（RNA聚合酶，或叫RNA合成酶）与DNA模板的结合。 启动子：指一段能使特定基因进行转录的脱氧核糖核酸（DNA）序列。启动子可以被RNA聚合酶辨认，并开始转录合成RNA。在核糖核酸（RNA）合成中，启动子可以和调控基因转录的转录因子产生相互作用，控制基因表达（转录）的起始时间和表达的程度，包含核心启动子区域和调控区域，就像“开关”，决定基因的活动，继而控制细胞开始生产哪一种蛋白质。 增强子：是DNA上一小段可与蛋白质（反式作用因子；transacting factor，也就是转录因子）结合的区域，与蛋白质结合之后，基因的转录作用将会加强。增强子可能位于基因上游，也可能位于下游。且不一定接近所要作用的基因，甚至不一定与基因位于同一染色体。这是因为染色质的缠绕结构，使序列上相隔很远的位置也有机会相互接触。</p></blockquote><ol type="a"><li>2015年，将预训练、DNN和hidden Markov model结合的模型实现了对复制域分类的突破【34】；</li><li>2016年，【35】通过使用convolutional/highway的MLP框架，依据TFBS来对基因序列进行分类，AUC达到了0.946；</li><li>【36】使用CNN模型来对启动子进行分子，实现了0.9左右的ACC；</li><li>【37】使用3层全连接来进行增强子和启动子的分类，达到了93.59的ACC；</li><li>【38】开发了一个浅层CNN模型-CNNdel，来进行基因删除位点的预测，使用来自1000 Genomes Projects的数据进行训练，也得到了超过其他方法的结果。</li></ol><p>总体来说，CNNs逐渐压过了DNNs称为主流，并且开始出现了CNNs+LSTMs的杂交模型。</p></li><li><p>预测基因表达。比如目标基因的表达量、预测基因功能、建模基因调控网络等。</p><ol type="a"><li>【39】利用GEO的microarray数据，训练了一个DNN model来预测目标基因的表达量，明显好于Logistic；</li><li>【40】基于stAEs和MLP，通过基因变异的基因型来预测基因表达；</li><li>【41】提出了一个基于CNN-biLSTM的模型，称为DanQ，来预测非编码区域的功能，实现了97.6的AUPR；</li><li>【42】使用RNN来建立基因调控网络，超越了其他的方法；</li></ol><p>CNNs依然是此领域的主要模型，而在研究比较少的基因调控网络领域，还是主要以RNN为主。</p></li><li><p>探索基因和疾病的关系。</p><ol type="a"><li>2017年，【43】使用MLP模型来预测cancer risk和生存，使用的是TCGA的数据，并和cox弹性网得到了类似的表现；</li><li>【44】使用CNNs来预测序列变异对近端CpG位点（DNA甲基化）的影响，得到了0.854的AUC；</li><li>【45】，即DeepCpG，在单细胞领域来预测甲基化位点，其使用的是CNN-RNN的杂交模型，并且模型可以解释；</li></ol><p>在预测甲基化的领域，还是以CNNs为主，RNNs可能会有所应用，但一般也要CNNs配合。而在探索基因和疾病的关系领域，主要使用DNNs，并且AEs和DBN也有所应用。</p></li></ol><h3 id="transcriptions">Transcriptions</h3><ol type="1"><li><p>预测RNA序列的结构，比如预测RBP结合位点、可变剪切位点和RNA类型。</p><ol type="a"><li>2015，基于DBN模型即可探索潜在的结合位点【28】，使用到的数据有RNA序列信息、RNA二级结构和RNA三级结构信息，相对于之前的方法MRE下降了22%；</li><li>【84】开发了一个deep CNNs model来进行剪切点的分类，称为DeeSpline，提高了预测ACC； c.2017年，基于MLP的模型的成功实现了pre-miRNAs和psudo hair-pins的分类，并得到了0.968的ACC【46】；</li></ol></li><li><p>探索RNA和疾病的关联。</p><ol type="a"><li>2017年，基于DBN的一个分类模型，成功利用miRNA属性进行疾病的分类，平均提高了6%-10%【47】；</li><li>【48】使用转录组数据并结合DNN模型，来确定各种药物在不同生物系统下的药理学性质，此模型的效果要好于SVM；</li></ol></li></ol><h3 id="proteomics">Proteomics</h3><ol type="1"><li><p>蛋白质结构预测。比如蛋白质二级结构预测、蛋白质模型质量评估、protein contact map等。</p><ol type="a"><li>【49】通过st-sp AEs来预测二级结构和扭转角，使用原始氨基酸序列作为输入，达到了82%的ACC；</li><li>【36】使用DNN替代SVM来进行蛋白质模型质量评价，就PCC从0.85提高到了0.9；</li><li>【50】结合了两个deep residual networks来预测contacts，其接受sequence conservation information和evoluationary coupling作为输入，得到了最高的F1-score；</li></ol></li><li><p>蛋白质功能预测。</p><ol type="a"><li>【51】中，使用CNN模型来预测蛋白质功能，使用蛋白质三级结构作为输入，得到了87.6%的准确率；</li><li>【52】使用LSTM来预测4种类型蛋白质的功能，使用的是原始氨基酸序列作为输入，得到了99%的ACC；</li></ol></li><li><p>预测蛋白质交互作用、蛋白质亚细胞定位或其他功能。</p><ol type="a"><li>【53】使用stAEs来预测蛋白质交互作用，得到97.19%的ACC；</li><li>【54】使用CNNs模型来自动检测亚细胞定位，在每个细胞定位分类任务中得到了91%的ACC，在每个蛋白质上得到了99%的ACC；</li></ol></li></ol><h3 id="开源软件">开源软件</h3><p>很多人将开发的模型、工具的开源代码放在了网上，或者做成了web服务，现在将其列举如下：</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-18-32-19.png" alt="各种开源工具和代码"><br></p><h2 id="使用dl来解决omics问题">使用DL来解决omics问题</h2><p>这里总结了使用DL来进行omics研究的流程。</p><h3 id="数据获得">数据获得</h3><p>以下是常用的omics数据库：</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-18-40-03.png" alt="常用组学数据库"><br></p><p>需要对其进行一定的处理。</p><h3 id="数据预处理">数据预处理</h3><ol type="1"><li><p>data cleaning。</p><ul><li>缺失值填补，异常值处理：可使用k近邻、regression或决策树等方法来进行填补；</li><li>去除重复的数据：把相似性超过某个阈值的样本删除；</li><li>处理噪声：使用聚类方法、regression或binning；</li></ul><p>这个工作是time-consuming和labor-intensive，也没有什么统一的标准。可以使用一些方便的软件包：<code>OpenRefine</code>【124】或<code>DataKleenr</code>。</p></li><li><p>Normalization。</p><p>主要的作用是将数据缩放至一个合适的范围内。</p><ul><li>如果我们的数据比较集中，并且不服从正态分布，没有涉及到距离、相关性的计算，我们可以使用min-max normalization。比如图像数据。</li><li>如果数据大约服从正态分布，并且我们希望保留样本间距离关系，则可以使用zero-mean normalization。比如基因表达谱数据等。这也是最常用的normalization方法。</li></ul></li><li><p>Dimensionality reduction。</p><p>删除一些无关的变量，使用AEs来进行降维，或者使用PCA等等。</p></li></ol><h3 id="编码">编码</h3><ul><li><p><strong>one-hot encoding</strong></p><p><span class="math inline">\(N\)</span>长度的DNA序列被编码为<span class="math inline">\(4\times N\)</span>的矩阵，蛋白质序列被编码成<span class="math inline">\(20\times N\)</span>的矩阵，其中的每个值是<span class="math inline">\(0\)</span>或<span class="math inline">\(1\)</span>。</p></li><li><p><a href="https://en.wikipedia.org/wiki/Position-Specific_Scoring_Matrix" target="_blank" rel="noopener"><strong>position-specific scoring matrix（PSSM, PWM, PSWM）</strong></a></p><p>也可以用来编码核苷酸序列或蛋白质序列，这里使用wiki的例子进行解释：</p><ol type="a"><li><p>我们有以下9条序列：</p><pre><code>GAGGTAAACTCCGTAAGTCAGGTTGGAACAGTCAGTTAGGTCATTTAGGTACTGATGGTAACTCAGGTATACTGTGTGAGTAAGGTAAGT</code></pre></li><li><p>首先将每个位置上的频数进行计算，称为PFM（position frequency matrix）：</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-22-07-33.png" alt="PFM"><br></p></li><li><p>然后每个位置归一化为概率，得到PPM（position probability matrix）：</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-22-09-13.png" alt="PPM"><br></p></li><li><p>最后将概率转换为权重，即使用<span class="math inline">\(\log2(M_{k,j}/b_k)\)</span>，其中<span class="math inline">\(b_k=1/|k|\)</span>，其中<span class="math inline">\(k\)</span>表示每个位置上的离散值有多少个，对于氨基酸序列<span class="math inline">\(k=20\)</span>，而对于核苷酸序列则<span class="math inline">\(k=4\)</span>，最后得到PWM（position weight matrix）：</p><p><img src="/2020/05/15/paper/omics/dl-in-omics2019/DL-in-omics2019_2020-05-15-22-13-04.png" alt="PWM"><br></p></li><li><p>然后使用其来编码数据即可。</p></li></ol><p>有一些现有的程序可以实现（比如PSI-BLAST），在这些算法中，其计算过程更加复杂，但基本思想是一致的。</p><blockquote><p>这样编码是认为<strong>在序列的不同位置，相同的标签也应该有不同的编码</strong>。比如在序列开始的A和在序列结束时的A应该有不同的值。</p><p>如果某个位置上，A出现的次数明显比CGT更多，则其自然在此位置有更高的权重。如果在另外的位置上，A出现的次数比较少，则其就有较小的权重。如果一次都没有出现，权重是<span class="math inline">\(-\infty\)</span></p><p>另外，权重的大小还和类别数有关。比如在某位置上，氨基酸序列中A（丙氨酸）出现的频率是0.7，在DNA序列中A（腺嘌呤）出现的概率也是0.7，但最终氨基酸序列计算的编码要比DNA序列计算的编码大。这是因为在20分类中得到0.7的概率要比4分类更难，自然应有更高的赋值。</p></blockquote></li><li><p><strong><a href="https://en.wikipedia.org/wiki/Point_accepted_mutation" target="_blank" rel="noopener">PAM（point accepted mutation）matrix</a> and <a href="https://en.wikipedia.org/wiki/BLOSUM" target="_blank" rel="noopener">BLOSUM（blocks substitution）matrix</a></strong></p><p>这两个矩阵是序列的替换记分矩阵，常用于序列比对，即其衡量了序列上的两个值间的相似程度。那么同样的，其也可以用来作为序列的编码。详情请见</p></li></ul><p>除了以上3种方法外，对于蛋白质序列，还有autocovariance method和conjoint triad method 【126】方法。</p><p>另外，还有一些方法致力于将多种类型的数据进行整合分析【128,49,50,98,129】。</p><h3 id="模型选择">模型选择</h3><ol type="1"><li>尽量针对不同的任务使用不同的架构；</li><li>可以将多种不同的架构进行结合，从而得到更好的结果；</li><li>时刻关注最先进模型的研究，关于新技术。</li></ol><h3 id="模型训练">模型训练</h3><ol type="1"><li>考虑一下硬件配置是否支持；</li><li>注意数据集要分成training、validation和testing，本研究作者常用的分发为70%用作training和validation，30%用作testing；</li><li>合理选择激活函数，本研究作者建议的隐藏层激活函数为ReLU和maxout；</li><li>考虑试验一下dropout、early stop和weight decay，来预防过拟合。</li></ol><h3 id="评价">评价</h3><p>推荐使用交叉验证。</p><h3 id="深度学习框架">深度学习框架</h3><blockquote><p>这里总结了一下框架，但内容有点过时，就不贴了。</p></blockquote><h2 id="机会和挑战">机会和挑战</h2><ul><li>数据量：omics数据量一般不足，并且有imbalance的问题；</li><li>解决数据量不足：zero-shot learning【135】、one-shot learning【136】和GAN【137】； 解决imbalance：resamling、cost-sensitive learning【138】。</li><li>数据质量：omics数据一般来自不同平台，数据质量比较难以保证；</li><li>解决：上面提到的数据清洗过程。</li><li>计算花销：有硬件门槛；</li><li>“黑盒”问题：无法进行解释；</li><li>关于“黑盒”问题，也有所进展。比如【139】提出的Deep Motif Dashboard，就为TFBS的分类提供了一种可视化策略。</li><li>模型选择和训练：选择一个合适的模型和合适的超参数是困难的；</li></ul><p>当然，未来，还有一些其他的DL概念会对omics的研究产生影响：</p><ul><li>reinforcement leanring 【140】</li><li>incremental learning 【141】</li><li>transfer learning 【142】</li></ul><h2 id="结论">结论</h2><p>DL技术非常适合解决omics的问题。</p><hr><h2 id="questions">Questions</h2><p><em>这篇文章的一些结论或者内容感觉有些老了，之前以为是19年的文章，可能会比较新。但读到才发现可能是18年的。</em></p><ul><li>但还是有所收获，特别是其介绍的一些序列编码方法是第一次听说。总结了一些文章的github。另外，其提到的文章中也有一些值得关注的。比如那个使用RNN来建网的方法，还有提到的一系列基于DBN的方法。*</li></ul>]]></content>
      
      
      <categories>
          
          <category> Paper </category>
          
          <category> Review </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Omics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客搭建</title>
      <link href="/2020/05/10/tools/blog-build/"/>
      <url>/2020/05/10/tools/blog-build/</url>
      
        <content type="html"><![CDATA[<p>自己在学习的过程中，积累了大量的学习材料和笔记。对于增量学习过程，这些学习材料和笔记应该得到较好的组织，而且有些内容很容易因为不常使用而忘记。所以将其进行有条理的整理，便于进行随时查阅，是非常有必要的。</p><p>显然，搭建一个个人博客是一个比较合适的选择。我希望我的个人博客能够满足下面的特点：</p><ul><li>漂亮，好看，逼格满满。</li><li>拥有足够的表现力，可以满足我的多种需求（比如学习笔记、论文笔记等）。</li><li>可以自动化处理多种格式的文件（比如<code>.ipynb</code>和<code>.Rmd</code>，这些文件是我学习python和R时常使用的格式）。</li><li>可以进行自定义修改。</li></ul><p>经过一番的折腾，我选择了vscode + Hexo + pandoc + github page + 脚本辅助的模式。我希望它能够满足我的以上的需求：</p><ul><li>vscode借助其各种插件（vim、Paste Image等）可以实现舒适的文本编辑体验。</li><li>Hexo有各种漂亮的主题，简单的操作就可以定制化一个漂亮的个人博客；Hexo也有各种js脚本制作的插件，可以实现更多的功能以（字数统计、词云、插入音乐等）。</li><li>pandoc版的markdown拥有比传统markdown更多的语法，更强的表现力。</li><li>github page提供了免费的静态网页托管站点，而且依托其issue还可以增加评论功能。</li><li>通过python、js等脚本语言，可以进一步扩宽Hexo的功能（编写新的Hexo脚本），这样我们可以将更多类型的文本整合到博客系统中，并且进行高度的自定义。</li></ul><p>现在，我将我搭建博客的全过程进行记录，以便于发现问题和总结，并探索一个快速的、可重复的操作步骤。</p><h1 id="第一部分-依赖安装">第一部分 依赖安装</h1><h2 id="git安装">1. git安装</h2><p>对于linux系统，使用root权限下的包管理器安装即可；对于windows，使用可执行安装文件，一步一步根据引导即可完成安装。</p><h2 id="node.js安装">2. node.js安装</h2><p>如果是windows系统，同样使用引导界面安装即可。</p><p>如果是linux系统，除了使用包管理器安装以外，还可以使用下面的方式（不需要root权限，便于管理）:</p><ol type="1"><li>从<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">node官网</a>中下载linux的2进制安装包；</li><li><code>tar -Jxvf node-v12.16.3-linux-x64.tar.xz</code>，解压；</li><li>（创建<code>.local/bin</code>，没有必要将这个路径加入到环境变量中，其默认就在环境变量中），将<code>bin/node</code>（别忘了<code>npm</code>和<code>npx</code>）软连接到<code>.local/bin</code>中；</li><li><code>node -v</code>查看是否成功。</li></ol><h2 id="hexo安装">3. Hexo安装</h2><p><a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">Hexo</a>依赖于<a href="https://git-scm.com/downloads" target="_blank" rel="noopener">git</a>和<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">node.js</a>，其作为node.js的一个软件包存在的，可以使用npm进行安装管理。</p><blockquote><p>这里需要介绍以下<code>npm</code>的规则，其默认是局部安装模式。如果使用全局安装模式（<code>-g</code>），则相关内容会被安装到<code>prefix/lib/node_modules</code>中（可以使用<code>npm help npm</code>来查看，windows是在C盘下面）。如果是局部安装模式，则相关内容会被安装到当前的文件夹下的node_modules中。</p></blockquote><p>为了提高npm的安装速度，可以<a href="https://blog.csdn.net/quuqu/article/details/64121812" target="_blank" rel="noopener">设置一下淘宝镜像</a>或使用<a href="https://developer.aliyun.com/mirror/NPM" target="_blank" rel="noopener"><code>cnpm</code></a>，然后全局安装hexo-cli（全局安装可以使得我们在任何位置使用<code>hexo</code>命令）：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> config <span class="token keyword">set</span> registry https://registry.npm.taobao.org<span class="token function">npm</span> <span class="token function">install</span> hexo-cli -g<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>注意，如果在linux上解压二进制安装包安装的node.js，则其全局安装位置可能并不在环境变量中，需要手动再将<code>hexo</code>加入环境变量才好使用。</p><h2 id="pandoc部分">4. Pandoc部分</h2><p>其安装和node.js的安装方式类似，比照其安装即可。</p><h2 id="vscode">5. vscode</h2><p>vscode的安装不再赘述，这里侧重于工作流程、配置和一些好用的插件。</p><p>整个工作流程可以是这样的：</p><ol type="1"><li>直接在<code>_posts</code>文件夹下创建工作环境，编辑markdown文件，需要导入图片的时候，就在其同级目录下创建一个同名文件夹，将图片放入其中来引用即可（使用<a href="https://marketplace.visualstudio.com/items?itemName=mushan.vscode-paste-image" target="_blank" rel="noopener">Paste Image</a>插件可以自动创建这个目录）。</li><li>因为所有的markdown文件都必须在<code>_post</code>目录下，所以为了容易区分，文件命名很重要，可以使用<code>-</code>来增加可读性，比如关于pytorch的学习可以使用<code>python-pytorch-xx</code>、论文的阅读总结可以使用<code>paper-xx</code>。</li></ol><h2 id="paste-image">5.1 <a href="https://marketplace.visualstudio.com/items?itemName=mushan.vscode-paste-image" target="_blank" rel="noopener">Paste Image</a></h2><p>其作用是可以将剪切板中的图片直接放入markdown中（快捷键为C-A-v），并保存到指定的文件夹下。我对此插件进行了下列配置：</p><ol type="1"><li><p>保存剪切板图片的时候，使用当前正在编辑的文件的名称作为图片文件名称的前缀，使用时间作为其名称的主题；</p></li><li><p>设置其保存路径为当前文件同级目录下的同名文件夹；</p></li><li><p>在保存图片的时候，会出现vscode input box，从而可以更改路径；</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-10-18-03-00.png" alt="PasteImage的配置"><br></p></li></ol><h1 id="第二部分-配置博客">第二部分 配置博客</h1><p>本次博客配置使用的主题为<a href="https://github.com/blinkfox/hexo-theme-matery.git" target="_blank" rel="noopener">hexo-theme-matery</a>，其有比较全面的<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md" target="_blank" rel="noopener">中文配置说明</a>。另外，博客的配置还参考了两位大佬 -- <a href="https://zhuanlan.zhihu.com/p/35668237" target="_blank" rel="noopener">godweiyang</a>和<a href="https://qinnian.xyz/CreateBlog.html" target="_blank" rel="noopener">钦の念</a>的配置过程，受益匪浅。</p><p>另外，在配置过程中，为了添加更多的功能，安装了众多的hexo插件，这些插件都集中记录在此：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># --save表示安装使用依赖</span><span class="token function">npm</span> <span class="token function">install</span> hexo-deployer-git --save           <span class="token comment" spellcheck="true"># 用于进行git部署</span><span class="token function">npm</span> <span class="token function">install</span> hexo-wordcount --save              <span class="token comment" spellcheck="true"># 统计文章字数</span><span class="token function">npm</span> <span class="token function">install</span> gitalk --save                      <span class="token comment" spellcheck="true"># gitalk评论系统</span><span class="token function">npm</span> <span class="token function">install</span> valine --save                      <span class="token comment" spellcheck="true"># valine评论系统</span><span class="token function">npm</span> <span class="token function">install</span> hexo-prism-plugin --save           <span class="token comment" spellcheck="true"># 代码高亮</span><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search --save       <span class="token comment" spellcheck="true"># 搜索</span><span class="token function">npm</span> <span class="token function">install</span> hexo-permalink-pinyin --save       <span class="token comment" spellcheck="true"># 汉字转拼音</span><span class="token function">npm</span> <span class="token function">install</span> hexo-filter-github-emojis --save   <span class="token comment" spellcheck="true"># emojis表情</span><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed --save         <span class="token comment" spellcheck="true"># RSS订阅</span><span class="token function">npm</span> <span class="token function">install</span> https://github.com/xcodebuild/hexo-asset-image --save<span class="token function">npm</span> <span class="token function">install</span> hexo-renderer-pandoc --save        <span class="token comment" spellcheck="true"># 一个新的markdown渲染器</span><span class="token function">npm</span> <span class="token function">install</span> hexo-helper-live2d --save          <span class="token comment" spellcheck="true"># 动画人物支持</span><span class="token function">npm</span> <span class="token function">install</span> live2d-widget-model-shizuku --save <span class="token comment" spellcheck="true"># 动画人物支持</span><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-sitemap --save      <span class="token comment" spellcheck="true"># 添加站点地图</span><span class="token function">npm</span> <span class="token function">install</span> hexo-lazyload-image --save         <span class="token comment" spellcheck="true"># 图片懒加载</span><span class="token function">npm</span> <span class="token function">install</span> hexo-renderer-mathjax --save       <span class="token comment" spellcheck="true"># 解析公式</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另外，因为我们想要使用pandoc作为markdown的渲染器，所以就必须把默认的渲染器卸载</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">npm</span> uninstall hexo-renderer-marked --save<span class="token function">npm</span> uninstall hexo-math --save            <span class="token comment" spellcheck="true"># 一般来说这个插件是没有安装的，但为了hexo-renderer-mathjax可以工作，最好确认一下</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="创建站点">1. 创建站点</h2><ol type="1"><li><p>在站点文件夹下使用<code>hexo init</code>命令；</p></li><li><p>别忘了使用<code>npm install</code>来安装一些必要的组件；</p></li><li><p>现在可以通过<code>npm g &amp;&amp; npm s</code>来打开本地服务器，然后连接<code>http://localhost:4000/</code>来查看是否成功：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-10-23.png" alt="页面效果"><br></p></li></ol><h2 id="博客部署至github">2. 博客部署至github</h2><ol type="1"><li><p>创建一个名为<code>luyiyun.github.io</code>的repository；</p></li><li><p>配置SSH key（为了不用每次都输密码）；</p></li><li><p>安装<code>hexo-deployer-git</code>插件，更改博客<code>_config.yml</code>文件，添加deploy项：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-12-51.png" alt="添加deploy配置"><br></p></li><li><p>运行以下的命令：</p><pre class="line-numbers language-bash"><code class="language-bash">hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span> hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后打开<code>luyiyun.github.io</code>，看是否部署成功：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-19-05.png" alt="部署成功"><br></p></li></ol><p>以上在<a href="https://qinnian.xyz/CreateBlog.html" target="_blank" rel="noopener">钦の念</a>的博客中有更加详细的叙述。</p><h2 id="申请个人域名">2. 申请个人域名</h2><ol type="1"><li><p>申请一个新的域名<code>luyiyun.online</code>（腾讯云），别忘了添加一条解析记录使之能够正常解析；</p></li><li><p>在<code>/source</code>目录下，新建<code>CNAME</code>文件，然后写上域名，保存，然后<code>hexo g &amp;&amp; hexo d</code>部署；</p></li><li><p><code>CNAME</code>文件会被放到<code>public</code>中并一并上传到github上；</p></li><li><p>查看repository的settings，发现以下结果，代表可正常使用：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-38-16.png" alt="个人域名配置成功"><br></p></li><li><p>可以使用这个域名来打开看看了：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-39-38.png" alt="个人域名解析成功"><br></p></li></ol><h2 id="博客配置文件">3. 博客配置文件</h2><p>博客的配置文件是根目录下的<code>_config.yml</code>，现在我们对其中的内容依次进行处理：</p><ol type="1"><li><p>站点基本信息配置：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-43-06.png" alt="site"><br></p></li><li><p>网站的url：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-44-21.png" alt="url"><br></p></li><li><p>分页，设置这个是为了适配<a href="https://github.com/blinkfox/hexo-theme-matery.git" target="_blank" rel="noopener">hexo-theme-matery</a>：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-46-33.png" alt="per_page"><br></p></li><li><p>主题，这里使用<a href="https://github.com/blinkfox/hexo-theme-matery.git" target="_blank" rel="noopener">hexo-theme-matery</a>：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-14-48-13.png" alt="theme"><br></p><blockquote><p>我们在<code>/themes</code>文件夹下使用git来下载该主题：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/blinkfox/hexo-theme-matery.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></blockquote></li><li><p>渲染器，这里使用<a href="https://pandoc.org/MANUAL.html" target="_blank" rel="noopener">pandoc</a>作为渲染器，自然我们需要安装<a href="https://github.com/wzpan/hexo-renderer-pandoc" target="_blank" rel="noopener">hexo-renderer-pandoc</a>插件。</p><p><a href="https://pandoc.org/MANUAL.html" target="_blank" rel="noopener">pandoc</a>的缺点在于比较笨重，如果只是为了渲染markdownd的话，有点杀鸡用牛刀的感觉。但对于我而言，有以下几点原因，使得我选择了它：</p><ul><li>更多可以使用的语法，有更强的表现力（前面提到了）。</li><li>我希望兼容<code>Rmarkdown</code>，其中其使用的就是pandoc语法。</li><li>pandoc直接兼容公式渲染，我们只需要改一个好用的CDN链接即可。</li></ul><p>但其和下面讲到的语法高亮插件<code>hexo-prism-plugin</code>有冲突，所以需要进行一些修改。</p><p>在<code>node-modules/hexo-renderer-pandoc/index.js</code>中，找到：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token keyword">var</span> args <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token string">'markdown-smart'</span><span class="token operator">+</span>extensions<span class="token punctuation">,</span> <span class="token string">'-t'</span><span class="token punctuation">,</span> <span class="token string">'html-smart'</span><span class="token punctuation">,</span> math<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将其改为</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token keyword">var</span> args <span class="token operator">=</span> <span class="token punctuation">[</span> <span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token string">'markdown-smart'</span><span class="token operator">+</span>extensions<span class="token punctuation">,</span> <span class="token string">'-t'</span><span class="token punctuation">,</span> <span class="token string">'html-smart'</span><span class="token punctuation">,</span> math<span class="token punctuation">,</span> <span class="token string">"--no-highlight"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>即将pandoc自己的代码高亮关掉，不然其会影响到后面<code>hexo-prism-plugin</code>的使用。</p></li><li><p>代码高亮，使用<code>hexo-prism-plugin</code>，并在<code>_config.yml</code>中加入以下内容：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-50-24.png" alt="hightlight"><br></p><blockquote><p>前面有默认有<code>highlight: enable</code>的配置，所以这两个只保留一个即可。</p></blockquote><p><code>hexo-prism-plugin</code>使用的是<a href="https://prismjs.com/index.html" target="_blank" rel="noopener">prism</a>来提供代码高亮。这个是一个在网页中提供代码高亮的解决方案，为几乎所有的语言提供了对应的代码高亮，而且还提供了一些插件，可以做到一键复制、增加行号等操作。</p><p><a href="https://prismjs.com/index.html" target="_blank" rel="noopener">prism</a>需要渲染后的网页中的代码块以下面的形式存在：</p><pre class="line-numbers language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pre</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>code</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>langauge-python<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        import numpy as np        np.random.rand(10)    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>hexo-prism-plugin</code>可以将下面的形式更改为上面的：</p><pre class="line-numbers language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pre</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>code</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>python<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        import numpy as np        np.random.rand(10)    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>而pandoc渲染后是下面的形式</p><pre class="line-numbers language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>pre</span> <span class="token attr-name">code</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>python<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>code</span><span class="token punctuation">></span></span>        import numpy as np        np.random.rand(10)    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>code</span><span class="token punctuation">></span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以我们需要更改<code>node-modules/hexo-prism-plugin/src/index.js</code>中的正则表达式</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token keyword">const</span> regex <span class="token operator">=</span>  <span class="token regex">/&lt;pre>&lt;code class="(.*)?">([\s\S]*?)&lt;\/code>&lt;\/pre>/igm</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>改为</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token keyword">const</span> regex <span class="token operator">=</span>  <span class="token regex">/&lt;pre class="(.*)?">&lt;code>([\s\S]*?)&lt;\/code>&lt;\/pre>/igm</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样就可以了。</p></li><li><p>搜索，使用<code>hexo-generator-search</code>插件，并在配置文件中加入：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-52-45.png" alt="search"><br></p></li><li><p>中文链接转拼音，使用<code>hexo-permalink-pinyin</code>：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-54-47.png" alt="pinyin"><br></p></li><li><p>添加对<code>emoji</code>表情的支持，<code>hexo-filter-github-emojis</code></p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-56-43.png" alt="emoji"><br></p></li><li><p>添加RSS订阅支持，<code>hexo-generator-feed</code>，</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-58-22.png" alt="RSS"><br></p><p>出现下面情况，说明RSS配置成功：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-18-12-25.png" alt="RSS-OK"><br></p></li><li><p>图片路径改为绝对路径，需要安装<code>hexo-asset-image</code>，并将<code>post_asset_folder</code>改为<code>true</code>。</p><blockquote><p>设置<code>_config.yml</code>中的<code>post_asset_folder: true</code>，这意味着使用<code>hexo new &lt;blog&gt;</code>时，在<code>_posts</code>中不只生成了一个md文件，而且还出现了一个同名文件夹，用来放md文件引用的内容。<del>我们可以在md文件中使用<code>![](name.jpg)</code>来引入图片。</del>但我们不会这样做，因为如此引入图片，在编写博客的时候是无法预览的，我们应该使用<code>![](&lt;blog&gt;/name.jpg)</code>的格式来引入。该插件使得我们就算这样引入图片，hexo也可以正确读取并处理它。</p></blockquote></li><li><p>安装<code>hexo-renderer-pandoc</code>，提供pandoc语法支持。</p></li><li><p>添加动漫人物，需要安装两个插件，并在根目录配置文件中添加下面的配置：</p><pre class="line-numbers language-yml"><code class="language-yml">live2d:    enable: true    scriptFrom: local    pluginRootPath: live2dw/    pluginJsPath: lib/    pluginModelPath: assets/    tagMode: false    log: false    model:        use: live2d-widget-model-shizuku    display:        position: right        width: 150        height: 300    mobile:        show: true    react:        opacity: 0.7<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>SEO配置</p><p>SEO（Search Engine Optimization），即搜索引擎优化：</p><blockquote><p>搜索引擎优化是一种通过了解搜索引擎的运作规则来调整网站，以及提高目的网站在有关搜索引擎内排名的方式。</p></blockquote><ol type="a"><li><p>验证网站。如果在谷歌搜索<code>site:luyiyun.online</code>查不到，这说明未被收录，则需要前往Google Search Console，进行验证：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-18-53-12.png" alt="gsc"><br></p><p>方式和添加解析是一样，在腾讯云的控制台，添加DNS解析记录即可，其中记录值使用Google Search Console提供的值：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-18-55-35.png" alt="gsc2"><br></p><p>等待几分钟后，在Google Search Console中进行验证，通过即可。</p></li><li><p>添加站点地图作用是告诉搜索引擎你的网站结构等信息，让搜索引擎更智能抓取内容。需要安装<code>hexo-generator-sitemap</code>插件，并在根目录的配置文件下添加：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-18-59-19.png" alt="sitemap"><br></p></li><li><p>当<code>hexo g</code>后，public中出现了<code>sitemap.xml</code>文件。我们可以再进入Google Search Console，然后把这个站点地图（是这个sitemap文件）添加进去，</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-19-10-01.png" alt="sitemap2"><br></p></li><li><p>简化路径：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-19-12-03.png" alt="path"><br></p></li></ol></li></ol><h2 id="新建主题文章模板">4. 新建主题文章模板</h2><p>建议将<code>/scaffolds/post.md</code>修改至：</p><pre class="line-numbers language-markdown"><code class="language-markdown"><span class="token hr punctuation">---</span>title: Hexo博客搭建date: 1589105282000author: Lu Yiyunimg: "文章特色图，空则hexo-theme-matery自动进行填补"coverImg: "文章在首页轮播封面时显示的图片，默认使用文章特色图"top: truecover: truetoc: truemathjax: truesummary: "自定义文章的摘要，不然自动从文章正文中吸取"categories:<span class="token list punctuation">-</span> A<span class="token list punctuation">-</span> Btags:<span class="token list punctuation">-</span> a<span class="token list punctuation">-</span> b<span class="token title important">keywords:<span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="新建工具页面">5. 新建工具页面</h2><pre class="line-numbers language-markdown"><code class="language-markdown">hexo new page "categories"hexo new page "tags"hexo new page "about"hexo new page "contact"hexo new page "friends"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>并都将其中的<code>index.md</code>文件改写为以下格式：</p><pre class="line-numbers language-markdown"><code class="language-markdown"><span class="token hr punctuation">---</span>title: categoriesdate: 2020-05-10 13:25:48type: "categories"<span class="token title important">layout: "categories"<span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后手动再<code>/source/</code>下创建一个<code>404.md</code>，并填写一下内容：</p><pre class="line-numbers language-markdown"><code class="language-markdown"><span class="token hr punctuation">---</span>title: 404date: 2019-07-19 16:41:10type: "404"layout: "404"<span class="token title important">description: "你来到了没有知识的荒原 :("<span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>并在<code>/themes/hexo-theme-matery/layout/</code>下新建<code>404.ejs</code>，并添加以下内容：</p><pre class="line-numbers language-javascript"><code class="language-javascript"><span class="token operator">&lt;</span>style type<span class="token operator">=</span><span class="token string">"text/css"</span><span class="token operator">></span>    <span class="token comment" spellcheck="true">/* don't remove. */</span>    <span class="token punctuation">.</span>about<span class="token operator">-</span>cover <span class="token punctuation">{</span>        height<span class="token punctuation">:</span> 75vh<span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token operator">&lt;</span><span class="token operator">/</span>style<span class="token operator">></span><span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"bg-cover pd-header about-cover"</span><span class="token operator">></span>    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"container"</span><span class="token operator">></span>        <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"row"</span><span class="token operator">></span>            <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"col s10 offset-s1 m8 offset-m2 l8 offset-l2"</span><span class="token operator">></span>                <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"brand"</span><span class="token operator">></span>                    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"title center-align"</span><span class="token operator">></span>                        <span class="token number">404</span>                    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                    <span class="token operator">&lt;</span>div <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"description center-align"</span><span class="token operator">></span>                        <span class="token operator">&lt;</span><span class="token operator">%</span><span class="token operator">=</span> page<span class="token punctuation">.</span>description <span class="token operator">%</span><span class="token operator">></span>                    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>                <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>            <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>        <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span>    <span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span class="token operator">&lt;</span><span class="token operator">/</span>div<span class="token operator">></span><span class="token operator">&lt;</span>script<span class="token operator">></span>    <span class="token comment" spellcheck="true">// 每天切换 banner 图.  Switch banner image every day.</span>    <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'.bg-cover'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">css</span><span class="token punctuation">(</span><span class="token string">'background-image'</span><span class="token punctuation">,</span> <span class="token string">'url(/medias/banner/'</span> <span class="token operator">+</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getDay</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg)'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&lt;</span><span class="token operator">/</span>script<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样，我们就添加了一个404页面了。</p><h2 id="主题配置文件">6. 主题配置文件</h2><p>在<code>/themes/hexo-theme-matery</code>下有一个<code>_config.yml</code>文件，用来控制主题的诸多属性。</p><ol type="1"><li><p>第一部分配置菜单导航，icon可以在<a href="https://fontawesome.com/" target="_blank" rel="noopener">Font Awesome</a>中找：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-15-18-16.png" alt="theme-menu"><br></p></li><li><p>站点运行时间：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-15-21-03.png" alt="theme-start-time"><br></p></li><li><p>首页配置，包括封面轮播图、“梦想”和音乐：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-15-23-59.png" alt="theme-index"><br></p></li><li><p>配置logo、favicon：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-42-12.png" alt="theme-logo"><br></p></li><li><p>联系方式：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-44-00.png" alt="theme-link"><br></p></li><li><p>文章目录设置：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-45-03.png" alt="theme-toc"><br></p></li><li><p>代码块部分：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-45-50.png" alt="theme-code-block"><br></p></li><li><p>打赏部分，记得替换为自己的二维码：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-46-43.png" alt="theme-reward"><br></p></li><li><p>复制时追加版权信息：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-48-45.png" alt="theme-copyright"><br></p></li><li><p>激活mathjax：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-49-25.png" alt="theme-math"><br></p><p>注意需要安装<code>hexo-renderer-pandoc</code>，并卸载<code>hexo-renderer-marked</code>，然后安装<code>hexo-renderer-mathjax</code>插件才行。</p></li><li><p>开启文章信息，需要安装<code>hexo-wordcount</code>插件：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-52-08.png" alt="theme-word"><br></p></li><li><p>"关于"页面的配置：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-16-55-47.png" alt="theme-about"><br></p></li><li><p>评论配置，这里会开启两个评论：基于github issue的gitalk和无后端的valine：</p><ul><li><p>gitalk，安装相关插件<code>gitalk</code>：</p><ul><li><p>我们需要创建一个新的github repository来储存评论：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-01-01.png" alt="theme-gitalk1"><br></p></li><li><p>开启issue功能（默认开启）：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-02-49.png" alt="theme-gitalk2"><br></p></li><li><p>注册一个github application：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-08-21.png" alt="theme-gitalk3"><br></p><p>并得到Client ID和Client Secret：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-09-29.png" alt="theme-gitalk4"><br></p></li><li><p>将这些信息配置到<code>_config.yml</code>文件中：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-12-25.png" alt="theme-gitalk5"><br></p></li><li><p>最终效果：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-22-28.png" alt="theme-gitalk6"><br></p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-23-05.png" alt="theme-gitalk7"><br></p></li></ul></li><li><p><a href="https://valine.js.org/quickstart.html" target="_blank" rel="noopener">valine</a>，需要先安装插件<code>valine</code>：</p><ul><li><p>首先我们需要注册一个LeanCloud账户，并完成实名认证；</p></li><li><p>创建一个应用，然后找到其ID和Key：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-31-24.png" alt="theme-valine1"><br></p></li><li><p>将这些信息配置到<code>_config.yml</code>文件中：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-34-10.png" alt="theme-valine2"><br></p></li><li><p>效果：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-36-40.png" alt="theme-valine3"><br></p></li><li><p>我们可以在LeanCloud中对这些评论进行管理：</p><p><img src="/2020/05/10/tools/blog-build/BlogBuild_2020-05-11-17-38-10.png" alt="theme-valine4"><br></p></li></ul></li></ul></li></ol><h2 id="提高加载速度">7. 提高加载速度</h2><p>可以使用<a href="https://developers.google.com/speed/pagespeed/insights/" target="_blank" rel="noopener">Google PageSpeed Insights</a>来对网站的速度进行测试，并找到其瓶颈所在，其他的各种测速工具可以见<a href="https://qinnian.xyz/CreateBlog.html" target="_blank" rel="noopener">钦の念</a>的博客。</p><h3 id="图片懒加载">7.1 图片懒加载</h3><p>第一种可以提高速度的方式是进行图片的懒加载，安装<code>hexo-lazyload-image</code>，并在站点配置文件中加入：</p><pre class="line-numbers language-yml"><code class="language-yml">lazyload:enable: trueonlypost: false   # true则只会懒加载文章中的图片，logo头像什么的不会loadingImg: ./medias/loading.gif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><em>此插件与hexo-asset-image似乎不兼容，未解决。</em></p><h3 id="gitee和github双线部署">7.2 gitee和github双线部署</h3><p><em>未完待续...</em></p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Blog </tag>
            
            <tag> Hexo </tag>
            
            <tag> Vscode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zsh及oh-my-zsh安装</title>
      <link href="/2020/05/10/tools/zsh-an-zhuang/"/>
      <url>/2020/05/10/tools/zsh-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>zsh以及oh-my-zsh除了可以提高终端的颜值，而且通过众多的插件可以提高我们的使用体验，所以这里将其安装和使用总结在这里，便于之后使用。</p><h1 id="zsh安装">zsh安装</h1><p><a href="http://zsh.sourceforge.net/" target="_blank" rel="noopener">zsh</a>是一个类似bash的shell，同样也是一个脚本语言集。</p><h2 id="包管理器安装">包管理器安装</h2><p>这就不多赘述了，如果是Ubuntu</p><pre><code>apt-get install zsh</code></pre><p>如果是centos</p><pre><code>yum install zsh -y</code></pre><p>oh-my-zsh给我们总结了所有平台安装zsh的方式：<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Installing-ZSH" target="_blank" rel="noopener">Installing ZSH</a>，其中也介绍了如何把zsh设置为默认终端的流程。</p><h2 id="源码安装">源码安装</h2><p>如果我们没有root权限，或者希望将zsh安装到一个确定的目录下，则需要使用<a href="http://zsh.sourceforge.net/Arc/source.html" target="_blank" rel="noopener">源码</a>安装。</p><ol type="1"><li><p>下载源码包，然后是标准的CMMI（configure、make、make install）：</p><pre><code>mkdir buildcd build../configure --prefix=/path/to/zshmakemake install</code></pre></li><li><p>将zsh加入到环境变量中</p></li><li><p>将下列语句加入到<code>.bash_profile</code>中，使得自动载入zsh以及将zsh设置为默认的终端（如果zsh被安装在或其被链接到<code>$HOME/.local/bin/zsh</code>）：</p><pre><code>[ -f $HOME/.local/bin/zsh ] &amp;&amp; {    echo "Type Y to run zsh: \c"    read line    [ "$line" = Y ] &amp;&amp; {        export SHELL=$HOME/.local/bin/zsh        exec $HOME/.local/bin/zsh -l    }}</code></pre></li></ol><h1 id="oh-my-zsh安装">oh-my-zsh安装</h1><p><a href="https://ohmyz.sh/#install" target="_blank" rel="noopener">oh-my-zsh</a>是一个开源的zsh configure framewo，有好看的主题，有众多的插件来提高其功能。其<a href="https://ohmyz.sh/#install" target="_blank" rel="noopener">官网</a>中有安装的方式，这里我们使用下面稍加修改的模式：</p><pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 可能下不下来，这时只能手动下载</span><span class="token function">wget</span> https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.shZSH<span class="token operator">=</span>/path/to/oh-my-zsh sh install.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><code>/path/to/oh-my-zsh</code>是自定义安装目录。</p><p>如果想要卸载oh-my-zsh，直接运行<code>uninstall_oh_my_zsh</code>即可。</p><h1 id="oh-my-zsh配置">oh-my-zsh配置</h1><h2 id="themes">themes</h2><p>设置主题，只需要在<code>.zshrc</code>中更改<code>ZSH_THEME</code>，然后<code>source .zshrc</code>即可。</p><p>oh-my-zsh本身就预装了大量的<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes" target="_blank" rel="noopener">主题</a>，在<code>$ZSH/themes</code>中。另外，还有大量的<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/External-themes" target="_blank" rel="noopener">额外主题</a>，但需要进行安装。</p><h2 id="plugins">plugins</h2><p>插件可以帮助我们更加有效率的工作，比如进行命令的提示、历史命令的记录等。本身oh-my-zsh也预装了大量的插件，<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins-Overview" target="_blank" rel="noopener">这里</a>是其插件列表。同样，我们也可以安装一些<a href="https://github.com/ohmyzsh/ohmyzsh/wiki/External-plugins" target="_blank" rel="noopener">第三方插件</a>。</p><p>插件启用的方式也是非常简单的，即在<code>.zshrc</code>中的<code>plugins=(...)</code>中添加我们想要的插件即可。</p><p>比如，这里我添加的:</p><ol type="1"><li><p><a href="https://github.com/zsh-users/zsh-autosuggestions/blob/master/INSTALL.md" target="_blank" rel="noopener"><code>zsh-autosuggestions</code></a>:</p><pre><code>git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions</code></pre><p>添加<code>zsh-autosuggestions</code>到<code>plugins=()</code>中。</p></li><li><p><a href="https://github.com/zsh-users/zsh-syntax-highlighting/blob/master/INSTALL.md" target="_blank" rel="noopener"><code>zsh-syntax-highlighting</code></a></p><pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting</code></pre><p>添加<code>zsh-syntax-highlighting</code>到<code>plugins=()</code>中。</p></li><li><p>另外，我还添加了<code>pyenv</code>、<code>virtualenv</code>来显示虚拟环境下的python。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Zsh </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
